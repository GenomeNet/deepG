<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Create GenomeNet Model with Given Architecture Parameters — create_model_genomenet • deepG</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Create GenomeNet Model with Given Architecture Parameters — create_model_genomenet"><meta property="og:description" content="Create GenomeNet Model with Given Architecture Parameters"><meta property="og:image" content="https://genomenet.github.io/deepG/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">deepG</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.1-9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">
    <span class="fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Notebooks
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing" class="external-link">deepG tutorial</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing" class="external-link">Read-length level: Human contamination</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing" class="external-link">Locus level: CRISPR detection</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing" class="external-link">Gene level: 16S rRNA detection</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing" class="external-link">Genome level: Bacterial morphology (Sporulation)</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing" class="external-link">Full metagenome level: Colorectal cancer prediction</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing" class="external-link">BERT with deepG</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../articles/training_types.html">Training types</a>
    </li>
    <li>
      <a href="../articles/data_generator.html">Data generator</a>
    </li>
    <li>
      <a href="../articles/using_tb.html">Using tensorboard</a>
    </li>
    <li>
      <a href="../articles/integrated_gradient.html">Integrated Gradient</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/GenomeNet/deepG/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Create GenomeNet Model with Given Architecture Parameters</h1>
    <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/HEAD/R/create_model.R" class="external-link"><code>R/create_model.R</code></a></small>
    <div class="hidden name"><code>create_model_genomenet.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Create GenomeNet Model with Given Architecture Parameters</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">create_model_genomenet</span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">300</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  number_of_cnn_layers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  conv_block_count <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  kernel_size_0 <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  kernel_size_end <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  filters_0 <span class="op">=</span> <span class="fl">256</span>,</span>
<span>  filters_end <span class="op">=</span> <span class="fl">512</span>,</span>
<span>  dilation_end <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  max_pool_end <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  dense_layer_num <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  dense_layer_units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  dropout_lstm <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  dropout <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  batch_norm_momentum <span class="op">=</span> <span class="fl">0.8</span>,</span>
<span>  leaky_relu_alpha <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  dense_activation <span class="op">=</span> <span class="st">"relu"</span>,</span>
<span>  skip_block_fraction <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  residual_block <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  reverse_encoding <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  model_type <span class="op">=</span> <span class="st">"gap"</span>,</span>
<span>  recurrent_type <span class="op">=</span> <span class="st">"lstm"</span>,</span>
<span>  recurrent_layers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  recurrent_bidirectional <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  recurrent_units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  last_layer_activation <span class="op">=</span> <span class="st">"softmax"</span>,</span>
<span>  loss_fn <span class="op">=</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span>  auc_metric <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  num_targets <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  model_seed <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bal_acc <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  f1_metric <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mixed_precision <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mirrored_strategy <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>maxlen</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Input sequence length.</p></dd>


<dt>learning_rate</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Used by the <code>keras</code> optimizer that is specified by <code>optimizer</code>.</p></dd>


<dt>number_of_cnn_layers</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Target number of CNN-layers to use in total. If <code>number_of_cnn_layers</code> is
greater than <code>conv_block_count</code>, then the effective number of CNN layers
is set to the closest integer that is divisible by <code>conv_block_count</code>.</p></dd>


<dt>conv_block_count</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of convolutional blocks, into which the CNN layers are divided.
If this is greater than <code>number_of_cnn_layers</code>, then it is set to
<code>number_of_cnn_layers</code> (the convolutional block size will then be 1).<br>
Convolutional blocks are used when <code>model_type</code> is <code>"gap"</code> (the output of
the last <code>conv_block_count * (1 - skip_block_fraction)</code> blocks is
fed to global average pooling and then concatenated), and also when
<code>residual_block</code> is <code>TRUE</code> (the number of filters is held constant within
blocks). If neither of these is the case, <code>conv_block_count</code> has little
effect besides the fact that <code>number_of_cnn_layers</code> is set to the closest
integer divisible by <code>conv_block_count</code>.</p></dd>


<dt>kernel_size_0</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target CNN kernel size of the first CNN-layer. Although CNN kernel size is
always an integer, this value can be non-integer, potentially affecting
the kernel-sizes of intermediate layers (which are geometrically
interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).</p></dd>


<dt>kernel_size_end</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target CNN kernel size of the last CNN-layer; ignored if only one
CNN-layer is used (i.e. if <code>number_of_cnn_layers</code> is 1). Although CNN
kernel size is always an integer, this value can be non-integer,
potentially affecting the kernel-sizes of intermediate layers (which are
geometrically interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).</p></dd>


<dt>filters_0</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target filter number of the first CNN-layer. Although CNN filter number is
always an integer, this value can be non-integer, potentially affecting
the filter-numbers of intermediate layers (which are geometrically
interpolated between <code>filters_0</code> and <code>filters_end</code>).<br>
Note that filters are constant within convolutional blocks when
<code>residual_block</code> is <code>TRUE</code>.</p></dd>


<dt>filters_end</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target filter number of the last CNN-layer; ignored if only one CNN-layer
is used (i.e. if <code>number_of_cnn_layers</code> is 1). Although CNN filter number
is always an integer, this value can be non-integer, potentially affecting
the filter-numbers of intermediatdilation_rates layers (which are geometrically
interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).<br>
Note that filters are constant within convolutional blocks when
<code>residual_block</code> is <code>TRUE</code>.</p></dd>


<dt>dilation_end</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Dilation of the last CNN-layer <em>within each block</em>. Dilation rates within
each convolutional block grows exponentially from 1 (no dilation) for the
first CNN-layer to each block, to this value. Set to 1 (default) to
disable dilation.</p></dd>


<dt>max_pool_end</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target total effective pooling of CNN part of the network. "Effective
pooling" here is the product of the pooling rates of all previous
CNN-layers. A network with three CNN-layers, all of which are followed
by pooling layers of size 2, therefore has effective pooling of 8, with
the effective pooling at intermediate positions being 1 (beginning), 2,
and 4. Effective pooling after each layer is set to the power of 2 that is,
on a logarithmic scale, closest to
<code>max_pool_end ^ (&lt;CNN layer number&gt; / &lt;total number of CNN layers&gt;)</code>.
Therefore, even though the total effective pooling size of the whole
CNN part of the network will always be a power of 2, having different,
possibly non-integer values of <code>max_pool_end</code>, will still lead to
different networks.</p></dd>


<dt>dense_layer_num</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
number of dense layers at the end of the network, not counting the output
layer.</p></dd>


<dt>dense_layer_units</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of units in each dense layer, except for the output layer.</p></dd>


<dt>dropout_lstm</dt>
<dd><p>Fraction of the units to drop for inputs.</p></dd>


<dt>dropout</dt>
<dd><p>(<code>numeric(1)</code>)<br>
Dropout rate of dense layers, except for the output layer.</p></dd>


<dt>batch_norm_momentum</dt>
<dd><p>(<code>numeric(1)</code>)<br><code>momentum</code>-parameter of <code>layer_batch_normalization</code> layers used in the
convolutional part of the network.</p></dd>


<dt>leaky_relu_alpha</dt>
<dd><p>(<code>numeric(1)</code>)<br><code>alpha</code>-parameter of the <code>layer_activation_leaky_relu</code> activation layers
used in the convolutional part of the network.</p></dd>


<dt>dense_activation</dt>
<dd><p>(<code>character(1)</code>)<br>
Which activation function to use for dense layers. Should be one of
<code>"relu"</code>, <code>"sigmoid"</code>, or <code>"tanh"</code>.</p></dd>


<dt>skip_block_fraction</dt>
<dd><p>(<code>numeric(1)</code>)<br>
What fraction of the first convolutional blocks to skip.
Only used when <code>model_type</code> is <code>"gap"</code>.</p></dd>


<dt>residual_block</dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether to use residual layers in the convolutional part of the network.</p></dd>


<dt>reverse_encoding</dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether the network should have a second input for reverse-complement
sequences.</p></dd>


<dt>optimizer</dt>
<dd><p>(<code>character(1)</code>)<br>
Which optimizer to use. One of <code>"adam"</code>, <code>"adagrad"</code>, <code>"rmsprop"</code>, or <code>"sgd"</code>.</p></dd>


<dt>model_type</dt>
<dd><p>(<code>character(1)</code>)<br>
Whether to use the global average pooling (<code>"gap"</code>) or recurrent
(<code>"recurrent"</code>) model type.</p></dd>


<dt>recurrent_type</dt>
<dd><p>(<code>character(1)</code>)<br>
Which recurrent network type to use. One of <code>"lstm"</code> or <code>"gru"</code>.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt>recurrent_layers</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of recurrent layers.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt>recurrent_bidirectional</dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether to use bidirectional recurrent layers.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt>recurrent_units</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of units in each recurrent layer.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt>vocabulary_size</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Vocabulary size of (one-hot encoded) input strings. This determines the
input tensor shape, together with <code>maxlen</code>.</p></dd>


<dt>last_layer_activation</dt>
<dd><p>Either <code>"sigmoid"</code> or <code>"softmax"</code>.</p></dd>


<dt>loss_fn</dt>
<dd><p>Either <code>"categorical_crossentropy"</code> or <code>"binary_crossentropy"</code>. If <code>label_noise_matrix</code> given, will use custom <code>"noisy_loss"</code>.</p></dd>


<dt>auc_metric</dt>
<dd><p>Whether to add AUC metric.</p></dd>


<dt>num_targets</dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of output units to create.</p></dd>


<dt>model_seed</dt>
<dd><p>Set seed for model parameters in tensorflow if not <code>NULL</code>.</p></dd>


<dt>bal_acc</dt>
<dd><p>Whether to add balanced accuracy.</p></dd>


<dt>f1_metric</dt>
<dd><p>Whether to add F1 metric.</p></dd>


<dt>mixed_precision</dt>
<dd><p>Whether to use mixed precision (https://www.tensorflow.org/guide/mixed_precision).</p></dd>


<dt>mirrored_strategy</dt>
<dd><p>Whether to use distributed mirrored strategy. If NULL, will use distributed mirrored strategy only if &gt;1 GPU available.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    

<p>A keras model.</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">create_model_genomenet</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model: "model_2"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ________________________________________________________________________________</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Layer (type)                       Output Shape                    Param #     </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================================================================</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  input_3 (InputLayer)               [(None, 300, 4)]                0           </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  conv1d (Conv1D)                    (None, 300, 256)                16640       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  global_average_pooling1d (GlobalA  (None, 256)                     0           </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  veragePooling1D)                                                               </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  dropout (Dropout)                  (None, 256)                     0           </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  dense_3 (Dense)                    (None, 100)                     25700       </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  dense_4 (Dense)                    (None, 2)                       202         </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================================================================</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Total params: 42542 (166.18 KB)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Trainable params: 42542 (166.18 KB)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Non-trainable params: 0 (0.00 Byte)</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ________________________________________________________________________________</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer></div>

  


  

  </body></html>


<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Train neural network on genomic data — train_model • deepG</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Train neural network on genomic data — train_model"><meta property="og:description" content="Train a neural network on genomic data. Data can be fasta/fastq files, rds files or a prepared data set.
If the data is given as collection of fasta, fastq or rds files, function will create a data generator that extracts training and validation batches
from files. Function includes several options to determine the sampling strategy of the generator and preprocessing of the data.
Training progress can be visualized in tensorboard. Model weights can be stored during training using checkpoints."><meta property="og:image" content="https://genomenet.github.io/deepG/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">deepG</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.1-9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">
    <span class="fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Google Colab Notebooks
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing" class="external-link">deepG tutorial</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing" class="external-link">Human contamination</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1MmQB2pFfEcp4GbgbT7wu6ScNt1YsChmn?usp=sharing" class="external-link">CRISPR detection</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing" class="external-link">16S rRNA detection</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../articles/training_types.html">Training types</a>
    </li>
    <li>
      <a href="../articles/data_generator.html">Data generator</a>
    </li>
    <li>
      <a href="../articles/using_tb.html">Using tensorboard</a>
    </li>
    <li>
      <a href="../articles/integrated_gradient.html">Integrated Gradient</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/GenomeNet/deepG/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Train neural network on genomic data</h1>
    <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/HEAD/R/train.R" class="external-link"><code>R/train.R</code></a></small>
    <div class="hidden name"><code>train_model.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Train a neural network on genomic data. Data can be fasta/fastq files, rds files or a prepared data set.
If the data is given as collection of fasta, fastq or rds files, function will create a data generator that extracts training and validation batches
from files. Function includes several options to determine the sampling strategy of the generator and preprocessing of the data.
Training progress can be visualized in tensorboard. Model weights can be stored during training using checkpoints.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">train_model</span><span class="op">(</span></span>
<span>  train_type <span class="op">=</span> <span class="st">"lm"</span>,</span>
<span>  model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  path <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  path_val <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dataset <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dataset_val <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  path_checkpoint <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  path_tensorboard <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  path_log <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>  run_name <span class="op">=</span> <span class="st">"run"</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">64</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  max_queue_size <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  reduce_lr_on_plateau <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  lr_plateau_factor <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>  patience <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  cooldown <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  steps_per_epoch <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  step <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  shuffle_file_order <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  initial_epoch <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"c"</span>, <span class="st">"g"</span>, <span class="st">"t"</span><span class="op">)</span>,</span>
<span>  save_best_only <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  save_weights_only <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  seed <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1234</span>, <span class="fl">4321</span><span class="op">)</span>,</span>
<span>  shuffle_input <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  tb_images <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  format <span class="op">=</span> <span class="st">"fasta"</span>,</span>
<span>  path_file_log <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  vocabulary_label <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  file_limit <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  reverse_complement <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  reverse_complement_encoding <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  output_format <span class="op">=</span> <span class="st">"target_right"</span>,</span>
<span>  reset_states <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  ambiguous_nuc <span class="op">=</span> <span class="st">"equal"</span>,</span>
<span>  proportion_per_seq <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  read_data <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  use_quality_score <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  padding <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  early_stopping_time <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  added_label_path <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  add_input_as_seq <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  target_from_csv <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  target_split <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  validation_only_after_training <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  skip_amb_nuc <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  max_samples <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  split_seq <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  class_weight <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  concat_seq <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  target_len <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  print_scores <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  train_val_split_csv <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  use_coverage <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  set_learning <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  proportion_entries <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  sample_by_file_size <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  n_gram <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  n_gram_stride <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  random_sampling <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  add_noise <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>train_type</dt>
<dd><p>Either <code>"lm"</code>, <code>"lm_rds"</code> for language model; <code>"label_header"</code>, <code>"label_folder"</code>, <code>"label_csv"</code>, <code>"label_rds"</code> for classification or <code>"dummy_gen"</code>.</p><ul><li><p>Language model is trained to predict character(s) in a sequence. <br></p></li>
<li><p><code>"label_header"</code>/<code>"label_folder"</code>/<code>"label_csv"</code> are trained to predict a corresponding class given a sequence as input.</p></li>
<li><p>If <code>"label_header"</code>, class will be read from fasta headers.</p></li>
<li><p>If <code>"label_folder"</code>, class will be read from folder, i.e. all files in one folder must belong to the same class.</p></li>
<li><p>If <code>"label_csv"</code>, targets are read from a csv file. This file should have one column named "file". The targets then correspond to entries in that row (except "file"
column). Example: if we are currently working with a file called "a.fasta", there should be a row in our csv file</p><table class="table table"><tr><td>file</td><td>label_1</td><td>label_2</td></tr><tr><td>"a.fasta"</td><td>1</td><td>0</td></tr></table></li>
<li><p>If <code>"label_rds"</code>, generator will iterate over set of .rds files containing each a list of input and target tensors. Not implemented for model
with multiple inputs.</p></li>
<li><p>If <code>"lm_rds"</code>, generator will iterate over set of .rds files and will split tensor according to <code>target_len</code> argument
(targets are last <code>target_len</code> nucleotides of each sequence).</p></li>
<li><p>If <code>"dummy_gen"</code>, generator creates random data once and repeatedly feeds these to model.</p></li>
</ul></dd>


<dt>model</dt>
<dd><p>A keras model.</p></dd>


<dt>path</dt>
<dd><p>Path to training data. If <code>train_type</code> is <code>label_folder</code>, should be a vector or list
where each entry corresponds to a class (list elements can be directories and/or individual files). If <code>train_type</code> is not <code>label_folder</code>,
can be a single directory or file or a list of directories and/or files.</p></dd>


<dt>path_val</dt>
<dd><p>Path to validation data. See <code>path</code> argument for details.</p></dd>


<dt>dataset</dt>
<dd><p>List of training data holding training samples in RAM instead of using generator. Should be list with two entries called <code>"X"</code> and <code>"Y"</code>.</p></dd>


<dt>dataset_val</dt>
<dd><p>List of validation data. Should have two entries called <code>"X"</code> and <code>"Y"</code>.</p></dd>


<dt>path_checkpoint</dt>
<dd><p>Path to checkpoints folder or <code>NULL</code>. If <code>NULL</code>, checkpoints don't get stored.</p></dd>


<dt>path_tensorboard</dt>
<dd><p>Path to tensorboard directory or <code>NULL</code>. If <code>NULL</code>, training not tracked on tensorboard.</p></dd>


<dt>path_log</dt>
<dd><p>Path to directory to write training scores. File name is <code>run_name</code> + <code>".csv"</code>. No output if <code>NULL</code>.</p></dd>


<dt>train_val_ratio</dt>
<dd><p>For generator defines the fraction of batches that will be used for validation (compared to size of training data), i.e. one validation iteration
processes <code>batch_size</code> \(*\) <code>steps_per_epoch</code> \(*\) <code>train_val_ratio</code> samples. If you use dataset instead of generator and <code>dataset_val</code> is <code>NULL</code>, splits <code>dataset</code>
into train/validation data.</p></dd>


<dt>run_name</dt>
<dd><p>Name of the run. Name will be used to identify output from callbacks. If <code>NULL</code>, will use date as run name.
If name already present, will add <code>"_2"</code> to name or <code>"_{x+1}"</code> if name ends with <code>_x</code>, where <code>x</code> is some integer.</p></dd>


<dt>batch_size</dt>
<dd><p>Number of samples used for one network update.</p></dd>


<dt>epochs</dt>
<dd><p>Number of iterations.</p></dd>


<dt>max_queue_size</dt>
<dd><p>Maximum size for the generator queue.</p></dd>


<dt>reduce_lr_on_plateau</dt>
<dd><p>Whether to use learning rate scheduler.</p></dd>


<dt>lr_plateau_factor</dt>
<dd><p>Factor of decreasing learning rate when plateau is reached.</p></dd>


<dt>patience</dt>
<dd><p>Number of epochs waiting for decrease in validation loss before reducing learning rate.</p></dd>


<dt>cooldown</dt>
<dd><p>Number of epochs without changing learning rate.</p></dd>


<dt>steps_per_epoch</dt>
<dd><p>Number of training batches per epoch.</p></dd>


<dt>step</dt>
<dd><p>Frequency of sampling steps.</p></dd>


<dt>shuffle_file_order</dt>
<dd><p>Boolean, whether to go through files sequentially or shuffle beforehand.</p></dd>


<dt>initial_epoch</dt>
<dd><p>Epoch at which to start training. Note that network
will run for (<code>epochs</code> - <code>initial_epochs</code>) rounds and not <code>epochs</code> rounds.</p></dd>


<dt>vocabulary</dt>
<dd><p>Vector of allowed characters. Characters outside vocabulary get encoded as specified in <code>ambiguous_nuc</code>.</p></dd>


<dt>save_best_only</dt>
<dd><p>Only save model that improved on best validation loss score.</p></dd>


<dt>save_weights_only</dt>
<dd><p>Whether to save weights only.</p></dd>


<dt>seed</dt>
<dd><p>Sets seed for reproducible results.</p></dd>


<dt>shuffle_input</dt>
<dd><p>Whether to shuffle entries in file.</p></dd>


<dt>tb_images</dt>
<dd><p>Whether to show custom images (confusion matrix) in tensorboard "IMAGES" tab.</p></dd>


<dt>format</dt>
<dd><p>File format, <code>"fasta"</code>, <code>"fastq"</code> or <code>"rds"</code>.</p></dd>


<dt>path_file_log</dt>
<dd><p>Write name of files used for training to csv file if path is specified.</p></dd>


<dt>vocabulary_label</dt>
<dd><p>Character vector of possible targets. Targets outside <code>vocabulary_label</code> will get discarded if
<code>train_type = "label_header"</code>.</p></dd>


<dt>file_limit</dt>
<dd><p>Integer or <code>NULL</code>. If integer, use only specified number of randomly sampled files for training. Ignored if greater than number of files in <code>path</code>.</p></dd>


<dt>reverse_complement</dt>
<dd><p>Boolean, for every new file decide randomly to use original data or its reverse complement.</p></dd>


<dt>reverse_complement_encoding</dt>
<dd><p>Whether to use both original sequence and reverse complement as two input sequences.</p></dd>


<dt>output_format</dt>
<dd><p>Determines shape of output tensor for language model.
Either <code>"target_right"</code>, <code>"target_middle_lstm"</code>, <code>"target_middle_cnn"</code> or <code>"wavenet"</code>.
Assume a sequence <code>"AACCGTA"</code>. Output correspond as follows</p><ul><li><p><code>"target_right": X = "AACCGT", Y = "A"</code></p></li>
<li><p><code>"target_middle_lstm": X = (X_1 = "AAC", X_2 = "ATG"), Y = "C"</code> (note reversed order of X_2)</p></li>
<li><p><code>"target_middle_cnn": X = "AACGTA", Y = "C"</code></p></li>
<li><p><code>"wavenet": X = "AACCGT", Y = "ACCGTA"</code></p></li>
</ul></dd>


<dt>reset_states</dt>
<dd><p>Whether to reset hidden states of RNN layer at every new input file and before/after validation.</p></dd>


<dt>ambiguous_nuc</dt>
<dd><p>How to handle nucleotides outside vocabulary, either <code>"zero"</code>, <code>"discard"</code>, <code>"empirical"</code> or <code>"equal"</code>.</p><ul><li><p>If <code>"zero"</code>, input gets encoded as zero vector.</p></li>
<li><p>If <code>"equal"</code>, input is repetition of <code>1/length(vocabulary)</code>.</p></li>
<li><p>If <code>"discard"</code>, samples containing nucleotides outside vocabulary get discarded.</p></li>
<li><p>If <code>"empirical"</code>, use nucleotide distribution of current file.</p></li>
</ul></dd>


<dt>proportion_per_seq</dt>
<dd><p>Numerical value between 0 and 1. Proportion of sequence to take samples from (use random subsequence).</p></dd>


<dt>read_data</dt>
<dd><p>If <code>TRUE</code> the first element of output is a list of length 2, each containing one part of paired read. Maxlen should be 2*length of one read.</p></dd>


<dt>use_quality_score</dt>
<dd><p>Whether to use fastq quality scores. If <code>TRUE</code> input is not one-hot-encoding but corresponds to probabilities.
For example (0.97, 0.01, 0.01, 0.01) instead of (1, 0, 0, 0).</p></dd>


<dt>padding</dt>
<dd><p>Whether to pad sequences too short for one sample with zeros.</p></dd>


<dt>early_stopping_time</dt>
<dd><p>Time in seconds after which to stop training.</p></dd>


<dt>added_label_path</dt>
<dd><p>Path to file with additional input labels. Should be a csv file with one column named "file". Other columns should correspond to labels.</p></dd>


<dt>add_input_as_seq</dt>
<dd><p>Boolean vector specifying for each entry in <code>added_label_path</code> if rows from csv should be encoded as a sequence or used directly.
If a row in your csv file is a sequence this should be <code>TRUE</code>. For example you may want to add another sequence, say ACCGT. Then this would correspond to 1,2,2,3,4 in
csv file (if vocabulary = c("A", "C", "G", "T")).  If <code>add_input_as_seq</code> is <code>TRUE</code>, 12234 gets one-hot encoded, so added input is a 3D tensor.  If <code>add_input_as_seq</code> is
<code>FALSE</code> this will feed network just raw data (a 2D tensor).</p></dd>


<dt>target_from_csv</dt>
<dd><p>Path to csv file with target mapping. One column should be called "file" and other entries in row are the targets.</p></dd>


<dt>target_split</dt>
<dd><p>If target gets read from csv file, list of names to divide target tensor into list of tensors.
Example: if csv file has header names <code>"file", "label_1", "label_2", "label_3"</code> and <code>target_split = list(c("label_1", "label_2"), "label_3")</code>,
this will divide target matrix to list of length 2, where the first element contains columns named <code>"label_1"</code> and <code>"label_2"</code> and the
second entry contains the column named <code>"label_3"</code>.</p></dd>


<dt>validation_only_after_training</dt>
<dd><p>Whether to skip validation during training and only do one validation iteration after training.</p></dd>


<dt>skip_amb_nuc</dt>
<dd><p>Threshold of ambiguous nucleotides to accept in fasta entry. Complete entry will get discarded otherwise.</p></dd>


<dt>max_samples</dt>
<dd><p>Maximum number of samples to use from one file. If not <code>NULL</code> and file has more than <code>max_samples</code> samples, will randomly choose a
subset of <code>max_samples</code> samples.</p></dd>


<dt>split_seq</dt>
<dd><p>Split input sequence into two sequences while removing nucleotide in middle. If input is <code>x_1,..., x_(n+1)</code>, input gets split into
<code>input_1 = x_1,..., x_m</code> and <code>input_2 = x_(n+1),..., x_(m+2)</code> where <code>m = ceiling((n+1)/2)</code> and <code>n = maxlen</code>. Note that <code>x_(m+1)</code> is not used. Can be used for transfer learning,
when switching from language model trained with target in middle to label classification.</p></dd>


<dt>class_weight</dt>
<dd><p>List of weights for output. Order should correspond to <code>vocabulary_label</code>.
You can use <code><a href="get_class_weight.html">get_class_weight</a></code> function to estimate class weights:</p>
<p><code>class_weights &lt;- get_class_weights(path = path, train_type = train_type)</code></p>
<p>If <code>train_type = "label_csv"</code> you need to add path to csv file:</p>
<p><code>class_weights &lt;- get_class_weights(path = path, train_type = train_type, csv_path = target_from_csv)</code></p></dd>


<dt>concat_seq</dt>
<dd><p>Character string or <code>NULL</code>. If not <code>NULL</code> all entries from file get concatenated to one sequence with <code>concat_seq</code> string between them.
Example: If 1.entry AACC, 2. entry TTTG and <code>concat_seq = "ZZZ"</code> this becomes AACCZZZTTTG.</p></dd>


<dt>target_len</dt>
<dd><p>Number of nucleotides to predict at once for language model.</p></dd>


<dt>print_scores</dt>
<dd><p>Whether to print train/validation scores during training.</p></dd>


<dt>train_val_split_csv</dt>
<dd><p>A csv file specifying train/validation split. csv file should contain one column named <code>"file"</code> and one column named
<code>"type"</code>. The <code>"file"</code> column contains names of fasta/fastq files and <code>"type"</code> column specifies if file is used for training or validation.
Entries in <code>"type"</code> must be named <code>"train"</code> or <code>"val"</code>, otherwise file will not be used for either. <code>path</code> and <code>path_val</code> arguments should be the same.
Not implemented for <code>train_type = "label_folder"</code>.</p></dd>


<dt>use_coverage</dt>
<dd><p>Integer or <code>NULL</code>. If not <code>NULL</code>, use coverage as encoding rather than one-hot encoding and normalize.
Coverage information must be contained in fasta header: there must be a string <code>"cov_n"</code> in the header, where <code>n</code> is some integer.</p></dd>


<dt>set_learning</dt>
<dd><p>When you want to assign one label to set of samples. Only implemented for <code>train_type = "label_folder"</code>.
Input is a list with the following parameters</p><ul><li><p><code>samples_per_target</code>: how many samples to use for one target.</p></li>
<li><p><code>maxlen</code>: length of one sample.</p></li>
<li><p><code>reshape_mode</code>: <code>"time_dist", "multi_input"</code> or <code>"concat"</code>.</p><ul><li><p>If <code>reshape_mode</code> is <code>"multi_input"</code>, generator will produce <code>samples_per_target</code> separate inputs, each of length <code>maxlen</code> (model should have
<code>samples_per_target</code> input layers).</p></li>
<li><p>If reshape_mode is <code>"time_dist"</code>, generator will produce a 4D input array. The dimensions correspond to
<code>(batch_size, samples_per_target, maxlen, length(vocabulary))</code>.</p></li>
<li><p>If <code>reshape_mode</code> is <code>"concat"</code>, generator will concatenate <code>samples_per_target</code> sequences
of length <code>maxlen</code> to one long sequence.</p></li>
</ul></li>
<li><p>If <code>reshape_mode</code> is <code>"concat"</code>, there is an additional <code>buffer_len</code>
argument. If <code>buffer_len</code> is an integer, the subsequences are interspaced with <code>buffer_len</code> rows. The input length is
(<code>maxlen</code> \(*\) <code>samples_per_target</code>) + <code>buffer_len</code> \(*\) (<code>samples_per_target</code> - 1).</p></li>
</ul></dd>


<dt>proportion_entries</dt>
<dd><p>Proportion of fasta entries to keep. For example, if fasta file has 50 entries and <code>proportion_entries = 0.1</code>,
will randomly select 5 entries.</p></dd>


<dt>sample_by_file_size</dt>
<dd><p>Sample new file weighted by file size (bigger files more likely).</p></dd>


<dt>n_gram</dt>
<dd><p>Encode n nucleotides at once. Can be used for language model for target encoding.</p></dd>


<dt>n_gram_stride</dt>
<dd><p>Step size for n-gram encoding. For AACCGGTT with <code>n-gram = 4</code> and <code>n_gram_stride = 2</code>, generator encodes
<code>(AACC), (CCGG), (GGTT)</code>; for <code>n_gram_stride = 4</code> generator encodes <code>(AACC), (GGTT)</code>.</p></dd>


<dt>add_noise</dt>
<dd><p><code>NULL</code> or list of arguments. If not <code>NULL</code>, list must contain the following arguments: <code>noise_type</code> can be <code>"normal"</code> or <code>"uniform"</code>;
optional arguments <code>sd</code> or <code>mean</code> if noise_type is <code>"normal"</code> (default is <code>sd=1</code> and <code>mean=0</code>) or <code>min, max</code> if <code>noise_type</code> is <code>"uniform"</code>
(default is <code>min=0, max=1</code>).</p></dd>

</dl></div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># create dummy data</span></span></span>
<span class="r-in"><span><span class="va">path_train_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">path_train_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">path_val_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">path_val_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="kw">for</span> <span class="op">(</span><span class="va">current_path</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">path_train_1</span>, <span class="va">path_train_2</span>,</span></span>
<span class="r-in"><span>                       <span class="va">path_val_1</span>, <span class="va">path_val_2</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">current_path</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="create_dummy_data.html">create_dummy_data</a></span><span class="op">(</span>file_path <span class="op">=</span> <span class="va">current_path</span>,</span></span>
<span class="r-in"><span>                    num_files <span class="op">=</span> <span class="fl">3</span>,</span></span>
<span class="r-in"><span>                    seq_length <span class="op">=</span> <span class="fl">10</span>,</span></span>
<span class="r-in"><span>                    num_seq <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>                    vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"c"</span>, <span class="st">"g"</span>, <span class="st">"t"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># create model</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span>layer_lstm <span class="op">=</span> <span class="fl">8</span>, layer_dense <span class="op">=</span> <span class="fl">2</span>, maxlen <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Model: "model_33"</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ________________________________________________________________________________</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  Layer (type)                       Output Shape                    Param #     </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================================================================</span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  input_22 (InputLayer)              [(None, 5, 4)]                  0           </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  lstm_24 (LSTM)                     (None, 8)                       416         </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>  dense_35 (Dense)                   (None, 2)                       18          </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ================================================================================</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Total params: 434</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Trainable params: 434</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Non-trainable params: 0</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> ________________________________________________________________________________</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># train model</span></span></span>
<span class="r-in"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu">train_model</span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_folder"</span>,</span></span>
<span class="r-in"><span>                    model <span class="op">=</span> <span class="va">model</span>,</span></span>
<span class="r-in"><span>                    path <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">path_train_1</span>, <span class="va">path_train_2</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                    path_val <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">path_val_1</span>, <span class="va">path_val_2</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                    batch_size <span class="op">=</span> <span class="fl">8</span>,</span></span>
<span class="r-in"><span>                    epochs <span class="op">=</span> <span class="fl">3</span>,</span></span>
<span class="r-in"><span>                    steps_per_epoch <span class="op">=</span> <span class="fl">6</span>,</span></span>
<span class="r-in"><span>                    step <span class="op">=</span> <span class="fl">5</span>,</span></span>
<span class="r-in"><span>                    format <span class="op">=</span> <span class="st">"fasta"</span>,</span></span>
<span class="r-in"><span>                    vocabulary_label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label_1"</span>, <span class="st">"label_2"</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-msg co"><span class="r-pr">#&gt;</span> Training done.</span>
<span class="r-in"><span> </span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Alice McHardy.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.5.</p>
</div>

      </footer></div>

  


  

  </body></html>


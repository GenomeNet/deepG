<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Remove layers from model and add dense layers — remove_add_layers • deepG</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Remove layers from model and add dense layers — remove_add_layers"><meta property="og:description" content="Function takes a model as input and removes all layers after a certain layer, specified in layer_name argument.
Optional to add dense layers on top of pruned model. Model can have multiple output layers with separate loss/activation functions.
You can freeze all the weights of the pruned model by setting freeze_base_model = TRUE."><meta property="og:image" content="https://genomenet.github.io/deepG/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">deepG</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.1-9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">
    <span class="fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Notebooks
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing" class="external-link">deepG tutorial</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing" class="external-link">Read-length level: Human contamination</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing" class="external-link">Locus level: CRISPR detection</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing" class="external-link">Gene level: 16S rRNA detection</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing" class="external-link">Genome level: Bacterial morphology (Sporulation)</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing" class="external-link">Full metagenome level: Colorectal cancer prediction</a>
    </li>
    <li>
      <a href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing" class="external-link">BERT with deepG</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../articles/training_types.html">Training types</a>
    </li>
    <li>
      <a href="../articles/data_generator.html">Data generator</a>
    </li>
    <li>
      <a href="../articles/using_tb.html">Using tensorboard</a>
    </li>
    <li>
      <a href="../articles/integrated_gradient.html">Integrated Gradient</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/GenomeNet/deepG/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Remove layers from model and add dense layers</h1>
    <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/HEAD/R/create_model.R" class="external-link"><code>R/create_model.R</code></a></small>
    <div class="hidden name"><code>remove_add_layers.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Function takes a model as input and removes all layers after a certain layer, specified in <code>layer_name</code> argument.
Optional to add dense layers on top of pruned model. Model can have multiple output layers with separate loss/activation functions.
You can freeze all the weights of the pruned model by setting <code>freeze_base_model = TRUE</code>.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">remove_add_layers</span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  layer_name <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dense_layers <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  shared_dense_layers <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  last_activation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"softmax"</span><span class="op">)</span>,</span>
<span>  output_names <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  losses <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  dropout <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dropout_shared <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  freeze_base_model <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  compile <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  solver <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  flatten <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  global_pooling <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  model_seed <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  mixed_precision <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mirrored_strategy <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>model</dt>
<dd><p>A keras model.</p></dd>


<dt>layer_name</dt>
<dd><p>Name of last layer to use from old model.</p></dd>


<dt>dense_layers</dt>
<dd><p>List of vectors specifying number of units for each dense layer. If this is a list of length &gt; 1, model
has multiple output layers.</p></dd>


<dt>shared_dense_layers</dt>
<dd><p>Vector with number of units for dense layer. These layers will be connected on top of layer in
argument <code>layer_name</code>. Can be used to have shared dense layers, before model has multiple output layers. Don't use if model has just one output layer
(use only <code>dense_layers</code>).</p></dd>


<dt>last_activation</dt>
<dd><p>List of activations for last entry for each list entry from <code>dense_layers</code>. Either <code>"softmax"</code>, <code>"sigmoid"</code> or <code>"linear"</code>.</p></dd>


<dt>output_names</dt>
<dd><p>List of names for each output layer.</p></dd>


<dt>losses</dt>
<dd><p>List of loss function for each output.</p></dd>


<dt>verbose</dt>
<dd><p>Boolean.</p></dd>


<dt>dropout</dt>
<dd><p>List of vectors with dropout rates for each new dense layer.</p></dd>


<dt>dropout_shared</dt>
<dd><p>Vectors of dropout rates for dense layer from <code>shared_dense_layers</code>.</p></dd>


<dt>freeze_base_model</dt>
<dd><p>Whether to freeze all weights before new dense layers.</p></dd>


<dt>compile</dt>
<dd><p>Boolean, whether to compile the new model.</p></dd>


<dt>learning_rate</dt>
<dd><p>Learning rate if <code>compile = TRUE</code>, default learning rate of the old model.</p></dd>


<dt>solver</dt>
<dd><p>Optimization method, options are <code>"adam", "adagrad", "rmsprop"</code> or <code>"sgd"</code>.</p></dd>


<dt>flatten</dt>
<dd><p>Whether to add flatten layer before new dense layers.</p></dd>


<dt>global_pooling</dt>
<dd><p>"max_ch_first" for global max pooling with channel first
(<a href="https://keras.io/api/layers/pooling_layers/global_average_pooling1d/" class="external-link">keras docs</a>),
"max_ch_last" for global max pooling with channel last, "average_ch_first" for global average pooling with channel first,
"average_ch_last" for global average pooling with channel last or <code>NULL</code> for no global pooling.
"both_ch_first" or "both_ch_last" to combine average and max pooling. "all" for all 4 options at once.</p></dd>


<dt>model_seed</dt>
<dd><p>Set seed for model parameters in tensorflow if not <code>NULL</code>.</p></dd>


<dt>mixed_precision</dt>
<dd><p>Whether to use mixed precision (https://www.tensorflow.org/guide/mixed_precision).</p></dd>


<dt>mirrored_strategy</dt>
<dd><p>Whether to use distributed mirrored strategy. If NULL, will use distributed mirrored strategy only if &gt;1 GPU available.</p></dd>

</dl></div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">model_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span>layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">64</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                                 maxlen <span class="op">=</span> <span class="fl">50</span>,</span></span>
<span class="r-in"><span>                                 layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">4</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>                                 verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># get name of second to last layer </span></span></span>
<span class="r-in"><span><span class="va">num_layers</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">model_1</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">layers</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">layer_name</span> <span class="op">&lt;-</span> <span class="va">model_1</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">layers</span><span class="op">[[</span><span class="va">num_layers</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">name</span></span></span>
<span class="r-in"><span><span class="co"># add dense layer with multi outputs and separate loss/activations functions</span></span></span>
<span class="r-in"><span><span class="va">model_2</span> <span class="op">&lt;-</span> <span class="fu">remove_add_layers</span><span class="op">(</span>model <span class="op">=</span> <span class="va">model_1</span>,</span></span>
<span class="r-in"><span>                             layer_name <span class="op">=</span> <span class="va">layer_name</span>,</span></span>
<span class="r-in"><span>                             dense_layers <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">16</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             losses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"binary_crossentropy"</span>, <span class="st">"mae"</span>,</span></span>
<span class="r-in"><span>                                           <span class="st">"categorical_crossentropy"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             last_activation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"sigmoid"</span>, <span class="st">"linear"</span>, <span class="st">"softmax"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             freeze_base_model <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>                             output_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"out_1_binary_classsification"</span>, </span></span>
<span class="r-in"><span>                                                 <span class="st">"out_2_regression"</span>, </span></span>
<span class="r-in"><span>                                                 <span class="st">"out_3_classification"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span> </span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "Original model: "</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> NULL</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] "New model: "</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> NULL</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> input_23 trainable: FALSE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lstm_21 trainable: FALSE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> lstm_22 trainable: FALSE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> dense_39 trainable: FALSE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> dense_new_1 trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> dense_new_2 trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> dense_new_3 trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> dense_new_4 trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> out_1_binary_classsification trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> out_2_regression trainable: TRUE </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> out_3_classification trainable: TRUE </span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer></div>

  


  

  </body></html>


<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="deepG">
<title>Training Types • deepG</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Training Types">
<meta property="og:description" content="deepG">
<meta property="og:image" content="https://genomenet.github.io/deepG/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">deepG</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.3.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-notebooks">Notebooks</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-notebooks">
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing">deepG tutorial</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing">Read-length level: Human contamination</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing">Locus level: CRISPR detection</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing">Gene level: 16S rRNA detection</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing">Genome level: Bacterial morphology (Sporulation)</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing">Full metagenome level: Colorectal cancer prediction</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing">BERT with deepG</a>
  </div>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../articles/training_types.html">Training types</a>
    <a class="dropdown-item" href="../articles/data_generator.html">Data generator</a>
    <a class="dropdown-item" href="../articles/using_tb.html">Using tensorboard</a>
    <a class="dropdown-item" href="../articles/integrated_gradient.html">Integrated Gradient</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/GenomeNet/deepG/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Training Types</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/HEAD/vignettes/training_types.Rmd" class="external-link"><code>vignettes/training_types.Rmd</code></a></small>
      <div class="d-none name"><code>training_types.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://remotes.r-lib.org/reference/install_github.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"GenomeNet/deepG"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/GenomeNet/deepG" class="external-link">deepG</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org" class="external-link">magrittr</a></span><span class="op">)</span></span></code></pre></div>
<style type="text/css">
mark.in {
  background-color: CornflowerBlue;
}

mark.out {
  background-color: IndianRed;
}

</style>
<p>The deepG library offers several options to extract input/target
pairs from data. We can differentiate between to main approach:</p>
<ul>
<li>
<strong>Language model:</strong> predict a character or several
characters in a sequence.</li>
<li>
<strong>Label Classification:</strong> map a label to a
sequence.</li>
</ul>
<div class="section level2">
<h2 id="language-model">Language model<a class="anchor" aria-label="anchor" href="#language-model"></a>
</h2>
<p>With language model, we mean a model that predicts a character in a
sequence. We have several options to determine the output format of the
data generator using the <code>output_format</code> argument.</p>
<p>The <code>output_format</code> determines the shape of the output for
a language model, i.e. part of a sequence is the input <span class="math inline">\(X\)</span> and another the target <span class="math inline">\(Y\)</span>. Assume a sequence <tt>abcdefg</tt> and
<code>maxlen = 6</code>. Output correspond as follows</p>
<p><strong>“target_right”</strong>: <span class="math inline">\(X=\)</span> <tt>abcdef</tt>, <span class="math inline">\(Y=\)</span> <tt>g</tt></p>
<p><strong>“target_middle_lstm”</strong>: <span class="math inline">\(X
=\)</span> (<span class="math inline">\(X_1 =\)</span> <tt>abc</tt>,
<span class="math inline">\(X_2 =\)</span> <tt>gfe</tt>), <span class="math inline">\(Y=\)</span> <tt>d</tt> (note reversed order of
<span class="math inline">\(X_2\)</span>)</p>
<p><strong>“target_middle_cnn”</strong>: <span class="math inline">\(X
=\)</span> <tt>abcefg</tt>, <span class="math inline">\(Y =\)</span>
<tt>d</tt></p>
<p><strong>“wavenet”</strong>: <span class="math inline">\(X =\)</span>
<tt>abcdef</tt>, <span class="math inline">\(Y =\)</span>
<tt>bcdefg</tt></p>
<div class="section level3">
<h3 id="create-dummy-data">Create dummy data<a class="anchor" aria-label="anchor" href="#create-dummy-data"></a>
</h3>
<p>To test the different language model options, we create a simple
dummy data set consisting of a repetition of the sequence
<tt>AAACCCGGGTTTAAACCC…</tt>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span><span class="va">base_seq</span> <span class="op">&lt;-</span> <span class="st">"AAACCCGGGTTT"</span></span>
<span><span class="va">full_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/strrep.html" class="external-link">strrep</a></span><span class="op">(</span><span class="va">base_seq</span>, <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Header <span class="op">=</span> <span class="st">"header"</span>, Sequence <span class="op">=</span> <span class="va">full_seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create training fasta file</span></span>
<span><span class="va">train_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir</span><span class="op">)</span></span>
<span><span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="va">train_dir</span>, <span class="st">"train_1.fasta"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># create validation fasta file (use same data as training)</span></span>
<span><span class="va">val_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir</span><span class="op">)</span></span>
<span><span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="va">val_dir</span>, <span class="st">"val_1.fasta"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="predict-next-character">Predict next character<a class="anchor" aria-label="anchor" href="#predict-next-character"></a>
</h3>
<p>Say we want to predict the next character in a sequence given the
last 5 characters and our text consists of the letters <tt>A,C,G,T</tt>
. First we have to create a model. We may use a model with 1 LSTM and 1
dense layer for predictions.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> <span class="co"># text consists of A,C,G,T</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_1 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm (LSTM)                 (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense (Dense)               (None, 4)                 36        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 452 (1.77 KB)</span></span>
<span><span class="co">## Trainable params: 452 (1.77 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<p>Next we have to specify the location of our training and validation
data and the output format of the data generator</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"lm"</span>, <span class="co"># running a language model</span></span>
<span>                    output_format <span class="op">=</span> <span class="st">"target_right"</span>, <span class="co"># predict target at end of sequence</span></span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, <span class="co"># use 20% of samples for validation compared to train</span></span>
<span>                    batch_size <span class="op">=</span> <span class="fl">16</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 3s - loss: 1.4633 - acc: 0.25005/5 [==============================] - 1s 65ms/step - loss: 1.0263 - acc: 0.7000 - val_loss: 0.4127 - val_acc: 0.9375 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.4608 - acc: 0.87505/5 [==============================] - 0s 19ms/step - loss: 0.2672 - acc: 0.9750 - val_loss: 0.1263 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 3/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.1768 - acc: 1.00005/5 [==============================] - 0s 16ms/step - loss: 0.0844 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 4/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0371 - acc: 1.00005/5 [==============================] - 0s 18ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="predict-character-in-middle-of-sequence">Predict character in middle of sequence<a class="anchor" aria-label="anchor" href="#predict-character-in-middle-of-sequence"></a>
</h3>
<p>If we want to predict a character in the middle of a sequence and use
LSTM layers, we should split our input into two layers. One layer
handles the sequence before and one the input after the target. If, for
example</p>
<p>sequence: <tt> ACCG<mark class="in">T</mark>GGAA<br></tt></p>
<p>then first input corresponds to <tt>ACCG</tt> and second to
<tt>AAGG</tt>. We may create a model with two input layers using the
<code>create_model_cnn_lstm_target_middle</code></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn_target_middle.html">create_model_lstm_cnn_target_middle</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> </span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_1"</span></span>
<span><span class="co">## __________________________________________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape                 Param #   Connected to                  </span></span>
<span><span class="co">## ==================================================================================================</span></span>
<span><span class="co">##  input_2 (InputLayer)        [(None, 3, 4)]               0         []                            </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  input_3 (InputLayer)        [(None, 2, 4)]               0         []                            </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  lstm_1 (LSTM)               (None, 8)                    416       ['input_2[0][0]']             </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  lstm_2 (LSTM)               (None, 8)                    416       ['input_3[0][0]']             </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  concatenate (Concatenate)   (None, 16)                   0         ['lstm_1[0][0]',              </span></span>
<span><span class="co">##                                                                      'lstm_2[0][0]']              </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  dense_1 (Dense)             (None, 4)                    68        ['concatenate[0][0]']         </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">## ==================================================================================================</span></span>
<span><span class="co">## Total params: 900 (3.52 KB)</span></span>
<span><span class="co">## Trainable params: 900 (3.52 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## __________________________________________________________________________________________________</span></span></code></pre>
<p>The <code>train_model</code> call is identical to the previous model,
except we have to change the output format of the generator by setting
<code>output_format = "target_middle_lstm"</code>. This reverses the
order of the sequence after the target.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"lm"</span>, <span class="co"># running a language model</span></span>
<span>                    output_format <span class="op">=</span> <span class="st">"target_middle_lstm"</span>, <span class="co"># predict target in middle of sequence </span></span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, <span class="co"># use 20% of samples for validation compared to train</span></span>
<span>                    batch_size <span class="op">=</span> <span class="fl">16</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 5s - loss: 1.4213 - acc: 0.18755/5 [==============================] - 2s 95ms/step - loss: 1.0128 - acc: 0.6125 - val_loss: 0.4022 - val_acc: 0.8750 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.4443 - acc: 0.81255/5 [==============================] - 0s 21ms/step - loss: 0.2350 - acc: 0.9375 - val_loss: 0.0406 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 3/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0442 - acc: 1.00005/5 [==============================] - 0s 21ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 4/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0034 - acc: 1.00005/5 [==============================] - 0s 20ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.9478e-04 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="masked-language-model">Masked language model<a class="anchor" aria-label="anchor" href="#masked-language-model"></a>
</h3>
<p>Here we mask some parts of the input sequence and the model tries to
predict the masked regions. Can be used for training BERT-like models.
See also this <a href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing" class="external-link">notebook</a>.
We can first check how the generator works.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create dummy training data</span></span>
<span><span class="va">nt_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span>collapse <span class="op">=</span> <span class="st">""</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/strrep.html" class="external-link">strrep</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Sequence <span class="op">=</span> <span class="va">nt_seq</span>, Header <span class="op">=</span> <span class="st">"seq_1"</span><span class="op">)</span></span>
<span><span class="va">fasta_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span>fileext <span class="op">=</span> <span class="st">".fasta"</span><span class="op">)</span></span>
<span><span class="va">fasta_file</span> <span class="op">&lt;-</span> <span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">fasta_path</span><span class="op">)</span></span>
<span><span class="va">masked_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mask_rate <span class="op">=</span> <span class="fl">0.10</span>, <span class="co"># replace 10% of input with special mask token</span></span>
<span>                  random_rate <span class="op">=</span> <span class="fl">0.03</span>, <span class="co"># set 3% of input to random value</span></span>
<span>                  identity_rate <span class="op">=</span> <span class="fl">0.02</span>, <span class="co"># leave 2% unchanged (and set sample weight to 1)</span></span>
<span>                  include_sw <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># 0,1 matrix showing where masking was applied</span></span>
<span></span>
<span><span class="va">gen</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/get_generator.html">get_generator</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>                      train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>                      masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>                      batch_size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram_stride <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      return_int <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                      maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu">gen</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">sw</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, sw <span class="op">=</span> <span class="va">sw</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   x y sw</span></span>
<span><span class="co">## 1 5 1  1</span></span>
<span><span class="co">## 2 1 1  0</span></span>
<span><span class="co">## 3 1 1  0</span></span>
<span><span class="co">## 4 1 1  0</span></span>
<span><span class="co">## 5 1 1  0</span></span>
<span><span class="co">## 6 1 1  0</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span> <span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    x y sw</span></span>
<span><span class="co">## 1  5 1  1</span></span>
<span><span class="co">## 7  5 1  1</span></span>
<span><span class="co">## 14 5 1  1</span></span>
<span><span class="co">## 21 1 1  1</span></span>
<span><span class="co">## 34 5 2  1</span></span>
<span><span class="co">## 43 2 2  1</span></span>
<span><span class="co">## 51 4 3  1</span></span>
<span><span class="co">## 54 5 3  1</span></span>
<span><span class="co">## 59 3 3  1</span></span>
<span><span class="co">## 73 5 3  1</span></span>
<span><span class="co">## 74 5 3  1</span></span>
<span><span class="co">## 79 5 4  1</span></span>
<span><span class="co">## 82 5 4  1</span></span>
<span><span class="co">## 85 5 4  1</span></span>
<span><span class="co">## 87 2 4  1</span></span></code></pre>
<p>Create the model architecture.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_transformer.html">create_model_transformer</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  embed_dim <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  ff_dim <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  pos_encoding <span class="op">=</span> <span class="st">"embedding"</span>,</span>
<span>  head_size <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  num_heads <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  flatten_method <span class="op">=</span> <span class="st">"none"</span>,</span>
<span>  last_layer_activation <span class="op">=</span> <span class="st">"softmax"</span>,</span>
<span>  loss_fn <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span>  solver <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.005</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_2"</span></span>
<span><span class="co">## ________________________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">## ================================================================================</span></span>
<span><span class="co">##  input_4 (InputLayer)               [(None, 100)]                   0           </span></span>
<span><span class="co">##  layer_pos_embedding (layer_pos_em  (None, 100, 16)                 1696        </span></span>
<span><span class="co">##  bedding)                                                                       </span></span>
<span><span class="co">##  layer_transformer_block (layer_tr  (None, 100, 16)                 6512        </span></span>
<span><span class="co">##  ansformer_block)                                                               </span></span>
<span><span class="co">##  dense_4 (Dense)                    (None, 100, 6)                  102         </span></span>
<span><span class="co">## ================================================================================</span></span>
<span><span class="co">## Total params: 8310 (32.46 KB)</span></span>
<span><span class="co">## Trainable params: 8310 (32.46 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## ________________________________________________________________________________</span></span></code></pre>
<p>Train the model.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">128</span></span>
<span><span class="va">masked_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mask_rate <span class="op">=</span> <span class="fl">0.10</span>, random_rate <span class="op">=</span> <span class="fl">0.03</span>, identity_rate <span class="op">=</span> <span class="fl">0.02</span>, include_sw <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            <span class="co"># training args</span></span>
<span>            run_name <span class="op">=</span> <span class="st">"bert_1"</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">75</span>,</span>
<span>            <span class="co"># generator args</span></span>
<span>            maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>            train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>            path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>            path_val <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>            batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>            step <span class="op">=</span> <span class="fl">25</span>,</span>
<span>            masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>            proportion_per_seq <span class="op">=</span> <span class="fl">0.97</span>,</span>
<span>            return_int <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 1:04 - loss: 0.3223 - acc: 0.1191 2/75 [..............................] - ETA: 3s - loss: 0.3005 - acc: 0.1820   3/75 [&gt;.............................] - ETA: 3s - loss: 0.2810 - acc: 0.2263 4/75 [&gt;.............................] - ETA: 3s - loss: 0.2652 - acc: 0.2792 5/75 [=&gt;............................] - ETA: 3s - loss: 0.2567 - acc: 0.3310 7/75 [=&gt;............................] - ETA: 3s - loss: 0.2444 - acc: 0.4058 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.2397 - acc: 0.4415 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.2361 - acc: 0.483110/75 [===&gt;..........................] - ETA: 3s - loss: 0.2329 - acc: 0.523311/75 [===&gt;..........................] - ETA: 3s - loss: 0.2304 - acc: 0.557513/75 [====&gt;.........................] - ETA: 3s - loss: 0.2268 - acc: 0.605814/75 [====&gt;.........................] - ETA: 3s - loss: 0.2255 - acc: 0.624915/75 [=====&gt;........................] - ETA: 3s - loss: 0.2243 - acc: 0.643116/75 [=====&gt;........................] - ETA: 3s - loss: 0.2230 - acc: 0.659317/75 [=====&gt;........................] - ETA: 3s - loss: 0.2219 - acc: 0.673519/75 [======&gt;.......................] - ETA: 2s - loss: 0.2201 - acc: 0.697520/75 [=======&gt;......................] - ETA: 2s - loss: 0.2192 - acc: 0.707821/75 [=======&gt;......................] - ETA: 2s - loss: 0.2182 - acc: 0.717322/75 [=======&gt;......................] - ETA: 2s - loss: 0.2175 - acc: 0.725523/75 [========&gt;.....................] - ETA: 2s - loss: 0.2166 - acc: 0.733525/75 [=========&gt;....................] - ETA: 2s - loss: 0.2153 - acc: 0.747026/75 [=========&gt;....................] - ETA: 2s - loss: 0.2148 - acc: 0.752927/75 [=========&gt;....................] - ETA: 2s - loss: 0.2143 - acc: 0.758428/75 [==========&gt;...................] - ETA: 2s - loss: 0.2138 - acc: 0.763629/75 [==========&gt;...................] - ETA: 2s - loss: 0.2133 - acc: 0.768331/75 [===========&gt;..................] - ETA: 2s - loss: 0.2126 - acc: 0.776932/75 [===========&gt;..................] - ETA: 2s - loss: 0.2122 - acc: 0.780933/75 [============&gt;.................] - ETA: 2s - loss: 0.2118 - acc: 0.784534/75 [============&gt;.................] - ETA: 2s - loss: 0.2114 - acc: 0.788035/75 [=============&gt;................] - ETA: 2s - loss: 0.2110 - acc: 0.791236/75 [=============&gt;................] - ETA: 2s - loss: 0.2106 - acc: 0.794437/75 [=============&gt;................] - ETA: 2s - loss: 0.2103 - acc: 0.797338/75 [==============&gt;...............] - ETA: 1s - loss: 0.2101 - acc: 0.800039/75 [==============&gt;...............] - ETA: 1s - loss: 0.2099 - acc: 0.802740/75 [===============&gt;..............] - ETA: 1s - loss: 0.2095 - acc: 0.805241/75 [===============&gt;..............] - ETA: 1s - loss: 0.2092 - acc: 0.807642/75 [===============&gt;..............] - ETA: 1s - loss: 0.2089 - acc: 0.809943/75 [================&gt;.............] - ETA: 1s - loss: 0.2087 - acc: 0.812045/75 [=================&gt;............] - ETA: 1s - loss: 0.2083 - acc: 0.816146/75 [=================&gt;............] - ETA: 1s - loss: 0.2080 - acc: 0.818147/75 [=================&gt;............] - ETA: 1s - loss: 0.2077 - acc: 0.819948/75 [==================&gt;...........] - ETA: 1s - loss: 0.2076 - acc: 0.821649/75 [==================&gt;...........] - ETA: 1s - loss: 0.2075 - acc: 0.823350/75 [===================&gt;..........] - ETA: 1s - loss: 0.2074 - acc: 0.824851/75 [===================&gt;..........] - ETA: 1s - loss: 0.2072 - acc: 0.826452/75 [===================&gt;..........] - ETA: 1s - loss: 0.2070 - acc: 0.827953/75 [====================&gt;.........] - ETA: 1s - loss: 0.2069 - acc: 0.829354/75 [====================&gt;.........] - ETA: 1s - loss: 0.2066 - acc: 0.830755/75 [=====================&gt;........] - ETA: 1s - loss: 0.2064 - acc: 0.832157/75 [=====================&gt;........] - ETA: 0s - loss: 0.2061 - acc: 0.834758/75 [======================&gt;.......] - ETA: 0s - loss: 0.2059 - acc: 0.835959/75 [======================&gt;.......] - ETA: 0s - loss: 0.2057 - acc: 0.837160/75 [=======================&gt;......] - ETA: 0s - loss: 0.2056 - acc: 0.838261/75 [=======================&gt;......] - ETA: 0s - loss: 0.2054 - acc: 0.839362/75 [=======================&gt;......] - ETA: 0s - loss: 0.2052 - acc: 0.840463/75 [========================&gt;.....] - ETA: 0s - loss: 0.2051 - acc: 0.841564/75 [========================&gt;.....] - ETA: 0s - loss: 0.2050 - acc: 0.842465/75 [=========================&gt;....] - ETA: 0s - loss: 0.2050 - acc: 0.843366/75 [=========================&gt;....] - ETA: 0s - loss: 0.2049 - acc: 0.844268/75 [==========================&gt;...] - ETA: 0s - loss: 0.2048 - acc: 0.846069/75 [==========================&gt;...] - ETA: 0s - loss: 0.2047 - acc: 0.846870/75 [===========================&gt;..] - ETA: 0s - loss: 0.2046 - acc: 0.847671/75 [===========================&gt;..] - ETA: 0s - loss: 0.2046 - acc: 0.848472/75 [===========================&gt;..] - ETA: 0s - loss: 0.2045 - acc: 0.849173/75 [============================&gt;.] - ETA: 0s - loss: 0.2044 - acc: 0.849974/75 [============================&gt;.] - ETA: 0s - loss: 0.2043 - acc: 0.850775/75 [==============================] - ETA: 0s - loss: 0.2042 - acc: 0.851475/75 [==============================] - 5s 54ms/step - loss: 0.2042 - acc: 0.8514 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 2/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.1964 - acc: 0.9049 2/75 [..............................] - ETA: 4s - loss: 0.1985 - acc: 0.9034 3/75 [&gt;.............................] - ETA: 4s - loss: 0.1978 - acc: 0.9048 4/75 [&gt;.............................] - ETA: 3s - loss: 0.1980 - acc: 0.9046 5/75 [=&gt;............................] - ETA: 3s - loss: 0.1988 - acc: 0.9040 6/75 [=&gt;............................] - ETA: 3s - loss: 0.1977 - acc: 0.9046 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.1977 - acc: 0.9046 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.1976 - acc: 0.904510/75 [===&gt;..........................] - ETA: 4s - loss: 0.1976 - acc: 0.904611/75 [===&gt;..........................] - ETA: 4s - loss: 0.1974 - acc: 0.904712/75 [===&gt;..........................] - ETA: 4s - loss: 0.1972 - acc: 0.905113/75 [====&gt;.........................] - ETA: 3s - loss: 0.1974 - acc: 0.905014/75 [====&gt;.........................] - ETA: 3s - loss: 0.1975 - acc: 0.904915/75 [=====&gt;........................] - ETA: 3s - loss: 0.1974 - acc: 0.904817/75 [=====&gt;........................] - ETA: 3s - loss: 0.1974 - acc: 0.904618/75 [======&gt;.......................] - ETA: 3s - loss: 0.1973 - acc: 0.904719/75 [======&gt;.......................] - ETA: 3s - loss: 0.1973 - acc: 0.904820/75 [=======&gt;......................] - ETA: 3s - loss: 0.1971 - acc: 0.905021/75 [=======&gt;......................] - ETA: 3s - loss: 0.1975 - acc: 0.904722/75 [=======&gt;......................] - ETA: 3s - loss: 0.1973 - acc: 0.905023/75 [========&gt;.....................] - ETA: 3s - loss: 0.1970 - acc: 0.905224/75 [========&gt;.....................] - ETA: 3s - loss: 0.1970 - acc: 0.905125/75 [=========&gt;....................] - ETA: 2s - loss: 0.1968 - acc: 0.905226/75 [=========&gt;....................] - ETA: 2s - loss: 0.1968 - acc: 0.905127/75 [=========&gt;....................] - ETA: 2s - loss: 0.1969 - acc: 0.905128/75 [==========&gt;...................] - ETA: 2s - loss: 0.1970 - acc: 0.905129/75 [==========&gt;...................] - ETA: 2s - loss: 0.1969 - acc: 0.905430/75 [===========&gt;..................] - ETA: 2s - loss: 0.1968 - acc: 0.905431/75 [===========&gt;..................] - ETA: 2s - loss: 0.1966 - acc: 0.905532/75 [===========&gt;..................] - ETA: 2s - loss: 0.1968 - acc: 0.905333/75 [============&gt;.................] - ETA: 2s - loss: 0.1970 - acc: 0.905134/75 [============&gt;.................] - ETA: 2s - loss: 0.1969 - acc: 0.905335/75 [=============&gt;................] - ETA: 2s - loss: 0.1969 - acc: 0.905436/75 [=============&gt;................] - ETA: 2s - loss: 0.1969 - acc: 0.905537/75 [=============&gt;................] - ETA: 2s - loss: 0.1968 - acc: 0.905538/75 [==============&gt;...............] - ETA: 2s - loss: 0.1969 - acc: 0.905639/75 [==============&gt;...............] - ETA: 2s - loss: 0.1970 - acc: 0.905640/75 [===============&gt;..............] - ETA: 1s - loss: 0.1970 - acc: 0.905641/75 [===============&gt;..............] - ETA: 1s - loss: 0.1969 - acc: 0.905742/75 [===============&gt;..............] - ETA: 1s - loss: 0.1969 - acc: 0.905843/75 [================&gt;.............] - ETA: 1s - loss: 0.1970 - acc: 0.905744/75 [================&gt;.............] - ETA: 1s - loss: 0.1968 - acc: 0.905745/75 [=================&gt;............] - ETA: 1s - loss: 0.1969 - acc: 0.905646/75 [=================&gt;............] - ETA: 1s - loss: 0.1969 - acc: 0.905747/75 [=================&gt;............] - ETA: 1s - loss: 0.1969 - acc: 0.905749/75 [==================&gt;...........] - ETA: 1s - loss: 0.1969 - acc: 0.905750/75 [===================&gt;..........] - ETA: 1s - loss: 0.1969 - acc: 0.905851/75 [===================&gt;..........] - ETA: 1s - loss: 0.1968 - acc: 0.905852/75 [===================&gt;..........] - ETA: 1s - loss: 0.1969 - acc: 0.905853/75 [====================&gt;.........] - ETA: 1s - loss: 0.1969 - acc: 0.905754/75 [====================&gt;.........] - ETA: 1s - loss: 0.1970 - acc: 0.905755/75 [=====================&gt;........] - ETA: 1s - loss: 0.1970 - acc: 0.905856/75 [=====================&gt;........] - ETA: 1s - loss: 0.1968 - acc: 0.906057/75 [=====================&gt;........] - ETA: 1s - loss: 0.1968 - acc: 0.905958/75 [======================&gt;.......] - ETA: 0s - loss: 0.1968 - acc: 0.906059/75 [======================&gt;.......] - ETA: 0s - loss: 0.1969 - acc: 0.906061/75 [=======================&gt;......] - ETA: 0s - loss: 0.1968 - acc: 0.906163/75 [========================&gt;.....] - ETA: 0s - loss: 0.1967 - acc: 0.906264/75 [========================&gt;.....] - ETA: 0s - loss: 0.1966 - acc: 0.906365/75 [=========================&gt;....] - ETA: 0s - loss: 0.1966 - acc: 0.906366/75 [=========================&gt;....] - ETA: 0s - loss: 0.1966 - acc: 0.906367/75 [=========================&gt;....] - ETA: 0s - loss: 0.1966 - acc: 0.906368/75 [==========================&gt;...] - ETA: 0s - loss: 0.1966 - acc: 0.906369/75 [==========================&gt;...] - ETA: 0s - loss: 0.1965 - acc: 0.906370/75 [===========================&gt;..] - ETA: 0s - loss: 0.1965 - acc: 0.906471/75 [===========================&gt;..] - ETA: 0s - loss: 0.1965 - acc: 0.906472/75 [===========================&gt;..] - ETA: 0s - loss: 0.1965 - acc: 0.906473/75 [============================&gt;.] - ETA: 0s - loss: 0.1965 - acc: 0.906575/75 [==============================] - ETA: 0s - loss: 0.1965 - acc: 0.906575/75 [==============================] - 4s 55ms/step - loss: 0.1965 - acc: 0.9065 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 3/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 4s - loss: 0.1936 - acc: 0.9098 2/75 [..............................] - ETA: 4s - loss: 0.1943 - acc: 0.9098 4/75 [&gt;.............................] - ETA: 3s - loss: 0.1959 - acc: 0.9063 5/75 [=&gt;............................] - ETA: 3s - loss: 0.1951 - acc: 0.9061 6/75 [=&gt;............................] - ETA: 3s - loss: 0.1951 - acc: 0.9044 7/75 [=&gt;............................] - ETA: 3s - loss: 0.1939 - acc: 0.9050 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.1941 - acc: 0.905010/75 [===&gt;..........................] - ETA: 3s - loss: 0.1941 - acc: 0.904012/75 [===&gt;..........................] - ETA: 3s - loss: 0.1944 - acc: 0.902713/75 [====&gt;.........................] - ETA: 3s - loss: 0.1946 - acc: 0.902315/75 [=====&gt;........................] - ETA: 3s - loss: 0.1944 - acc: 0.902616/75 [=====&gt;........................] - ETA: 3s - loss: 0.1946 - acc: 0.902817/75 [=====&gt;........................] - ETA: 3s - loss: 0.1947 - acc: 0.902918/75 [======&gt;.......................] - ETA: 2s - loss: 0.1947 - acc: 0.902419/75 [======&gt;.......................] - ETA: 2s - loss: 0.1948 - acc: 0.901821/75 [=======&gt;......................] - ETA: 2s - loss: 0.1946 - acc: 0.902522/75 [=======&gt;......................] - ETA: 2s - loss: 0.1945 - acc: 0.902823/75 [========&gt;.....................] - ETA: 2s - loss: 0.1944 - acc: 0.903024/75 [========&gt;.....................] - ETA: 2s - loss: 0.1943 - acc: 0.903025/75 [=========&gt;....................] - ETA: 2s - loss: 0.1943 - acc: 0.903126/75 [=========&gt;....................] - ETA: 2s - loss: 0.1942 - acc: 0.903427/75 [=========&gt;....................] - ETA: 2s - loss: 0.1940 - acc: 0.903829/75 [==========&gt;...................] - ETA: 2s - loss: 0.1940 - acc: 0.903630/75 [===========&gt;..................] - ETA: 2s - loss: 0.1939 - acc: 0.903832/75 [===========&gt;..................] - ETA: 2s - loss: 0.1939 - acc: 0.904133/75 [============&gt;.................] - ETA: 2s - loss: 0.1939 - acc: 0.904235/75 [=============&gt;................] - ETA: 2s - loss: 0.1941 - acc: 0.903736/75 [=============&gt;................] - ETA: 2s - loss: 0.1941 - acc: 0.903937/75 [=============&gt;................] - ETA: 1s - loss: 0.1941 - acc: 0.903938/75 [==============&gt;...............] - ETA: 1s - loss: 0.1941 - acc: 0.904039/75 [==============&gt;...............] - ETA: 1s - loss: 0.1941 - acc: 0.903541/75 [===============&gt;..............] - ETA: 1s - loss: 0.1942 - acc: 0.903342/75 [===============&gt;..............] - ETA: 1s - loss: 0.1941 - acc: 0.903543/75 [================&gt;.............] - ETA: 1s - loss: 0.1941 - acc: 0.903744/75 [================&gt;.............] - ETA: 1s - loss: 0.1940 - acc: 0.903845/75 [=================&gt;............] - ETA: 1s - loss: 0.1939 - acc: 0.902946/75 [=================&gt;............] - ETA: 1s - loss: 0.1939 - acc: 0.903047/75 [=================&gt;............] - ETA: 1s - loss: 0.1938 - acc: 0.903248/75 [==================&gt;...........] - ETA: 1s - loss: 0.1938 - acc: 0.903350/75 [===================&gt;..........] - ETA: 1s - loss: 0.1937 - acc: 0.903251/75 [===================&gt;..........] - ETA: 1s - loss: 0.1935 - acc: 0.903552/75 [===================&gt;..........] - ETA: 1s - loss: 0.1935 - acc: 0.903653/75 [====================&gt;.........] - ETA: 1s - loss: 0.1934 - acc: 0.903754/75 [====================&gt;.........] - ETA: 1s - loss: 0.1934 - acc: 0.903956/75 [=====================&gt;........] - ETA: 0s - loss: 0.1934 - acc: 0.904257/75 [=====================&gt;........] - ETA: 0s - loss: 0.1934 - acc: 0.904358/75 [======================&gt;.......] - ETA: 0s - loss: 0.1934 - acc: 0.904359/75 [======================&gt;.......] - ETA: 0s - loss: 0.1933 - acc: 0.904461/75 [=======================&gt;......] - ETA: 0s - loss: 0.1932 - acc: 0.904762/75 [=======================&gt;......] - ETA: 0s - loss: 0.1931 - acc: 0.904963/75 [========================&gt;.....] - ETA: 0s - loss: 0.1930 - acc: 0.905064/75 [========================&gt;.....] - ETA: 0s - loss: 0.1930 - acc: 0.905065/75 [=========================&gt;....] - ETA: 0s - loss: 0.1930 - acc: 0.905066/75 [=========================&gt;....] - ETA: 0s - loss: 0.1930 - acc: 0.904967/75 [=========================&gt;....] - ETA: 0s - loss: 0.1930 - acc: 0.904968/75 [==========================&gt;...] - ETA: 0s - loss: 0.1930 - acc: 0.905070/75 [===========================&gt;..] - ETA: 0s - loss: 0.1929 - acc: 0.904271/75 [===========================&gt;..] - ETA: 0s - loss: 0.1929 - acc: 0.904173/75 [============================&gt;.] - ETA: 0s - loss: 0.1928 - acc: 0.903974/75 [============================&gt;.] - ETA: 0s - loss: 0.1927 - acc: 0.903575/75 [==============================] - 4s 52ms/step - loss: 0.1926 - acc: 0.9033 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 4/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.1888 - acc: 0.9126 2/75 [..............................] - ETA: 3s - loss: 0.1876 - acc: 0.9122 3/75 [&gt;.............................] - ETA: 3s - loss: 0.1885 - acc: 0.8980 4/75 [&gt;.............................] - ETA: 3s - loss: 0.1892 - acc: 0.8971 5/75 [=&gt;............................] - ETA: 3s - loss: 0.1890 - acc: 0.8987 7/75 [=&gt;............................] - ETA: 3s - loss: 0.1881 - acc: 0.9017 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.1874 - acc: 0.9025 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.1871 - acc: 0.901910/75 [===&gt;..........................] - ETA: 3s - loss: 0.1877 - acc: 0.900511/75 [===&gt;..........................] - ETA: 3s - loss: 0.1864 - acc: 0.900513/75 [====&gt;.........................] - ETA: 3s - loss: 0.1852 - acc: 0.900914/75 [====&gt;.........................] - ETA: 3s - loss: 0.1842 - acc: 0.901415/75 [=====&gt;........................] - ETA: 3s - loss: 0.1828 - acc: 0.900516/75 [=====&gt;........................] - ETA: 3s - loss: 0.1827 - acc: 0.899918/75 [======&gt;.......................] - ETA: 3s - loss: 0.1805 - acc: 0.896019/75 [======&gt;.......................] - ETA: 2s - loss: 0.1789 - acc: 0.895121/75 [=======&gt;......................] - ETA: 2s - loss: 0.1781 - acc: 0.888422/75 [=======&gt;......................] - ETA: 2s - loss: 0.1776 - acc: 0.884423/75 [========&gt;.....................] - ETA: 2s - loss: 0.1763 - acc: 0.883724/75 [========&gt;.....................] - ETA: 2s - loss: 0.1751 - acc: 0.882525/75 [=========&gt;....................] - ETA: 2s - loss: 0.1741 - acc: 0.881726/75 [=========&gt;....................] - ETA: 2s - loss: 0.1736 - acc: 0.880927/75 [=========&gt;....................] - ETA: 2s - loss: 0.1730 - acc: 0.879228/75 [==========&gt;...................] - ETA: 2s - loss: 0.1730 - acc: 0.877329/75 [==========&gt;...................] - ETA: 2s - loss: 0.1722 - acc: 0.877030/75 [===========&gt;..................] - ETA: 2s - loss: 0.1721 - acc: 0.875831/75 [===========&gt;..................] - ETA: 2s - loss: 0.1713 - acc: 0.876233/75 [============&gt;.................] - ETA: 2s - loss: 0.1699 - acc: 0.877234/75 [============&gt;.................] - ETA: 2s - loss: 0.1693 - acc: 0.877636/75 [=============&gt;................] - ETA: 2s - loss: 0.1680 - acc: 0.879337/75 [=============&gt;................] - ETA: 2s - loss: 0.1676 - acc: 0.879239/75 [==============&gt;...............] - ETA: 1s - loss: 0.1664 - acc: 0.879740/75 [===============&gt;..............] - ETA: 1s - loss: 0.1659 - acc: 0.880241/75 [===============&gt;..............] - ETA: 1s - loss: 0.1649 - acc: 0.881542/75 [===============&gt;..............] - ETA: 1s - loss: 0.1642 - acc: 0.882043/75 [================&gt;.............] - ETA: 1s - loss: 0.1640 - acc: 0.881345/75 [=================&gt;............] - ETA: 1s - loss: 0.1624 - acc: 0.882646/75 [=================&gt;............] - ETA: 1s - loss: 0.1617 - acc: 0.883047/75 [=================&gt;............] - ETA: 1s - loss: 0.1611 - acc: 0.883148/75 [==================&gt;...........] - ETA: 1s - loss: 0.1606 - acc: 0.882549/75 [==================&gt;...........] - ETA: 1s - loss: 0.1600 - acc: 0.882351/75 [===================&gt;..........] - ETA: 1s - loss: 0.1589 - acc: 0.881752/75 [===================&gt;..........] - ETA: 1s - loss: 0.1582 - acc: 0.881953/75 [====================&gt;.........] - ETA: 1s - loss: 0.1576 - acc: 0.881954/75 [====================&gt;.........] - ETA: 1s - loss: 0.1570 - acc: 0.882056/75 [=====================&gt;........] - ETA: 1s - loss: 0.1558 - acc: 0.882457/75 [=====================&gt;........] - ETA: 0s - loss: 0.1550 - acc: 0.882958/75 [======================&gt;.......] - ETA: 0s - loss: 0.1544 - acc: 0.883359/75 [======================&gt;.......] - ETA: 0s - loss: 0.1538 - acc: 0.883560/75 [=======================&gt;......] - ETA: 0s - loss: 0.1531 - acc: 0.883861/75 [=======================&gt;......] - ETA: 0s - loss: 0.1524 - acc: 0.884462/75 [=======================&gt;......] - ETA: 0s - loss: 0.1517 - acc: 0.884963/75 [========================&gt;.....] - ETA: 0s - loss: 0.1509 - acc: 0.885664/75 [========================&gt;.....] - ETA: 0s - loss: 0.1501 - acc: 0.886165/75 [=========================&gt;....] - ETA: 0s - loss: 0.1493 - acc: 0.887066/75 [=========================&gt;....] - ETA: 0s - loss: 0.1485 - acc: 0.887768/75 [==========================&gt;...] - ETA: 0s - loss: 0.1468 - acc: 0.888969/75 [==========================&gt;...] - ETA: 0s - loss: 0.1459 - acc: 0.889371/75 [===========================&gt;..] - ETA: 0s - loss: 0.1440 - acc: 0.890272/75 [===========================&gt;..] - ETA: 0s - loss: 0.1431 - acc: 0.890573/75 [============================&gt;.] - ETA: 0s - loss: 0.1421 - acc: 0.891074/75 [============================&gt;.] - ETA: 0s - loss: 0.1411 - acc: 0.891375/75 [==============================] - ETA: 0s - loss: 0.1400 - acc: 0.891875/75 [==============================] - 4s 53ms/step - loss: 0.1400 - acc: 0.8918 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 5/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.0590 - acc: 0.9364 2/75 [..............................] - ETA: 3s - loss: 0.0588 - acc: 0.9349 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0569 - acc: 0.9372 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0526 - acc: 0.9422 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0528 - acc: 0.9396 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0508 - acc: 0.9432 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0474 - acc: 0.9472 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0464 - acc: 0.947810/75 [===&gt;..........................] - ETA: 3s - loss: 0.0454 - acc: 0.948811/75 [===&gt;..........................] - ETA: 3s - loss: 0.0445 - acc: 0.949113/75 [====&gt;.........................] - ETA: 3s - loss: 0.0432 - acc: 0.949414/75 [====&gt;.........................] - ETA: 3s - loss: 0.0423 - acc: 0.950316/75 [=====&gt;........................] - ETA: 3s - loss: 0.0409 - acc: 0.953017/75 [=====&gt;........................] - ETA: 3s - loss: 0.0402 - acc: 0.953618/75 [======&gt;.......................] - ETA: 2s - loss: 0.0395 - acc: 0.954519/75 [======&gt;.......................] - ETA: 2s - loss: 0.0388 - acc: 0.955720/75 [=======&gt;......................] - ETA: 2s - loss: 0.0381 - acc: 0.956721/75 [=======&gt;......................] - ETA: 2s - loss: 0.0374 - acc: 0.957322/75 [=======&gt;......................] - ETA: 2s - loss: 0.0369 - acc: 0.957623/75 [========&gt;.....................] - ETA: 2s - loss: 0.0364 - acc: 0.958525/75 [=========&gt;....................] - ETA: 2s - loss: 0.0352 - acc: 0.960426/75 [=========&gt;....................] - ETA: 2s - loss: 0.0346 - acc: 0.961527/75 [=========&gt;....................] - ETA: 2s - loss: 0.0341 - acc: 0.962228/75 [==========&gt;...................] - ETA: 2s - loss: 0.0338 - acc: 0.962829/75 [==========&gt;...................] - ETA: 2s - loss: 0.0332 - acc: 0.963731/75 [===========&gt;..................] - ETA: 2s - loss: 0.0327 - acc: 0.964432/75 [===========&gt;..................] - ETA: 2s - loss: 0.0322 - acc: 0.964934/75 [============&gt;.................] - ETA: 2s - loss: 0.0314 - acc: 0.965835/75 [=============&gt;................] - ETA: 2s - loss: 0.0311 - acc: 0.966037/75 [=============&gt;................] - ETA: 1s - loss: 0.0302 - acc: 0.967138/75 [==============&gt;...............] - ETA: 1s - loss: 0.0299 - acc: 0.967540/75 [===============&gt;..............] - ETA: 1s - loss: 0.0295 - acc: 0.967841/75 [===============&gt;..............] - ETA: 1s - loss: 0.0292 - acc: 0.968042/75 [===============&gt;..............] - ETA: 1s - loss: 0.0289 - acc: 0.968543/75 [================&gt;.............] - ETA: 1s - loss: 0.0287 - acc: 0.968944/75 [================&gt;.............] - ETA: 1s - loss: 0.0285 - acc: 0.969045/75 [=================&gt;............] - ETA: 1s - loss: 0.0282 - acc: 0.969246/75 [=================&gt;............] - ETA: 1s - loss: 0.0279 - acc: 0.969647/75 [=================&gt;............] - ETA: 1s - loss: 0.0277 - acc: 0.970048/75 [==================&gt;...........] - ETA: 1s - loss: 0.0274 - acc: 0.970449/75 [==================&gt;...........] - ETA: 1s - loss: 0.0270 - acc: 0.970750/75 [===================&gt;..........] - ETA: 1s - loss: 0.0268 - acc: 0.970851/75 [===================&gt;..........] - ETA: 1s - loss: 0.0266 - acc: 0.971152/75 [===================&gt;..........] - ETA: 1s - loss: 0.0265 - acc: 0.971354/75 [====================&gt;.........] - ETA: 1s - loss: 0.0260 - acc: 0.971855/75 [=====================&gt;........] - ETA: 1s - loss: 0.0257 - acc: 0.972156/75 [=====================&gt;........] - ETA: 0s - loss: 0.0254 - acc: 0.972557/75 [=====================&gt;........] - ETA: 0s - loss: 0.0252 - acc: 0.972958/75 [======================&gt;.......] - ETA: 0s - loss: 0.0250 - acc: 0.973059/75 [======================&gt;.......] - ETA: 0s - loss: 0.0249 - acc: 0.973060/75 [=======================&gt;......] - ETA: 0s - loss: 0.0249 - acc: 0.973061/75 [=======================&gt;......] - ETA: 0s - loss: 0.0248 - acc: 0.973163/75 [========================&gt;.....] - ETA: 0s - loss: 0.0244 - acc: 0.973464/75 [========================&gt;.....] - ETA: 0s - loss: 0.0243 - acc: 0.973465/75 [=========================&gt;....] - ETA: 0s - loss: 0.0244 - acc: 0.973466/75 [=========================&gt;....] - ETA: 0s - loss: 0.0242 - acc: 0.973567/75 [=========================&gt;....] - ETA: 0s - loss: 0.0241 - acc: 0.973769/75 [==========================&gt;...] - ETA: 0s - loss: 0.0237 - acc: 0.974170/75 [===========================&gt;..] - ETA: 0s - loss: 0.0237 - acc: 0.973971/75 [===========================&gt;..] - ETA: 0s - loss: 0.0237 - acc: 0.973972/75 [===========================&gt;..] - ETA: 0s - loss: 0.0236 - acc: 0.973973/75 [============================&gt;.] - ETA: 0s - loss: 0.0235 - acc: 0.973975/75 [==============================] - ETA: 0s - loss: 0.0233 - acc: 0.974175/75 [==============================] - 4s 54ms/step - loss: 0.0233 - acc: 0.9741 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 6/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.0138 - acc: 0.9798 2/75 [..............................] - ETA: 3s - loss: 0.0124 - acc: 0.9839 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0128 - acc: 0.9842 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0129 - acc: 0.9837 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0120 - acc: 0.9845 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0120 - acc: 0.9844 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0120 - acc: 0.9841 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0121 - acc: 0.9842 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0125 - acc: 0.984310/75 [===&gt;..........................] - ETA: 3s - loss: 0.0133 - acc: 0.983311/75 [===&gt;..........................] - ETA: 3s - loss: 0.0129 - acc: 0.983912/75 [===&gt;..........................] - ETA: 3s - loss: 0.0124 - acc: 0.984714/75 [====&gt;.........................] - ETA: 3s - loss: 0.0123 - acc: 0.985315/75 [=====&gt;........................] - ETA: 3s - loss: 0.0120 - acc: 0.985616/75 [=====&gt;........................] - ETA: 3s - loss: 0.0119 - acc: 0.985917/75 [=====&gt;........................] - ETA: 3s - loss: 0.0117 - acc: 0.986218/75 [======&gt;.......................] - ETA: 2s - loss: 0.0115 - acc: 0.986419/75 [======&gt;.......................] - ETA: 2s - loss: 0.0117 - acc: 0.986220/75 [=======&gt;......................] - ETA: 2s - loss: 0.0120 - acc: 0.986021/75 [=======&gt;......................] - ETA: 2s - loss: 0.0118 - acc: 0.986322/75 [=======&gt;......................] - ETA: 2s - loss: 0.0119 - acc: 0.986023/75 [========&gt;.....................] - ETA: 2s - loss: 0.0121 - acc: 0.985824/75 [========&gt;.....................] - ETA: 2s - loss: 0.0121 - acc: 0.985825/75 [=========&gt;....................] - ETA: 2s - loss: 0.0120 - acc: 0.986026/75 [=========&gt;....................] - ETA: 2s - loss: 0.0121 - acc: 0.985927/75 [=========&gt;....................] - ETA: 2s - loss: 0.0120 - acc: 0.986028/75 [==========&gt;...................] - ETA: 2s - loss: 0.0119 - acc: 0.986129/75 [==========&gt;...................] - ETA: 2s - loss: 0.0119 - acc: 0.986130/75 [===========&gt;..................] - ETA: 2s - loss: 0.0118 - acc: 0.986132/75 [===========&gt;..................] - ETA: 2s - loss: 0.0117 - acc: 0.986233/75 [============&gt;.................] - ETA: 2s - loss: 0.0117 - acc: 0.986235/75 [=============&gt;................] - ETA: 2s - loss: 0.0117 - acc: 0.986236/75 [=============&gt;................] - ETA: 2s - loss: 0.0117 - acc: 0.986237/75 [=============&gt;................] - ETA: 1s - loss: 0.0116 - acc: 0.986338/75 [==============&gt;...............] - ETA: 1s - loss: 0.0119 - acc: 0.985839/75 [==============&gt;...............] - ETA: 1s - loss: 0.0119 - acc: 0.985841/75 [===============&gt;..............] - ETA: 1s - loss: 0.0119 - acc: 0.985742/75 [===============&gt;..............] - ETA: 1s - loss: 0.0119 - acc: 0.985843/75 [================&gt;.............] - ETA: 1s - loss: 0.0120 - acc: 0.985744/75 [================&gt;.............] - ETA: 1s - loss: 0.0120 - acc: 0.985546/75 [=================&gt;............] - ETA: 1s - loss: 0.0119 - acc: 0.985447/75 [=================&gt;............] - ETA: 1s - loss: 0.0119 - acc: 0.985449/75 [==================&gt;...........] - ETA: 1s - loss: 0.0117 - acc: 0.985650/75 [===================&gt;..........] - ETA: 1s - loss: 0.0117 - acc: 0.985752/75 [===================&gt;..........] - ETA: 1s - loss: 0.0116 - acc: 0.985853/75 [====================&gt;.........] - ETA: 1s - loss: 0.0116 - acc: 0.985755/75 [=====================&gt;........] - ETA: 1s - loss: 0.0116 - acc: 0.985556/75 [=====================&gt;........] - ETA: 0s - loss: 0.0116 - acc: 0.985357/75 [=====================&gt;........] - ETA: 0s - loss: 0.0116 - acc: 0.985358/75 [======================&gt;.......] - ETA: 0s - loss: 0.0117 - acc: 0.985259/75 [======================&gt;.......] - ETA: 0s - loss: 0.0116 - acc: 0.985360/75 [=======================&gt;......] - ETA: 0s - loss: 0.0116 - acc: 0.985461/75 [=======================&gt;......] - ETA: 0s - loss: 0.0117 - acc: 0.985262/75 [=======================&gt;......] - ETA: 0s - loss: 0.0116 - acc: 0.985263/75 [========================&gt;.....] - ETA: 0s - loss: 0.0115 - acc: 0.985364/75 [========================&gt;.....] - ETA: 0s - loss: 0.0115 - acc: 0.985365/75 [=========================&gt;....] - ETA: 0s - loss: 0.0115 - acc: 0.985467/75 [=========================&gt;....] - ETA: 0s - loss: 0.0114 - acc: 0.985468/75 [==========================&gt;...] - ETA: 0s - loss: 0.0114 - acc: 0.985469/75 [==========================&gt;...] - ETA: 0s - loss: 0.0113 - acc: 0.985470/75 [===========================&gt;..] - ETA: 0s - loss: 0.0113 - acc: 0.985571/75 [===========================&gt;..] - ETA: 0s - loss: 0.0113 - acc: 0.985572/75 [===========================&gt;..] - ETA: 0s - loss: 0.0113 - acc: 0.985573/75 [============================&gt;.] - ETA: 0s - loss: 0.0113 - acc: 0.985574/75 [============================&gt;.] - ETA: 0s - loss: 0.0113 - acc: 0.985475/75 [==============================] - 4s 52ms/step - loss: 0.0112 - acc: 0.9855 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 7/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.0119 - acc: 0.9824 2/75 [..............................] - ETA: 4s - loss: 0.0127 - acc: 0.9810 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0114 - acc: 0.9831 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0109 - acc: 0.9847 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0098 - acc: 0.9863 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0095 - acc: 0.9868 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0091 - acc: 0.9872 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0092 - acc: 0.986810/75 [===&gt;..........................] - ETA: 3s - loss: 0.0091 - acc: 0.986911/75 [===&gt;..........................] - ETA: 3s - loss: 0.0091 - acc: 0.987012/75 [===&gt;..........................] - ETA: 3s - loss: 0.0088 - acc: 0.987713/75 [====&gt;.........................] - ETA: 3s - loss: 0.0086 - acc: 0.988015/75 [=====&gt;........................] - ETA: 3s - loss: 0.0086 - acc: 0.987516/75 [=====&gt;........................] - ETA: 3s - loss: 0.0086 - acc: 0.987617/75 [=====&gt;........................] - ETA: 3s - loss: 0.0086 - acc: 0.987718/75 [======&gt;.......................] - ETA: 3s - loss: 0.0087 - acc: 0.987619/75 [======&gt;.......................] - ETA: 3s - loss: 0.0088 - acc: 0.987520/75 [=======&gt;......................] - ETA: 2s - loss: 0.0087 - acc: 0.987721/75 [=======&gt;......................] - ETA: 2s - loss: 0.0088 - acc: 0.987722/75 [=======&gt;......................] - ETA: 2s - loss: 0.0087 - acc: 0.987923/75 [========&gt;.....................] - ETA: 2s - loss: 0.0087 - acc: 0.987924/75 [========&gt;.....................] - ETA: 2s - loss: 0.0088 - acc: 0.987825/75 [=========&gt;....................] - ETA: 2s - loss: 0.0087 - acc: 0.988027/75 [=========&gt;....................] - ETA: 2s - loss: 0.0087 - acc: 0.988028/75 [==========&gt;...................] - ETA: 2s - loss: 0.0087 - acc: 0.987929/75 [==========&gt;...................] - ETA: 2s - loss: 0.0086 - acc: 0.988130/75 [===========&gt;..................] - ETA: 2s - loss: 0.0087 - acc: 0.988031/75 [===========&gt;..................] - ETA: 2s - loss: 0.0087 - acc: 0.988032/75 [===========&gt;..................] - ETA: 2s - loss: 0.0088 - acc: 0.988033/75 [============&gt;.................] - ETA: 2s - loss: 0.0087 - acc: 0.988134/75 [============&gt;.................] - ETA: 2s - loss: 0.0089 - acc: 0.987935/75 [=============&gt;................] - ETA: 2s - loss: 0.0088 - acc: 0.988136/75 [=============&gt;................] - ETA: 2s - loss: 0.0089 - acc: 0.988037/75 [=============&gt;................] - ETA: 2s - loss: 0.0089 - acc: 0.987838/75 [==============&gt;...............] - ETA: 1s - loss: 0.0091 - acc: 0.987639/75 [==============&gt;...............] - ETA: 1s - loss: 0.0091 - acc: 0.987640/75 [===============&gt;..............] - ETA: 1s - loss: 0.0091 - acc: 0.987741/75 [===============&gt;..............] - ETA: 1s - loss: 0.0093 - acc: 0.987542/75 [===============&gt;..............] - ETA: 1s - loss: 0.0094 - acc: 0.987443/75 [================&gt;.............] - ETA: 1s - loss: 0.0094 - acc: 0.987444/75 [================&gt;.............] - ETA: 1s - loss: 0.0095 - acc: 0.987445/75 [=================&gt;............] - ETA: 1s - loss: 0.0096 - acc: 0.987347/75 [=================&gt;............] - ETA: 1s - loss: 0.0096 - acc: 0.987248/75 [==================&gt;...........] - ETA: 1s - loss: 0.0098 - acc: 0.987049/75 [==================&gt;...........] - ETA: 1s - loss: 0.0099 - acc: 0.986950/75 [===================&gt;..........] - ETA: 1s - loss: 0.0099 - acc: 0.986951/75 [===================&gt;..........] - ETA: 1s - loss: 0.0099 - acc: 0.986953/75 [====================&gt;.........] - ETA: 1s - loss: 0.0100 - acc: 0.986854/75 [====================&gt;.........] - ETA: 1s - loss: 0.0100 - acc: 0.986855/75 [=====================&gt;........] - ETA: 1s - loss: 0.0101 - acc: 0.986656/75 [=====================&gt;........] - ETA: 1s - loss: 0.0100 - acc: 0.986757/75 [=====================&gt;........] - ETA: 0s - loss: 0.0100 - acc: 0.986759/75 [======================&gt;.......] - ETA: 0s - loss: 0.0099 - acc: 0.986960/75 [=======================&gt;......] - ETA: 0s - loss: 0.0099 - acc: 0.986961/75 [=======================&gt;......] - ETA: 0s - loss: 0.0099 - acc: 0.986862/75 [=======================&gt;......] - ETA: 0s - loss: 0.0099 - acc: 0.986863/75 [========================&gt;.....] - ETA: 0s - loss: 0.0098 - acc: 0.986965/75 [=========================&gt;....] - ETA: 0s - loss: 0.0098 - acc: 0.987066/75 [=========================&gt;....] - ETA: 0s - loss: 0.0098 - acc: 0.986967/75 [=========================&gt;....] - ETA: 0s - loss: 0.0097 - acc: 0.987068/75 [==========================&gt;...] - ETA: 0s - loss: 0.0097 - acc: 0.986969/75 [==========================&gt;...] - ETA: 0s - loss: 0.0097 - acc: 0.986870/75 [===========================&gt;..] - ETA: 0s - loss: 0.0097 - acc: 0.986871/75 [===========================&gt;..] - ETA: 0s - loss: 0.0097 - acc: 0.986972/75 [===========================&gt;..] - ETA: 0s - loss: 0.0097 - acc: 0.986973/75 [============================&gt;.] - ETA: 0s - loss: 0.0097 - acc: 0.986774/75 [============================&gt;.] - ETA: 0s - loss: 0.0097 - acc: 0.986775/75 [==============================] - 4s 53ms/step - loss: 0.0097 - acc: 0.9867 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 8/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.0139 - acc: 0.9796 2/75 [..............................] - ETA: 3s - loss: 0.0130 - acc: 0.9816 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0108 - acc: 0.9845 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0094 - acc: 0.9857 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0097 - acc: 0.9856 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0097 - acc: 0.9860 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0093 - acc: 0.9865 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0091 - acc: 0.986910/75 [===&gt;..........................] - ETA: 3s - loss: 0.0091 - acc: 0.987111/75 [===&gt;..........................] - ETA: 3s - loss: 0.0094 - acc: 0.986512/75 [===&gt;..........................] - ETA: 3s - loss: 0.0094 - acc: 0.986513/75 [====&gt;.........................] - ETA: 3s - loss: 0.0096 - acc: 0.985714/75 [====&gt;.........................] - ETA: 3s - loss: 0.0096 - acc: 0.985716/75 [=====&gt;........................] - ETA: 3s - loss: 0.0097 - acc: 0.985917/75 [=====&gt;........................] - ETA: 3s - loss: 0.0095 - acc: 0.986018/75 [======&gt;.......................] - ETA: 3s - loss: 0.0095 - acc: 0.986219/75 [======&gt;.......................] - ETA: 2s - loss: 0.0095 - acc: 0.986520/75 [=======&gt;......................] - ETA: 2s - loss: 0.0095 - acc: 0.986622/75 [=======&gt;......................] - ETA: 2s - loss: 0.0093 - acc: 0.987023/75 [========&gt;.....................] - ETA: 2s - loss: 0.0093 - acc: 0.987224/75 [========&gt;.....................] - ETA: 2s - loss: 0.0093 - acc: 0.987225/75 [=========&gt;....................] - ETA: 2s - loss: 0.0095 - acc: 0.987126/75 [=========&gt;....................] - ETA: 2s - loss: 0.0094 - acc: 0.987428/75 [==========&gt;...................] - ETA: 2s - loss: 0.0092 - acc: 0.987829/75 [==========&gt;...................] - ETA: 2s - loss: 0.0093 - acc: 0.987731/75 [===========&gt;..................] - ETA: 2s - loss: 0.0090 - acc: 0.988132/75 [===========&gt;..................] - ETA: 2s - loss: 0.0089 - acc: 0.988233/75 [============&gt;.................] - ETA: 2s - loss: 0.0090 - acc: 0.988034/75 [============&gt;.................] - ETA: 2s - loss: 0.0089 - acc: 0.987935/75 [=============&gt;................] - ETA: 2s - loss: 0.0089 - acc: 0.988136/75 [=============&gt;................] - ETA: 2s - loss: 0.0089 - acc: 0.987937/75 [=============&gt;................] - ETA: 2s - loss: 0.0089 - acc: 0.987938/75 [==============&gt;...............] - ETA: 1s - loss: 0.0089 - acc: 0.987839/75 [==============&gt;...............] - ETA: 1s - loss: 0.0090 - acc: 0.987640/75 [===============&gt;..............] - ETA: 1s - loss: 0.0090 - acc: 0.987542/75 [===============&gt;..............] - ETA: 1s - loss: 0.0089 - acc: 0.987743/75 [================&gt;.............] - ETA: 1s - loss: 0.0090 - acc: 0.987744/75 [================&gt;.............] - ETA: 1s - loss: 0.0089 - acc: 0.987845/75 [=================&gt;............] - ETA: 1s - loss: 0.0089 - acc: 0.987846/75 [=================&gt;............] - ETA: 1s - loss: 0.0089 - acc: 0.987847/75 [=================&gt;............] - ETA: 1s - loss: 0.0089 - acc: 0.987948/75 [==================&gt;...........] - ETA: 1s - loss: 0.0089 - acc: 0.987849/75 [==================&gt;...........] - ETA: 1s - loss: 0.0089 - acc: 0.987850/75 [===================&gt;..........] - ETA: 1s - loss: 0.0088 - acc: 0.987951/75 [===================&gt;..........] - ETA: 1s - loss: 0.0088 - acc: 0.988052/75 [===================&gt;..........] - ETA: 1s - loss: 0.0088 - acc: 0.988054/75 [====================&gt;.........] - ETA: 1s - loss: 0.0088 - acc: 0.988155/75 [=====================&gt;........] - ETA: 1s - loss: 0.0088 - acc: 0.988056/75 [=====================&gt;........] - ETA: 0s - loss: 0.0089 - acc: 0.987857/75 [=====================&gt;........] - ETA: 0s - loss: 0.0089 - acc: 0.987858/75 [======================&gt;.......] - ETA: 0s - loss: 0.0089 - acc: 0.987959/75 [======================&gt;.......] - ETA: 0s - loss: 0.0089 - acc: 0.987960/75 [=======================&gt;......] - ETA: 0s - loss: 0.0089 - acc: 0.987961/75 [=======================&gt;......] - ETA: 0s - loss: 0.0088 - acc: 0.988063/75 [========================&gt;.....] - ETA: 0s - loss: 0.0088 - acc: 0.988164/75 [========================&gt;.....] - ETA: 0s - loss: 0.0088 - acc: 0.988165/75 [=========================&gt;....] - ETA: 0s - loss: 0.0088 - acc: 0.988166/75 [=========================&gt;....] - ETA: 0s - loss: 0.0088 - acc: 0.988167/75 [=========================&gt;....] - ETA: 0s - loss: 0.0087 - acc: 0.988268/75 [==========================&gt;...] - ETA: 0s - loss: 0.0087 - acc: 0.988169/75 [==========================&gt;...] - ETA: 0s - loss: 0.0087 - acc: 0.988170/75 [===========================&gt;..] - ETA: 0s - loss: 0.0087 - acc: 0.988171/75 [===========================&gt;..] - ETA: 0s - loss: 0.0087 - acc: 0.988272/75 [===========================&gt;..] - ETA: 0s - loss: 0.0087 - acc: 0.988374/75 [============================&gt;.] - ETA: 0s - loss: 0.0087 - acc: 0.988375/75 [==============================] - ETA: 0s - loss: 0.0086 - acc: 0.988475/75 [==============================] - 4s 53ms/step - loss: 0.0086 - acc: 0.9884 - lr: 0.0050</span></span></code></pre>
<pre><code><span><span class="co">## Training done.</span></span></code></pre>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<p>Evaluate the trained model.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gen</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/get_generator.html">get_generator</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>                      train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>                      masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>                      batch_size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram_stride <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      return_int <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                      maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu">gen</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">sw</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">model</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">## 1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 107ms/step</span></span></code></pre>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">pred</span><span class="op">[</span><span class="fl">1</span>,,<span class="op">]</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span> </span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, sw <span class="op">=</span> <span class="va">sw</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, pred <span class="op">=</span> <span class="va">pred</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   x sw y pred</span></span>
<span><span class="co">## 1 5  1 1    1</span></span>
<span><span class="co">## 2 1  0 1    1</span></span>
<span><span class="co">## 3 1  0 1    1</span></span>
<span><span class="co">## 4 1  0 1    1</span></span>
<span><span class="co">## 5 1  0 1    1</span></span>
<span><span class="co">## 6 1  0 1    1</span></span></code></pre>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    x sw y pred</span></span>
<span><span class="co">## 1  5  1 1    1</span></span>
<span><span class="co">## 7  5  1 1    1</span></span>
<span><span class="co">## 14 5  1 1    1</span></span>
<span><span class="co">## 21 1  1 1    1</span></span>
<span><span class="co">## 34 5  1 2    2</span></span>
<span><span class="co">## 43 2  1 2    2</span></span>
<span><span class="co">## 51 4  1 3    3</span></span>
<span><span class="co">## 54 5  1 3    3</span></span>
<span><span class="co">## 59 3  1 3    3</span></span>
<span><span class="co">## 73 5  1 3    3</span></span>
<span><span class="co">## 74 5  1 3    3</span></span>
<span><span class="co">## 79 5  1 4    4</span></span>
<span><span class="co">## 82 5  1 4    4</span></span>
<span><span class="co">## 85 5  1 4    4</span></span>
<span><span class="co">## 87 2  1 4    4</span></span></code></pre>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df2</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">df2</span><span class="op">$</span><span class="va">pred</span>, <span class="va">df2</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     1 2 3 4</span></span>
<span><span class="co">##   1 4 0 0 0</span></span>
<span><span class="co">##   2 0 2 0 0</span></span>
<span><span class="co">##   3 0 0 5 0</span></span>
<span><span class="co">##   4 0 0 0 4</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="label-classification">Label classification<a class="anchor" aria-label="anchor" href="#label-classification"></a>
</h2>
<p>With label classification, we describe the task of mapping a label to
a sequence. For example: given the input <tt>ACGACCG</tt>, does the
sequence belong to a viral or bacterial genome?</p>
<p>deepG offers three options to map a label to a sequence</p>
<ol style="list-style-type: decimal">
<li><p>the label gets read from the fasta header</p></li>
<li><p>files from every class are in separate folders</p></li>
<li><p>get label from csv file</p></li>
</ol>
<div class="section level3">
<h3 id="create-dummy-data-1">Create dummy data<a class="anchor" aria-label="anchor" href="#create-dummy-data-1"></a>
</h3>
<p>To test label classification, we create a simple dummy data set. One
class consists of random sequences using just <tt>A</tt> and <tt>C</tt>
and second class uses just <tt>G</tt> and <tt>T</tt>.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create training fasta files</span></span>
<span><span class="va">train_dir_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">train_dir_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir_1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir_2</span><span class="op">)</span></span>
<span><span class="va">train_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="va">train_dir_2</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_1"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_1_train_file"</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_2"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_2_train_file"</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/create_dummy_data.html">create_dummy_data</a></span><span class="op">(</span>file_path <span class="op">=</span> <span class="va">train_dir</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                    num_files <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                    seq_length <span class="op">=</span> <span class="fl">20</span>, </span>
<span>                    num_seq <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    header <span class="op">=</span> <span class="va">header</span>,</span>
<span>                    fasta_name_start <span class="op">=</span> <span class="va">fasta_name_start</span>,</span>
<span>                    vocabulary <span class="op">=</span> <span class="va">vocabulary</span><span class="op">)</span></span>
<span><span class="op">}</span>  </span>
<span></span>
<span><span class="co"># create validation fasta files</span></span>
<span><span class="va">val_dir_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">val_dir_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir_1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir_2</span><span class="op">)</span></span>
<span><span class="va">val_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">val_dir_1</span>, <span class="va">val_dir_2</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_1"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_1_val_file"</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_2"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_2_val_file"</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/create_dummy_data.html">create_dummy_data</a></span><span class="op">(</span>file_path <span class="op">=</span> <span class="va">val_dir</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                    num_files <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                    seq_length <span class="op">=</span> <span class="fl">20</span>, </span>
<span>                    num_seq <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    header <span class="op">=</span> <span class="va">header</span>,</span>
<span>                    fasta_name_start <span class="op">=</span> <span class="va">fasta_name_start</span>,</span>
<span>                    vocabulary <span class="op">=</span> <span class="va">vocabulary</span><span class="op">)</span></span>
<span><span class="op">}</span>  </span></code></pre></div>
</div>
<div class="section level3">
<h3 id="label-by-folder">Label by folder<a class="anchor" aria-label="anchor" href="#label-by-folder"></a>
</h3>
<p>In this approach, we put all data from one class into a separate
folder. Say we want to classify if a sequence belongs to a viral or
bacterial genome. We may put all virus and bacteria files into their own
folder. In this case the <code>path</code> and <code>path_val</code>
arguments should be vectors, where each entry is the path to one
class.</p>
<p>First we have to create a model. We may use a model with 1 LSTM and 1
dense layer for predictions. An input sequence has length 5.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># binary classification</span></span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> <span class="co"># text consists of A,C,G,T</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_3"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_5 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm_3 (LSTM)               (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense_5 (Dense)             (None, 2)                 18        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 434 (1.70 KB)</span></span>
<span><span class="co">## Trainable params: 434 (1.70 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_folder"</span>, <span class="co"># reading label from folder  </span></span>
<span>            model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            path <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="co"># note that path has two entries </span></span>
<span>                     <span class="va">train_dir_2</span><span class="op">)</span>,</span>
<span>            path_val <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">val_dir_1</span>,</span>
<span>                         <span class="va">val_dir_2</span><span class="op">)</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>            train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span>            batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">2</span>,</span>
<span>            vocabulary_label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label_1"</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="co"># names of classes</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 3s - loss: 0.7256 - acc: 0.37505/5 [==============================] - 1s 65ms/step - loss: 0.3478 - acc: 0.8750 - val_loss: 0.0136 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0138 - acc: 1.00005/5 [==============================] - 0s 19ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 3.3623e-04 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Final epoch (plot to see history):</span></span>
<span><span class="co">##     loss: 0.005179</span></span>
<span><span class="co">##      acc: 1</span></span>
<span><span class="co">## val_loss: 0.0003362</span></span>
<span><span class="co">##  val_acc: 1</span></span>
<span><span class="co">##       lr: 0.1</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="label-by-fasta-header">Label by fasta header<a class="anchor" aria-label="anchor" href="#label-by-fasta-header"></a>
</h3>
<p>The fasta headers in our dummy data have the names “label_1” or
“label_2”</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="va">train_dir_1</span>, full.names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">fasta_file</span> <span class="op">&lt;-</span> <span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">readFasta</a></span><span class="op">(</span><span class="va">files</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">fasta_file</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 5 × 2</span></span></span>
<span><span class="co">##   Header  Sequence            </span></span>
<span><span class="co">##   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>               </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> label_1 CCCACCCCCAACACCAACCC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">2</span> label_1 AACCCCCCACCCCAAACCAA</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">3</span> label_1 CCCAAACACACAACCAAACC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">4</span> label_1 ACCCAAAACAAAAACCCCAC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">5</span> label_1 CCCAACAACCAAACACACCC</span></span></code></pre>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_header"</span>, <span class="co"># reading label from fasta header  </span></span>
<span>            model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>            path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, </span>
<span>            train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span>            batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">2</span>,</span>
<span>            vocabulary_label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label_1"</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="co"># names of labels</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 3.7113e-04 - acc: 1.00005/5 [==============================] - 0s 23ms/step - loss: 1.8041e-04 - acc: 1.0000 - val_loss: 2.8997e-05 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 2.9146e-05 - acc: 1.00005/5 [==============================] - ETA: 0s - loss: 2.7459e-05 - acc: 1.00005/5 [==============================] - 0s 26ms/step - loss: 2.7459e-05 - acc: 1.0000 - val_loss: 2.3991e-05 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Final epoch (plot to see history):</span></span>
<span><span class="co">##     loss: 0.00002746</span></span>
<span><span class="co">##      acc: 1</span></span>
<span><span class="co">## val_loss: 0.00002399</span></span>
<span><span class="co">##  val_acc: 1</span></span>
<span><span class="co">##       lr: 0.1</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="label-from-csv-file">Label from csv file<a class="anchor" aria-label="anchor" href="#label-from-csv-file"></a>
</h3>
<p>In this approach we extract the sequence label by mapping the current
file name to a csv table.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">files_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="va">val_dir_1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">files_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_2</span>, <span class="va">val_dir_2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">files_1</span>, <span class="va">files_2</span><span class="op">)</span></span>
<span><span class="va">label_1</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_detect.html" class="external-link">str_detect</a></span><span class="op">(</span><span class="va">file</span>, <span class="st">"label_1"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">label_2</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_detect.html" class="external-link">str_detect</a></span><span class="op">(</span><span class="va">file</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">file</span>, <span class="va">label_1</span>, <span class="va">label_2</span><span class="op">)</span></span>
<span><span class="va">df</span></span></code></pre></div>
<pre><code><span><span class="co">##                          file label_1 label_2</span></span>
<span><span class="co">## 1  label_1_train_file_1.fasta       1       0</span></span>
<span><span class="co">## 2  label_1_train_file_2.fasta       1       0</span></span>
<span><span class="co">## 3  label_1_train_file_3.fasta       1       0</span></span>
<span><span class="co">## 4    label_1_val_file_1.fasta       1       0</span></span>
<span><span class="co">## 5    label_1_val_file_2.fasta       1       0</span></span>
<span><span class="co">## 6    label_1_val_file_3.fasta       1       0</span></span>
<span><span class="co">## 7  label_2_train_file_1.fasta       0       1</span></span>
<span><span class="co">## 8  label_2_train_file_2.fasta       0       1</span></span>
<span><span class="co">## 9  label_2_train_file_3.fasta       0       1</span></span>
<span><span class="co">## 10   label_2_val_file_1.fasta       0       1</span></span>
<span><span class="co">## 11   label_2_val_file_2.fasta       0       1</span></span>
<span><span class="co">## 12   label_2_val_file_3.fasta       0       1</span></span></code></pre>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">csv_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span>fileext <span class="op">=</span> <span class="st">".csv"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/write.table.html" class="external-link">write.csv</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">csv_path</span>, row.names <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_csv"</span>,</span>
<span>                    target_from_csv <span class="op">=</span> <span class="va">csv_path</span>,</span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>                    batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 5.9455e-06 - acc: 1.00005/5 [==============================] - 0s 22ms/step - loss: 1.0404e-05 - acc: 1.0000 - val_loss: 2.2948e-06 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 2.2650e-06 - acc: 1.00005/5 [==============================] - 0s 24ms/step - loss: 5.9783e-06 - acc: 1.0000 - val_loss: 8.8363e-06 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="training-with-rds-files">Training with rds files<a class="anchor" aria-label="anchor" href="#training-with-rds-files"></a>
</h3>
<p>We can also use rds files files as input, where the data must already
be preprocessed. We may use the <code>dataset_from_gen</code> function
to create rds files from fasta files.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rds_folder_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">rds_folder_val</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">rds_folder_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">rds_folder_val</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">data_type</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"train"</span>, <span class="st">"val"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">data_type</span> <span class="op">==</span> <span class="st">"train"</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">output_path</span> <span class="op">&lt;-</span> <span class="va">rds_folder_train</span></span>
<span>    <span class="va">path_corpus</span> <span class="op">&lt;-</span> <span class="va">train_dir</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">output_path</span> <span class="op">&lt;-</span> <span class="va">rds_folder_val</span></span>
<span>    <span class="va">path_corpus</span> <span class="op">&lt;-</span> <span class="va">val_dir</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/dataset_from_gen.html">dataset_from_gen</a></span><span class="op">(</span>output_path <span class="op">=</span> <span class="va">output_path</span>,</span>
<span>                   iterations <span class="op">=</span> <span class="fl">25</span>, <span class="co"># create 25 rds files </span></span>
<span>                   train_type <span class="op">=</span> <span class="st">"label_folder"</span>,</span>
<span>                   path_corpus <span class="op">=</span> <span class="va">path_corpus</span>, </span>
<span>                   batch_size <span class="op">=</span> <span class="fl">128</span>,</span>
<span>                   maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                   step <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                   vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"c"</span>, <span class="st">"g"</span>, <span class="st">"t"</span><span class="op">)</span>,</span>
<span>                   file_name_start <span class="op">=</span> <span class="st">"batch_"</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre></div>
<p>We created 25 files for training and validation with preprocessed
data.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">train_files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="va">rds_folder_train</span>, full.names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="va">train_files</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  [1] "batch_1.rds"  "batch_10.rds" "batch_11.rds" "batch_12.rds" "batch_13.rds"</span></span>
<span><span class="co">##  [6] "batch_14.rds" "batch_15.rds" "batch_16.rds" "batch_17.rds" "batch_18.rds"</span></span>
<span><span class="co">## [11] "batch_19.rds" "batch_2.rds"  "batch_20.rds" "batch_21.rds" "batch_22.rds"</span></span>
<span><span class="co">## [16] "batch_23.rds" "batch_24.rds" "batch_25.rds" "batch_3.rds"  "batch_4.rds" </span></span>
<span><span class="co">## [21] "batch_5.rds"  "batch_6.rds"  "batch_7.rds"  "batch_8.rds"  "batch_9.rds"</span></span></code></pre>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html" class="external-link">readRDS</a></span><span class="op">(</span><span class="va">train_files</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">example_batch</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">example_batch</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 128   5   4</span></span></code></pre>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 128   2</span></span></code></pre>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span><span class="op">[</span><span class="fl">1</span>,,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##      [,1] [,2] [,3] [,4]</span></span>
<span><span class="co">## [1,]    0    1    0    0</span></span>
<span><span class="co">## [2,]    0    1    0    0</span></span>
<span><span class="co">## [3,]    0    1    0    0</span></span>
<span><span class="co">## [4,]    1    0    0    0</span></span>
<span><span class="co">## [5,]    0    1    0    0</span></span></code></pre>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1 0</span></span></code></pre>
<p>We can now use these files for training.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_4"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_6 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm_4 (LSTM)               (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense_6 (Dense)             (None, 2)                 18        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 434 (1.70 KB)</span></span>
<span><span class="co">## Trainable params: 434 (1.70 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_rds"</span>,</span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">rds_folder_train</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">rds_folder_val</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    format <span class="op">=</span> <span class="st">"rds"</span>,</span>
<span>                    batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 2s - loss: 0.6628 - acc: 0.75005/5 [==============================] - 1s 59ms/step - loss: 0.3644 - acc: 0.8250 - val_loss: 0.0381 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0248 - acc: 1.00005/5 [==============================] - 0s 13ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 3.0245e-04 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

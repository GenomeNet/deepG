<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="deepG">
<title>Training Types • deepG</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Training Types">
<meta property="og:description" content="deepG">
<meta property="og:image" content="https://genomenet.github.io/deepG/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">deepG</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.3.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">
    <span class="fa fa fa fa-file-alt"></span>
     
    Reference
  </a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-notebooks">Notebooks</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-notebooks">
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing">deepG tutorial</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing">Read-length level: Human contamination</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing">Locus level: CRISPR detection</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing">Gene level: 16S rRNA detection</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing">Genome level: Bacterial morphology (Sporulation)</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing">Full metagenome level: Colorectal cancer prediction</a>
    <a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing">BERT with deepG</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../tutorial_html/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../tutorial_html/training_types.html">Training types</a>
    <a class="dropdown-item" href="../tutorial_html/data_generator.html">Data generator</a>
    <a class="dropdown-item" href="../tutorial_html/using_tb.html">Using tensorboard</a>
    <a class="dropdown-item" href="../tutorial_html/integrated_gradient.html">Integrated Gradient</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/GenomeNet/deepG/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Training Types</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/HEAD/vignettes/training_types.Rmd" class="external-link"><code>vignettes/training_types.Rmd</code></a></small>
      <div class="d-none name"><code>training_types.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#devtools::install_github("GenomeNet/deepG")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/GenomeNet/deepG" class="external-link">deepG</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org" class="external-link">magrittr</a></span><span class="op">)</span></span></code></pre></div>
<style type="text/css">
mark.in {
  background-color: CornflowerBlue;
}

mark.out {
  background-color: IndianRed;
}

</style>
<p>The deepG library offers several options to extract input/target
pairs from data. We can differentiate between to main approach:</p>
<ul>
<li>
<strong>Language model:</strong> predict a character or several
characters in a sequence.</li>
<li>
<strong>Label Classification:</strong> map a label to a
sequence.</li>
</ul>
<div class="section level2">
<h2 id="language-model">Language model<a class="anchor" aria-label="anchor" href="#language-model"></a>
</h2>
<p>With language model, we mean a model that predicts a character in a
sequence. We have several options to determine the output format of the
data generator using the <code>output_format</code> argument.</p>
<p>The <code>output_format</code> determines the shape of the output for
a language model, i.e. part of a sequence is the input <span class="math inline">\(X\)</span> and another the target <span class="math inline">\(Y\)</span>. Assume a sequence <tt>abcdefg</tt> and
<code>maxlen = 6</code>. Output correspond as follows</p>
<p><strong>“target_right”</strong>: <span class="math inline">\(X=\)</span> <tt>abcdef</tt>, <span class="math inline">\(Y=\)</span> <tt>g</tt></p>
<p><strong>“target_middle_lstm”</strong>: <span class="math inline">\(X
=\)</span> (<span class="math inline">\(X_1 =\)</span> <tt>abc</tt>,
<span class="math inline">\(X_2 =\)</span> <tt>gfe</tt>), <span class="math inline">\(Y=\)</span> <tt>d</tt> (note reversed order of
<span class="math inline">\(X_2\)</span>)</p>
<p><strong>“target_middle_cnn”</strong>: <span class="math inline">\(X
=\)</span> <tt>abcefg</tt>, <span class="math inline">\(Y =\)</span>
<tt>d</tt></p>
<p><strong>“wavenet”</strong>: <span class="math inline">\(X =\)</span>
<tt>abcdef</tt>, <span class="math inline">\(Y =\)</span>
<tt>bcdefg</tt></p>
<div class="section level3">
<h3 id="create-dummy-data">Create dummy data<a class="anchor" aria-label="anchor" href="#create-dummy-data"></a>
</h3>
<p>To test the different language model options, we create a simple
dummy data set consisting of a repetition of the sequence
<tt>AAACCCGGGTTTAAACCC…</tt>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span><span class="va">base_seq</span> <span class="op">&lt;-</span> <span class="st">"AAACCCGGGTTT"</span></span>
<span><span class="va">full_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/strrep.html" class="external-link">strrep</a></span><span class="op">(</span><span class="va">base_seq</span>, <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Header <span class="op">=</span> <span class="st">"header"</span>, Sequence <span class="op">=</span> <span class="va">full_seq</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># create training fasta file</span></span>
<span><span class="va">train_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir</span><span class="op">)</span></span>
<span><span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="va">train_dir</span>, <span class="st">"train_1.fasta"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># create validation fasta file (use same data as training)</span></span>
<span><span class="va">val_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir</span><span class="op">)</span></span>
<span><span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="va">val_dir</span>, <span class="st">"val_1.fasta"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="predict-next-character">Predict next character<a class="anchor" aria-label="anchor" href="#predict-next-character"></a>
</h3>
<p>Say we want to predict the next character in a sequence given the
last 5 characters and our text consists of the letters <tt>A,C,G,T</tt>
. First we have to create a model. We may use a model with 1 LSTM and 1
dense layer for predictions.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> <span class="co"># text consists of A,C,G,T</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_1 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm (LSTM)                 (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense (Dense)               (None, 4)                 36        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 452 (1.77 KB)</span></span>
<span><span class="co">## Trainable params: 452 (1.77 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<p>Next we have to specify the location of our training and validation
data and the output format of the data generator</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"lm"</span>, <span class="co"># running a language model</span></span>
<span>                    output_format <span class="op">=</span> <span class="st">"target_right"</span>, <span class="co"># predict target at end of sequence</span></span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, <span class="co"># use 20% of samples for validation compared to train</span></span>
<span>                    batch_size <span class="op">=</span> <span class="fl">16</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 3s - loss: 1.3941 - acc: 0.31255/5 [==============================] - 1s 64ms/step - loss: 1.0183 - acc: 0.5625 - val_loss: 0.4194 - val_acc: 0.9375 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.4492 - acc: 0.93755/5 [==============================] - 0s 17ms/step - loss: 0.2612 - acc: 0.9750 - val_loss: 0.0894 - val_acc: 0.9375 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 3/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.1322 - acc: 0.87505/5 [==============================] - 0s 17ms/step - loss: 0.0653 - acc: 0.9750 - val_loss: 0.0229 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 4/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0318 - acc: 1.00005/5 [==============================] - 0s 16ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="predict-character-in-middle-of-sequence">Predict character in middle of sequence<a class="anchor" aria-label="anchor" href="#predict-character-in-middle-of-sequence"></a>
</h3>
<p>If we want to predict a character in the middle of a sequence and use
LSTM layers, we should split our input into two layers. One layer
handles the sequence before and one the input after the target. If, for
example</p>
<p>sequence: <tt> ACCG<mark class="in">T</mark>GGAA<br></tt></p>
<p>then first input corresponds to <tt>ACCG</tt> and second to
<tt>AAGG</tt>. We may create a model with two input layers using the
<code>create_model_cnn_lstm_target_middle</code></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn_target_middle.html">create_model_lstm_cnn_target_middle</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> </span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_1"</span></span>
<span><span class="co">## __________________________________________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape                 Param #   Connected to                  </span></span>
<span><span class="co">## ==================================================================================================</span></span>
<span><span class="co">##  input_2 (InputLayer)        [(None, 3, 4)]               0         []                            </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  input_3 (InputLayer)        [(None, 2, 4)]               0         []                            </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  lstm_1 (LSTM)               (None, 8)                    416       ['input_2[0][0]']             </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  lstm_2 (LSTM)               (None, 8)                    416       ['input_3[0][0]']             </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  concatenate (Concatenate)   (None, 16)                   0         ['lstm_1[0][0]',              </span></span>
<span><span class="co">##                                                                      'lstm_2[0][0]']              </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">##  dense_1 (Dense)             (None, 4)                    68        ['concatenate[0][0]']         </span></span>
<span><span class="co">##                                                                                                   </span></span>
<span><span class="co">## ==================================================================================================</span></span>
<span><span class="co">## Total params: 900 (3.52 KB)</span></span>
<span><span class="co">## Trainable params: 900 (3.52 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## __________________________________________________________________________________________________</span></span></code></pre>
<p>The <code>train_model</code> call is identical to the previous model,
except we have to change the output format of the generator by setting
<code>output_format = "target_middle_lstm"</code>. This reverses the
order of the sequence after the target.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"lm"</span>, <span class="co"># running a language model</span></span>
<span>                    output_format <span class="op">=</span> <span class="st">"target_middle_lstm"</span>, <span class="co"># predict target in middle of sequence </span></span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, <span class="co"># use 20% of samples for validation compared to train</span></span>
<span>                    batch_size <span class="op">=</span> <span class="fl">16</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 5s - loss: 1.3951 - acc: 0.12505/5 [==============================] - 2s 94ms/step - loss: 0.9400 - acc: 0.6500 - val_loss: 0.2796 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.3045 - acc: 1.00005/5 [==============================] - 0s 19ms/step - loss: 0.1344 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 3/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0157 - acc: 1.00003/5 [=================&gt;............] - ETA: 0s - loss: 0.0112 - acc: 1.00005/5 [==============================] - 0s 30ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 4/4</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0031 - acc: 1.00005/5 [==============================] - 0s 19ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="masked-language-model">Masked language model<a class="anchor" aria-label="anchor" href="#masked-language-model"></a>
</h3>
<p>Here we mask some parts of the input sequence and the model tries to
predict the masked regions. Can be used for training BERT-like models.
See also this <a href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing" class="external-link">notebook</a>.
We can first check how the generator works.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create dummy training data</span></span>
<span><span class="va">nt_seq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span>collapse <span class="op">=</span> <span class="st">""</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/strrep.html" class="external-link">strrep</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Sequence <span class="op">=</span> <span class="va">nt_seq</span>, Header <span class="op">=</span> <span class="st">"seq_1"</span><span class="op">)</span></span>
<span><span class="va">fasta_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span>fileext <span class="op">=</span> <span class="st">".fasta"</span><span class="op">)</span></span>
<span><span class="va">fasta_file</span> <span class="op">&lt;-</span> <span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">writeFasta</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">fasta_path</span><span class="op">)</span></span>
<span><span class="va">masked_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mask_rate <span class="op">=</span> <span class="fl">0.10</span>, <span class="co"># replace 10% of input with special mask token</span></span>
<span>                  random_rate <span class="op">=</span> <span class="fl">0.03</span>, <span class="co"># set 3% of input to random value</span></span>
<span>                  identity_rate <span class="op">=</span> <span class="fl">0.02</span>, <span class="co"># leave 2% unchanged (and set sample weight to 1)</span></span>
<span>                  include_sw <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># 0,1 matrix showing where masking was applied</span></span>
<span></span>
<span><span class="va">gen</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/get_generator.html">get_generator</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>                      train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>                      masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>                      batch_size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram_stride <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      return_int <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                      maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu">gen</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">sw</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, sw <span class="op">=</span> <span class="va">sw</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   x y sw</span></span>
<span><span class="co">## 1 5 1  1</span></span>
<span><span class="co">## 2 1 1  0</span></span>
<span><span class="co">## 3 1 1  0</span></span>
<span><span class="co">## 4 1 1  0</span></span>
<span><span class="co">## 5 1 1  0</span></span>
<span><span class="co">## 6 1 1  0</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">df</span><span class="op">[</span> <span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    x y sw</span></span>
<span><span class="co">## 1  5 1  1</span></span>
<span><span class="co">## 7  5 1  1</span></span>
<span><span class="co">## 14 5 1  1</span></span>
<span><span class="co">## 21 1 1  1</span></span>
<span><span class="co">## 34 5 2  1</span></span>
<span><span class="co">## 43 2 2  1</span></span>
<span><span class="co">## 51 4 3  1</span></span>
<span><span class="co">## 54 5 3  1</span></span>
<span><span class="co">## 59 3 3  1</span></span>
<span><span class="co">## 73 5 3  1</span></span>
<span><span class="co">## 74 5 3  1</span></span>
<span><span class="co">## 79 5 4  1</span></span>
<span><span class="co">## 82 5 4  1</span></span>
<span><span class="co">## 85 5 4  1</span></span>
<span><span class="co">## 87 2 4  1</span></span></code></pre>
<p>Create the model architecture.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_transformer.html">create_model_transformer</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  embed_dim <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  ff_dim <span class="op">=</span> <span class="fl">32</span>,</span>
<span>  pos_encoding <span class="op">=</span> <span class="st">"embedding"</span>,</span>
<span>  head_size <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  num_heads <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fl">6</span>,</span>
<span>  flatten_method <span class="op">=</span> <span class="st">"none"</span>,</span>
<span>  last_layer_activation <span class="op">=</span> <span class="st">"softmax"</span>,</span>
<span>  loss_fn <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span>  solver <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.005</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_2"</span></span>
<span><span class="co">## ________________________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                       Output Shape                    Param #     </span></span>
<span><span class="co">## ================================================================================</span></span>
<span><span class="co">##  input_4 (InputLayer)               [(None, 100)]                   0           </span></span>
<span><span class="co">##  layer_pos_embedding (layer_pos_em  (None, 100, 16)                 1696        </span></span>
<span><span class="co">##  bedding)                                                                       </span></span>
<span><span class="co">##  layer_transformer_block (layer_tr  (None, 100, 16)                 6512        </span></span>
<span><span class="co">##  ansformer_block)                                                               </span></span>
<span><span class="co">##  dense_4 (Dense)                    (None, 100, 6)                  102         </span></span>
<span><span class="co">## ================================================================================</span></span>
<span><span class="co">## Total params: 8310 (32.46 KB)</span></span>
<span><span class="co">## Trainable params: 8310 (32.46 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## ________________________________________________________________________________</span></span></code></pre>
<p>Train the model.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">128</span></span>
<span><span class="va">masked_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mask_rate <span class="op">=</span> <span class="fl">0.10</span>, random_rate <span class="op">=</span> <span class="fl">0.03</span>, identity_rate <span class="op">=</span> <span class="fl">0.02</span>, include_sw <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            <span class="co"># training args</span></span>
<span>            run_name <span class="op">=</span> <span class="st">"bert_1"</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">75</span>,</span>
<span>            <span class="co"># generator args</span></span>
<span>            maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>            train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>            path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>            path_val <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>            batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>            step <span class="op">=</span> <span class="fl">25</span>,</span>
<span>            masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>            proportion_per_seq <span class="op">=</span> <span class="fl">0.97</span>,</span>
<span>            return_int <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 1:00 - loss: 0.3075 - acc: 0.2970 2/75 [..............................] - ETA: 5s - loss: 0.2703 - acc: 0.3285   3/75 [&gt;.............................] - ETA: 4s - loss: 0.2529 - acc: 0.3800 4/75 [&gt;.............................] - ETA: 4s - loss: 0.2422 - acc: 0.4434 5/75 [=&gt;............................] - ETA: 4s - loss: 0.2373 - acc: 0.4706 6/75 [=&gt;............................] - ETA: 4s - loss: 0.2331 - acc: 0.4951 7/75 [=&gt;............................] - ETA: 3s - loss: 0.2293 - acc: 0.5234 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.2265 - acc: 0.5472 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.2242 - acc: 0.575010/75 [===&gt;..........................] - ETA: 3s - loss: 0.2223 - acc: 0.605511/75 [===&gt;..........................] - ETA: 3s - loss: 0.2208 - acc: 0.631612/75 [===&gt;..........................] - ETA: 3s - loss: 0.2195 - acc: 0.652513/75 [====&gt;.........................] - ETA: 3s - loss: 0.2185 - acc: 0.670114/75 [====&gt;.........................] - ETA: 3s - loss: 0.2178 - acc: 0.685715/75 [=====&gt;........................] - ETA: 3s - loss: 0.2170 - acc: 0.700116/75 [=====&gt;........................] - ETA: 3s - loss: 0.2162 - acc: 0.712617/75 [=====&gt;........................] - ETA: 3s - loss: 0.2154 - acc: 0.723418/75 [======&gt;.......................] - ETA: 3s - loss: 0.2148 - acc: 0.732619/75 [======&gt;.......................] - ETA: 3s - loss: 0.2144 - acc: 0.740120/75 [=======&gt;......................] - ETA: 3s - loss: 0.2138 - acc: 0.746622/75 [=======&gt;......................] - ETA: 2s - loss: 0.2125 - acc: 0.758023/75 [========&gt;.....................] - ETA: 2s - loss: 0.2118 - acc: 0.764324/75 [========&gt;.....................] - ETA: 2s - loss: 0.2113 - acc: 0.770025/75 [=========&gt;....................] - ETA: 2s - loss: 0.2109 - acc: 0.775326/75 [=========&gt;....................] - ETA: 2s - loss: 0.2105 - acc: 0.780227/75 [=========&gt;....................] - ETA: 2s - loss: 0.2101 - acc: 0.784828/75 [==========&gt;...................] - ETA: 2s - loss: 0.2098 - acc: 0.788929/75 [==========&gt;...................] - ETA: 2s - loss: 0.2095 - acc: 0.792930/75 [===========&gt;..................] - ETA: 2s - loss: 0.2094 - acc: 0.796331/75 [===========&gt;..................] - ETA: 2s - loss: 0.2091 - acc: 0.799732/75 [===========&gt;..................] - ETA: 2s - loss: 0.2088 - acc: 0.803033/75 [============&gt;.................] - ETA: 2s - loss: 0.2085 - acc: 0.806034/75 [============&gt;.................] - ETA: 2s - loss: 0.2082 - acc: 0.808835/75 [=============&gt;................] - ETA: 2s - loss: 0.2080 - acc: 0.811436/75 [=============&gt;................] - ETA: 2s - loss: 0.2076 - acc: 0.814037/75 [=============&gt;................] - ETA: 2s - loss: 0.2075 - acc: 0.816438/75 [==============&gt;...............] - ETA: 2s - loss: 0.2074 - acc: 0.818739/75 [==============&gt;...............] - ETA: 1s - loss: 0.2071 - acc: 0.820940/75 [===============&gt;..............] - ETA: 1s - loss: 0.2069 - acc: 0.823041/75 [===============&gt;..............] - ETA: 1s - loss: 0.2067 - acc: 0.824942/75 [===============&gt;..............] - ETA: 1s - loss: 0.2064 - acc: 0.826943/75 [================&gt;.............] - ETA: 1s - loss: 0.2064 - acc: 0.828544/75 [================&gt;.............] - ETA: 1s - loss: 0.2062 - acc: 0.830245/75 [=================&gt;............] - ETA: 1s - loss: 0.2060 - acc: 0.831946/75 [=================&gt;............] - ETA: 1s - loss: 0.2058 - acc: 0.833547/75 [=================&gt;............] - ETA: 1s - loss: 0.2056 - acc: 0.835148/75 [==================&gt;...........] - ETA: 1s - loss: 0.2055 - acc: 0.836549/75 [==================&gt;...........] - ETA: 1s - loss: 0.2054 - acc: 0.837850/75 [===================&gt;..........] - ETA: 1s - loss: 0.2053 - acc: 0.839151/75 [===================&gt;..........] - ETA: 1s - loss: 0.2052 - acc: 0.840352/75 [===================&gt;..........] - ETA: 1s - loss: 0.2050 - acc: 0.841553/75 [====================&gt;.........] - ETA: 1s - loss: 0.2049 - acc: 0.842754/75 [====================&gt;.........] - ETA: 1s - loss: 0.2048 - acc: 0.843955/75 [=====================&gt;........] - ETA: 1s - loss: 0.2046 - acc: 0.845056/75 [=====================&gt;........] - ETA: 1s - loss: 0.2044 - acc: 0.846157/75 [=====================&gt;........] - ETA: 0s - loss: 0.2043 - acc: 0.847258/75 [======================&gt;.......] - ETA: 0s - loss: 0.2042 - acc: 0.848259/75 [======================&gt;.......] - ETA: 0s - loss: 0.2040 - acc: 0.849260/75 [=======================&gt;......] - ETA: 0s - loss: 0.2039 - acc: 0.850161/75 [=======================&gt;......] - ETA: 0s - loss: 0.2038 - acc: 0.850962/75 [=======================&gt;......] - ETA: 0s - loss: 0.2036 - acc: 0.851963/75 [========================&gt;.....] - ETA: 0s - loss: 0.2035 - acc: 0.852764/75 [========================&gt;.....] - ETA: 0s - loss: 0.2034 - acc: 0.853565/75 [=========================&gt;....] - ETA: 0s - loss: 0.2034 - acc: 0.854266/75 [=========================&gt;....] - ETA: 0s - loss: 0.2034 - acc: 0.855067/75 [=========================&gt;....] - ETA: 0s - loss: 0.2033 - acc: 0.855768/75 [==========================&gt;...] - ETA: 0s - loss: 0.2033 - acc: 0.856469/75 [==========================&gt;...] - ETA: 0s - loss: 0.2032 - acc: 0.857171/75 [===========================&gt;..] - ETA: 0s - loss: 0.2031 - acc: 0.858472/75 [===========================&gt;..] - ETA: 0s - loss: 0.2030 - acc: 0.859173/75 [============================&gt;.] - ETA: 0s - loss: 0.2030 - acc: 0.859774/75 [============================&gt;.] - ETA: 0s - loss: 0.2029 - acc: 0.860475/75 [==============================] - ETA: 0s - loss: 0.2028 - acc: 0.861075/75 [==============================] - 5s 55ms/step - loss: 0.2028 - acc: 0.8610 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 2/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.1943 - acc: 0.9056 2/75 [..............................] - ETA: 12s - loss: 0.1968 - acc: 0.9045 3/75 [&gt;.............................] - ETA: 8s - loss: 0.1965 - acc: 0.9054  4/75 [&gt;.............................] - ETA: 6s - loss: 0.1968 - acc: 0.9057 5/75 [=&gt;............................] - ETA: 5s - loss: 0.1977 - acc: 0.9052 6/75 [=&gt;............................] - ETA: 5s - loss: 0.1966 - acc: 0.9059 7/75 [=&gt;............................] - ETA: 5s - loss: 0.1968 - acc: 0.9060 8/75 [==&gt;...........................] - ETA: 4s - loss: 0.1969 - acc: 0.9061 9/75 [==&gt;...........................] - ETA: 4s - loss: 0.1968 - acc: 0.906010/75 [===&gt;..........................] - ETA: 4s - loss: 0.1969 - acc: 0.905811/75 [===&gt;..........................] - ETA: 4s - loss: 0.1968 - acc: 0.905912/75 [===&gt;..........................] - ETA: 4s - loss: 0.1966 - acc: 0.906113/75 [====&gt;.........................] - ETA: 3s - loss: 0.1968 - acc: 0.905914/75 [====&gt;.........................] - ETA: 3s - loss: 0.1969 - acc: 0.905515/75 [=====&gt;........................] - ETA: 3s - loss: 0.1969 - acc: 0.905416/75 [=====&gt;........................] - ETA: 3s - loss: 0.1969 - acc: 0.905617/75 [=====&gt;........................] - ETA: 3s - loss: 0.1968 - acc: 0.905818/75 [======&gt;.......................] - ETA: 3s - loss: 0.1967 - acc: 0.905919/75 [======&gt;.......................] - ETA: 3s - loss: 0.1968 - acc: 0.905920/75 [=======&gt;......................] - ETA: 3s - loss: 0.1966 - acc: 0.906221/75 [=======&gt;......................] - ETA: 3s - loss: 0.1968 - acc: 0.906222/75 [=======&gt;......................] - ETA: 3s - loss: 0.1966 - acc: 0.906523/75 [========&gt;.....................] - ETA: 3s - loss: 0.1964 - acc: 0.906524/75 [========&gt;.....................] - ETA: 3s - loss: 0.1964 - acc: 0.906425/75 [=========&gt;....................] - ETA: 2s - loss: 0.1962 - acc: 0.906626/75 [=========&gt;....................] - ETA: 2s - loss: 0.1963 - acc: 0.906527/75 [=========&gt;....................] - ETA: 2s - loss: 0.1962 - acc: 0.906628/75 [==========&gt;...................] - ETA: 2s - loss: 0.1964 - acc: 0.906529/75 [==========&gt;...................] - ETA: 2s - loss: 0.1962 - acc: 0.906830/75 [===========&gt;..................] - ETA: 2s - loss: 0.1962 - acc: 0.906931/75 [===========&gt;..................] - ETA: 2s - loss: 0.1960 - acc: 0.907032/75 [===========&gt;..................] - ETA: 2s - loss: 0.1961 - acc: 0.906933/75 [============&gt;.................] - ETA: 2s - loss: 0.1964 - acc: 0.906834/75 [============&gt;.................] - ETA: 2s - loss: 0.1963 - acc: 0.906835/75 [=============&gt;................] - ETA: 2s - loss: 0.1963 - acc: 0.906736/75 [=============&gt;................] - ETA: 2s - loss: 0.1962 - acc: 0.906837/75 [=============&gt;................] - ETA: 2s - loss: 0.1962 - acc: 0.906838/75 [==============&gt;...............] - ETA: 2s - loss: 0.1963 - acc: 0.906939/75 [==============&gt;...............] - ETA: 2s - loss: 0.1964 - acc: 0.906740/75 [===============&gt;..............] - ETA: 1s - loss: 0.1964 - acc: 0.906741/75 [===============&gt;..............] - ETA: 1s - loss: 0.1964 - acc: 0.906742/75 [===============&gt;..............] - ETA: 1s - loss: 0.1964 - acc: 0.906443/75 [================&gt;.............] - ETA: 1s - loss: 0.1964 - acc: 0.906344/75 [================&gt;.............] - ETA: 1s - loss: 0.1962 - acc: 0.906545/75 [=================&gt;............] - ETA: 1s - loss: 0.1963 - acc: 0.906546/75 [=================&gt;............] - ETA: 1s - loss: 0.1963 - acc: 0.906547/75 [=================&gt;............] - ETA: 1s - loss: 0.1963 - acc: 0.906448/75 [==================&gt;...........] - ETA: 1s - loss: 0.1963 - acc: 0.906549/75 [==================&gt;...........] - ETA: 1s - loss: 0.1963 - acc: 0.906550/75 [===================&gt;..........] - ETA: 1s - loss: 0.1963 - acc: 0.906551/75 [===================&gt;..........] - ETA: 1s - loss: 0.1962 - acc: 0.906652/75 [===================&gt;..........] - ETA: 1s - loss: 0.1963 - acc: 0.906553/75 [====================&gt;.........] - ETA: 1s - loss: 0.1963 - acc: 0.906554/75 [====================&gt;.........] - ETA: 1s - loss: 0.1964 - acc: 0.906555/75 [=====================&gt;........] - ETA: 1s - loss: 0.1964 - acc: 0.906656/75 [=====================&gt;........] - ETA: 1s - loss: 0.1962 - acc: 0.906858/75 [======================&gt;.......] - ETA: 0s - loss: 0.1961 - acc: 0.906859/75 [======================&gt;.......] - ETA: 0s - loss: 0.1962 - acc: 0.906860/75 [=======================&gt;......] - ETA: 0s - loss: 0.1962 - acc: 0.906861/75 [=======================&gt;......] - ETA: 0s - loss: 0.1962 - acc: 0.906962/75 [=======================&gt;......] - ETA: 0s - loss: 0.1961 - acc: 0.906963/75 [========================&gt;.....] - ETA: 0s - loss: 0.1960 - acc: 0.907064/75 [========================&gt;.....] - ETA: 0s - loss: 0.1959 - acc: 0.907165/75 [=========================&gt;....] - ETA: 0s - loss: 0.1959 - acc: 0.907166/75 [=========================&gt;....] - ETA: 0s - loss: 0.1959 - acc: 0.907167/75 [=========================&gt;....] - ETA: 0s - loss: 0.1959 - acc: 0.907168/75 [==========================&gt;...] - ETA: 0s - loss: 0.1958 - acc: 0.907169/75 [==========================&gt;...] - ETA: 0s - loss: 0.1958 - acc: 0.907170/75 [===========================&gt;..] - ETA: 0s - loss: 0.1957 - acc: 0.907171/75 [===========================&gt;..] - ETA: 0s - loss: 0.1957 - acc: 0.907072/75 [===========================&gt;..] - ETA: 0s - loss: 0.1957 - acc: 0.906973/75 [============================&gt;.] - ETA: 0s - loss: 0.1956 - acc: 0.906874/75 [============================&gt;.] - ETA: 0s - loss: 0.1956 - acc: 0.906775/75 [==============================] - ETA: 0s - loss: 0.1956 - acc: 0.906775/75 [==============================] - 4s 55ms/step - loss: 0.1956 - acc: 0.9067 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 3/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.1913 - acc: 0.8975 2/75 [..............................] - ETA: 4s - loss: 0.1926 - acc: 0.8993 3/75 [&gt;.............................] - ETA: 4s - loss: 0.1933 - acc: 0.9006 4/75 [&gt;.............................] - ETA: 3s - loss: 0.1944 - acc: 0.9003 6/75 [=&gt;............................] - ETA: 3s - loss: 0.1930 - acc: 0.8964 7/75 [=&gt;............................] - ETA: 3s - loss: 0.1918 - acc: 0.8971 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.1917 - acc: 0.8974 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.1917 - acc: 0.897110/75 [===&gt;..........................] - ETA: 3s - loss: 0.1916 - acc: 0.897511/75 [===&gt;..........................] - ETA: 3s - loss: 0.1915 - acc: 0.897112/75 [===&gt;..........................] - ETA: 3s - loss: 0.1916 - acc: 0.896713/75 [====&gt;.........................] - ETA: 3s - loss: 0.1917 - acc: 0.895314/75 [====&gt;.........................] - ETA: 3s - loss: 0.1917 - acc: 0.894815/75 [=====&gt;........................] - ETA: 3s - loss: 0.1916 - acc: 0.895216/75 [=====&gt;........................] - ETA: 3s - loss: 0.1918 - acc: 0.895017/75 [=====&gt;........................] - ETA: 3s - loss: 0.1919 - acc: 0.894318/75 [======&gt;.......................] - ETA: 3s - loss: 0.1918 - acc: 0.893019/75 [======&gt;.......................] - ETA: 3s - loss: 0.1918 - acc: 0.892720/75 [=======&gt;......................] - ETA: 2s - loss: 0.1917 - acc: 0.892621/75 [=======&gt;......................] - ETA: 2s - loss: 0.1915 - acc: 0.891722/75 [=======&gt;......................] - ETA: 2s - loss: 0.1916 - acc: 0.892023/75 [========&gt;.....................] - ETA: 2s - loss: 0.1914 - acc: 0.892424/75 [========&gt;.....................] - ETA: 2s - loss: 0.1912 - acc: 0.893025/75 [=========&gt;....................] - ETA: 2s - loss: 0.1913 - acc: 0.893226/75 [=========&gt;....................] - ETA: 2s - loss: 0.1912 - acc: 0.893627/75 [=========&gt;....................] - ETA: 2s - loss: 0.1910 - acc: 0.894328/75 [==========&gt;...................] - ETA: 2s - loss: 0.1910 - acc: 0.894529/75 [==========&gt;...................] - ETA: 2s - loss: 0.1910 - acc: 0.894730/75 [===========&gt;..................] - ETA: 2s - loss: 0.1909 - acc: 0.895231/75 [===========&gt;..................] - ETA: 2s - loss: 0.1909 - acc: 0.895732/75 [===========&gt;..................] - ETA: 2s - loss: 0.1909 - acc: 0.896033/75 [============&gt;.................] - ETA: 2s - loss: 0.1910 - acc: 0.896234/75 [============&gt;.................] - ETA: 2s - loss: 0.1910 - acc: 0.896535/75 [=============&gt;................] - ETA: 2s - loss: 0.1910 - acc: 0.896336/75 [=============&gt;................] - ETA: 2s - loss: 0.1911 - acc: 0.896237/75 [=============&gt;................] - ETA: 2s - loss: 0.1912 - acc: 0.896338/75 [==============&gt;...............] - ETA: 1s - loss: 0.1911 - acc: 0.896639/75 [==============&gt;...............] - ETA: 1s - loss: 0.1911 - acc: 0.896440/75 [===============&gt;..............] - ETA: 1s - loss: 0.1911 - acc: 0.895641/75 [===============&gt;..............] - ETA: 1s - loss: 0.1912 - acc: 0.895342/75 [===============&gt;..............] - ETA: 1s - loss: 0.1911 - acc: 0.895143/75 [================&gt;.............] - ETA: 1s - loss: 0.1911 - acc: 0.895444/75 [================&gt;.............] - ETA: 1s - loss: 0.1910 - acc: 0.895645/75 [=================&gt;............] - ETA: 1s - loss: 0.1910 - acc: 0.894846/75 [=================&gt;............] - ETA: 1s - loss: 0.1910 - acc: 0.894347/75 [=================&gt;............] - ETA: 1s - loss: 0.1908 - acc: 0.894548/75 [==================&gt;...........] - ETA: 1s - loss: 0.1908 - acc: 0.894650/75 [===================&gt;..........] - ETA: 1s - loss: 0.1907 - acc: 0.894551/75 [===================&gt;..........] - ETA: 1s - loss: 0.1904 - acc: 0.894852/75 [===================&gt;..........] - ETA: 1s - loss: 0.1905 - acc: 0.895053/75 [====================&gt;.........] - ETA: 1s - loss: 0.1903 - acc: 0.895154/75 [====================&gt;.........] - ETA: 1s - loss: 0.1902 - acc: 0.895155/75 [=====================&gt;........] - ETA: 1s - loss: 0.1902 - acc: 0.894956/75 [=====================&gt;........] - ETA: 1s - loss: 0.1900 - acc: 0.895157/75 [=====================&gt;........] - ETA: 0s - loss: 0.1899 - acc: 0.895158/75 [======================&gt;.......] - ETA: 0s - loss: 0.1897 - acc: 0.895159/75 [======================&gt;.......] - ETA: 0s - loss: 0.1894 - acc: 0.895460/75 [=======================&gt;......] - ETA: 0s - loss: 0.1892 - acc: 0.895661/75 [=======================&gt;......] - ETA: 0s - loss: 0.1887 - acc: 0.895762/75 [=======================&gt;......] - ETA: 0s - loss: 0.1881 - acc: 0.895663/75 [========================&gt;.....] - ETA: 0s - loss: 0.1876 - acc: 0.895664/75 [========================&gt;.....] - ETA: 0s - loss: 0.1869 - acc: 0.895265/75 [=========================&gt;....] - ETA: 0s - loss: 0.1863 - acc: 0.894466/75 [=========================&gt;....] - ETA: 0s - loss: 0.1857 - acc: 0.893667/75 [=========================&gt;....] - ETA: 0s - loss: 0.1848 - acc: 0.893368/75 [==========================&gt;...] - ETA: 0s - loss: 0.1841 - acc: 0.892569/75 [==========================&gt;...] - ETA: 0s - loss: 0.1836 - acc: 0.890870/75 [===========================&gt;..] - ETA: 0s - loss: 0.1828 - acc: 0.889471/75 [===========================&gt;..] - ETA: 0s - loss: 0.1822 - acc: 0.887372/75 [===========================&gt;..] - ETA: 0s - loss: 0.1815 - acc: 0.885873/75 [============================&gt;.] - ETA: 0s - loss: 0.1807 - acc: 0.884874/75 [============================&gt;.] - ETA: 0s - loss: 0.1802 - acc: 0.882475/75 [==============================] - ETA: 0s - loss: 0.1794 - acc: 0.881975/75 [==============================] - 4s 54ms/step - loss: 0.1794 - acc: 0.8819 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 4/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 4s - loss: 0.1208 - acc: 0.8734 2/75 [..............................] - ETA: 4s - loss: 0.1221 - acc: 0.8629 3/75 [&gt;.............................] - ETA: 4s - loss: 0.1236 - acc: 0.8566 4/75 [&gt;.............................] - ETA: 3s - loss: 0.1249 - acc: 0.8535 5/75 [=&gt;............................] - ETA: 3s - loss: 0.1245 - acc: 0.8575 6/75 [=&gt;............................] - ETA: 3s - loss: 0.1247 - acc: 0.8551 7/75 [=&gt;............................] - ETA: 5s - loss: 0.1250 - acc: 0.8576 8/75 [==&gt;...........................] - ETA: 4s - loss: 0.1246 - acc: 0.856710/75 [===&gt;..........................] - ETA: 4s - loss: 0.1238 - acc: 0.863511/75 [===&gt;..........................] - ETA: 4s - loss: 0.1230 - acc: 0.864912/75 [===&gt;..........................] - ETA: 4s - loss: 0.1219 - acc: 0.870313/75 [====&gt;.........................] - ETA: 3s - loss: 0.1218 - acc: 0.869214/75 [====&gt;.........................] - ETA: 3s - loss: 0.1211 - acc: 0.872715/75 [=====&gt;........................] - ETA: 3s - loss: 0.1197 - acc: 0.877816/75 [=====&gt;........................] - ETA: 3s - loss: 0.1199 - acc: 0.877017/75 [=====&gt;........................] - ETA: 3s - loss: 0.1188 - acc: 0.880718/75 [======&gt;.......................] - ETA: 3s - loss: 0.1181 - acc: 0.882019/75 [======&gt;.......................] - ETA: 3s - loss: 0.1167 - acc: 0.885520/75 [=======&gt;......................] - ETA: 3s - loss: 0.1159 - acc: 0.888321/75 [=======&gt;......................] - ETA: 3s - loss: 0.1156 - acc: 0.888922/75 [=======&gt;......................] - ETA: 3s - loss: 0.1148 - acc: 0.890523/75 [========&gt;.....................] - ETA: 3s - loss: 0.1132 - acc: 0.893524/75 [========&gt;.....................] - ETA: 3s - loss: 0.1117 - acc: 0.896425/75 [=========&gt;....................] - ETA: 2s - loss: 0.1102 - acc: 0.899126/75 [=========&gt;....................] - ETA: 2s - loss: 0.1090 - acc: 0.901327/75 [=========&gt;....................] - ETA: 2s - loss: 0.1078 - acc: 0.903228/75 [==========&gt;...................] - ETA: 2s - loss: 0.1069 - acc: 0.904829/75 [==========&gt;...................] - ETA: 2s - loss: 0.1052 - acc: 0.906830/75 [===========&gt;..................] - ETA: 2s - loss: 0.1041 - acc: 0.908331/75 [===========&gt;..................] - ETA: 2s - loss: 0.1024 - acc: 0.910132/75 [===========&gt;..................] - ETA: 2s - loss: 0.1007 - acc: 0.912133/75 [============&gt;.................] - ETA: 2s - loss: 0.0991 - acc: 0.913634/75 [============&gt;.................] - ETA: 2s - loss: 0.0977 - acc: 0.914935/75 [=============&gt;................] - ETA: 2s - loss: 0.0958 - acc: 0.916636/75 [=============&gt;................] - ETA: 2s - loss: 0.0944 - acc: 0.917937/75 [=============&gt;................] - ETA: 2s - loss: 0.0932 - acc: 0.918538/75 [==============&gt;...............] - ETA: 2s - loss: 0.0917 - acc: 0.919439/75 [==============&gt;...............] - ETA: 2s - loss: 0.0903 - acc: 0.920240/75 [===============&gt;..............] - ETA: 1s - loss: 0.0890 - acc: 0.921441/75 [===============&gt;..............] - ETA: 1s - loss: 0.0873 - acc: 0.922842/75 [===============&gt;..............] - ETA: 1s - loss: 0.0862 - acc: 0.923443/75 [================&gt;.............] - ETA: 1s - loss: 0.0853 - acc: 0.923844/75 [================&gt;.............] - ETA: 1s - loss: 0.0840 - acc: 0.925045/75 [=================&gt;............] - ETA: 1s - loss: 0.0828 - acc: 0.925846/75 [=================&gt;............] - ETA: 1s - loss: 0.0816 - acc: 0.926448/75 [==================&gt;...........] - ETA: 1s - loss: 0.0795 - acc: 0.927849/75 [==================&gt;...........] - ETA: 1s - loss: 0.0785 - acc: 0.928450/75 [===================&gt;..........] - ETA: 1s - loss: 0.0775 - acc: 0.929151/75 [===================&gt;..........] - ETA: 1s - loss: 0.0766 - acc: 0.929652/75 [===================&gt;..........] - ETA: 1s - loss: 0.0756 - acc: 0.930453/75 [====================&gt;.........] - ETA: 1s - loss: 0.0747 - acc: 0.931154/75 [====================&gt;.........] - ETA: 1s - loss: 0.0737 - acc: 0.931955/75 [=====================&gt;........] - ETA: 1s - loss: 0.0727 - acc: 0.932756/75 [=====================&gt;........] - ETA: 1s - loss: 0.0718 - acc: 0.933557/75 [=====================&gt;........] - ETA: 1s - loss: 0.0709 - acc: 0.934258/75 [======================&gt;.......] - ETA: 0s - loss: 0.0700 - acc: 0.935059/75 [======================&gt;.......] - ETA: 0s - loss: 0.0692 - acc: 0.935560/75 [=======================&gt;......] - ETA: 0s - loss: 0.0684 - acc: 0.936061/75 [=======================&gt;......] - ETA: 0s - loss: 0.0677 - acc: 0.936562/75 [=======================&gt;......] - ETA: 0s - loss: 0.0671 - acc: 0.937063/75 [========================&gt;.....] - ETA: 0s - loss: 0.0663 - acc: 0.937664/75 [========================&gt;.....] - ETA: 0s - loss: 0.0656 - acc: 0.938265/75 [=========================&gt;....] - ETA: 0s - loss: 0.0649 - acc: 0.938866/75 [=========================&gt;....] - ETA: 0s - loss: 0.0642 - acc: 0.939468/75 [==========================&gt;...] - ETA: 0s - loss: 0.0629 - acc: 0.940569/75 [==========================&gt;...] - ETA: 0s - loss: 0.0622 - acc: 0.941071/75 [===========================&gt;..] - ETA: 0s - loss: 0.0610 - acc: 0.942072/75 [===========================&gt;..] - ETA: 0s - loss: 0.0603 - acc: 0.942573/75 [============================&gt;.] - ETA: 0s - loss: 0.0598 - acc: 0.943074/75 [============================&gt;.] - ETA: 0s - loss: 0.0592 - acc: 0.943675/75 [==============================] - ETA: 0s - loss: 0.0586 - acc: 0.944175/75 [==============================] - 4s 56ms/step - loss: 0.0586 - acc: 0.9441 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 5/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 3s - loss: 0.0182 - acc: 0.9795 2/75 [..............................] - ETA: 3s - loss: 0.0183 - acc: 0.9804 3/75 [&gt;.............................] - ETA: 4s - loss: 0.0162 - acc: 0.9828 4/75 [&gt;.............................] - ETA: 4s - loss: 0.0160 - acc: 0.9807 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0170 - acc: 0.9792 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0163 - acc: 0.9795 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0154 - acc: 0.9805 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0153 - acc: 0.9801 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0156 - acc: 0.979311/75 [===&gt;..........................] - ETA: 3s - loss: 0.0156 - acc: 0.979813/75 [====&gt;.........................] - ETA: 3s - loss: 0.0152 - acc: 0.980214/75 [====&gt;.........................] - ETA: 3s - loss: 0.0149 - acc: 0.980316/75 [=====&gt;........................] - ETA: 3s - loss: 0.0150 - acc: 0.980817/75 [=====&gt;........................] - ETA: 3s - loss: 0.0149 - acc: 0.981218/75 [======&gt;.......................] - ETA: 3s - loss: 0.0149 - acc: 0.981019/75 [======&gt;.......................] - ETA: 3s - loss: 0.0148 - acc: 0.981120/75 [=======&gt;......................] - ETA: 2s - loss: 0.0147 - acc: 0.981321/75 [=======&gt;......................] - ETA: 2s - loss: 0.0145 - acc: 0.981122/75 [=======&gt;......................] - ETA: 2s - loss: 0.0143 - acc: 0.981223/75 [========&gt;.....................] - ETA: 2s - loss: 0.0143 - acc: 0.981324/75 [========&gt;.....................] - ETA: 2s - loss: 0.0142 - acc: 0.981525/75 [=========&gt;....................] - ETA: 2s - loss: 0.0141 - acc: 0.981726/75 [=========&gt;....................] - ETA: 2s - loss: 0.0139 - acc: 0.982027/75 [=========&gt;....................] - ETA: 2s - loss: 0.0139 - acc: 0.981928/75 [==========&gt;...................] - ETA: 2s - loss: 0.0140 - acc: 0.981829/75 [==========&gt;...................] - ETA: 2s - loss: 0.0139 - acc: 0.982030/75 [===========&gt;..................] - ETA: 2s - loss: 0.0141 - acc: 0.981631/75 [===========&gt;..................] - ETA: 2s - loss: 0.0139 - acc: 0.981832/75 [===========&gt;..................] - ETA: 2s - loss: 0.0139 - acc: 0.981533/75 [============&gt;.................] - ETA: 2s - loss: 0.0137 - acc: 0.981834/75 [============&gt;.................] - ETA: 2s - loss: 0.0136 - acc: 0.982035/75 [=============&gt;................] - ETA: 2s - loss: 0.0136 - acc: 0.981936/75 [=============&gt;................] - ETA: 2s - loss: 0.0135 - acc: 0.982037/75 [=============&gt;................] - ETA: 2s - loss: 0.0134 - acc: 0.982338/75 [==============&gt;...............] - ETA: 2s - loss: 0.0134 - acc: 0.982439/75 [==============&gt;...............] - ETA: 1s - loss: 0.0133 - acc: 0.982440/75 [===============&gt;..............] - ETA: 1s - loss: 0.0134 - acc: 0.982341/75 [===============&gt;..............] - ETA: 1s - loss: 0.0134 - acc: 0.982142/75 [===============&gt;..............] - ETA: 1s - loss: 0.0133 - acc: 0.982343/75 [================&gt;.............] - ETA: 1s - loss: 0.0132 - acc: 0.982444/75 [================&gt;.............] - ETA: 1s - loss: 0.0134 - acc: 0.982245/75 [=================&gt;............] - ETA: 1s - loss: 0.0133 - acc: 0.982146/75 [=================&gt;............] - ETA: 1s - loss: 0.0132 - acc: 0.982247/75 [=================&gt;............] - ETA: 1s - loss: 0.0132 - acc: 0.982248/75 [==================&gt;...........] - ETA: 1s - loss: 0.0131 - acc: 0.982349/75 [==================&gt;...........] - ETA: 1s - loss: 0.0130 - acc: 0.982450/75 [===================&gt;..........] - ETA: 1s - loss: 0.0131 - acc: 0.982251/75 [===================&gt;..........] - ETA: 1s - loss: 0.0132 - acc: 0.982252/75 [===================&gt;..........] - ETA: 1s - loss: 0.0132 - acc: 0.982253/75 [====================&gt;.........] - ETA: 1s - loss: 0.0132 - acc: 0.982154/75 [====================&gt;.........] - ETA: 1s - loss: 0.0131 - acc: 0.982255/75 [=====================&gt;........] - ETA: 1s - loss: 0.0129 - acc: 0.982457/75 [=====================&gt;........] - ETA: 0s - loss: 0.0128 - acc: 0.982758/75 [======================&gt;.......] - ETA: 0s - loss: 0.0127 - acc: 0.982859/75 [======================&gt;.......] - ETA: 0s - loss: 0.0128 - acc: 0.982760/75 [=======================&gt;......] - ETA: 0s - loss: 0.0128 - acc: 0.982761/75 [=======================&gt;......] - ETA: 0s - loss: 0.0128 - acc: 0.982862/75 [=======================&gt;......] - ETA: 0s - loss: 0.0127 - acc: 0.982863/75 [========================&gt;.....] - ETA: 0s - loss: 0.0127 - acc: 0.982864/75 [========================&gt;.....] - ETA: 0s - loss: 0.0128 - acc: 0.982765/75 [=========================&gt;....] - ETA: 0s - loss: 0.0130 - acc: 0.982566/75 [=========================&gt;....] - ETA: 0s - loss: 0.0130 - acc: 0.982667/75 [=========================&gt;....] - ETA: 0s - loss: 0.0129 - acc: 0.982769/75 [==========================&gt;...] - ETA: 0s - loss: 0.0127 - acc: 0.983070/75 [===========================&gt;..] - ETA: 0s - loss: 0.0128 - acc: 0.982871/75 [===========================&gt;..] - ETA: 0s - loss: 0.0128 - acc: 0.982772/75 [===========================&gt;..] - ETA: 0s - loss: 0.0127 - acc: 0.982873/75 [============================&gt;.] - ETA: 0s - loss: 0.0128 - acc: 0.982874/75 [============================&gt;.] - ETA: 0s - loss: 0.0127 - acc: 0.982975/75 [==============================] - ETA: 0s - loss: 0.0127 - acc: 0.983075/75 [==============================] - 4s 54ms/step - loss: 0.0127 - acc: 0.9830 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 6/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 4s - loss: 0.0059 - acc: 0.9895 2/75 [..............................] - ETA: 3s - loss: 0.0063 - acc: 0.9917 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0074 - acc: 0.9911 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0077 - acc: 0.9898 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0076 - acc: 0.9898 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0076 - acc: 0.9902 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0076 - acc: 0.9899 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0080 - acc: 0.9894 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0085 - acc: 0.989110/75 [===&gt;..........................] - ETA: 3s - loss: 0.0093 - acc: 0.988011/75 [===&gt;..........................] - ETA: 3s - loss: 0.0091 - acc: 0.988312/75 [===&gt;..........................] - ETA: 3s - loss: 0.0087 - acc: 0.988713/75 [====&gt;.........................] - ETA: 3s - loss: 0.0090 - acc: 0.988514/75 [====&gt;.........................] - ETA: 3s - loss: 0.0088 - acc: 0.988915/75 [=====&gt;........................] - ETA: 3s - loss: 0.0086 - acc: 0.989316/75 [=====&gt;........................] - ETA: 3s - loss: 0.0085 - acc: 0.989417/75 [=====&gt;........................] - ETA: 3s - loss: 0.0084 - acc: 0.989618/75 [======&gt;.......................] - ETA: 3s - loss: 0.0084 - acc: 0.989719/75 [======&gt;.......................] - ETA: 3s - loss: 0.0087 - acc: 0.989220/75 [=======&gt;......................] - ETA: 2s - loss: 0.0089 - acc: 0.989021/75 [=======&gt;......................] - ETA: 2s - loss: 0.0087 - acc: 0.989222/75 [=======&gt;......................] - ETA: 2s - loss: 0.0089 - acc: 0.989023/75 [========&gt;.....................] - ETA: 2s - loss: 0.0090 - acc: 0.988724/75 [========&gt;.....................] - ETA: 2s - loss: 0.0090 - acc: 0.988825/75 [=========&gt;....................] - ETA: 2s - loss: 0.0091 - acc: 0.988926/75 [=========&gt;....................] - ETA: 2s - loss: 0.0090 - acc: 0.988827/75 [=========&gt;....................] - ETA: 2s - loss: 0.0090 - acc: 0.988828/75 [==========&gt;...................] - ETA: 2s - loss: 0.0089 - acc: 0.988929/75 [==========&gt;...................] - ETA: 2s - loss: 0.0090 - acc: 0.989030/75 [===========&gt;..................] - ETA: 2s - loss: 0.0089 - acc: 0.989031/75 [===========&gt;..................] - ETA: 2s - loss: 0.0089 - acc: 0.988932/75 [===========&gt;..................] - ETA: 2s - loss: 0.0088 - acc: 0.989133/75 [============&gt;.................] - ETA: 2s - loss: 0.0088 - acc: 0.989135/75 [=============&gt;................] - ETA: 2s - loss: 0.0088 - acc: 0.989236/75 [=============&gt;................] - ETA: 2s - loss: 0.0087 - acc: 0.989137/75 [=============&gt;................] - ETA: 2s - loss: 0.0087 - acc: 0.989238/75 [==============&gt;...............] - ETA: 1s - loss: 0.0089 - acc: 0.988739/75 [==============&gt;...............] - ETA: 1s - loss: 0.0089 - acc: 0.988841/75 [===============&gt;..............] - ETA: 1s - loss: 0.0089 - acc: 0.988842/75 [===============&gt;..............] - ETA: 1s - loss: 0.0088 - acc: 0.988943/75 [================&gt;.............] - ETA: 1s - loss: 0.0089 - acc: 0.988944/75 [================&gt;.............] - ETA: 1s - loss: 0.0089 - acc: 0.988846/75 [=================&gt;............] - ETA: 1s - loss: 0.0089 - acc: 0.988947/75 [=================&gt;............] - ETA: 1s - loss: 0.0088 - acc: 0.988948/75 [==================&gt;...........] - ETA: 1s - loss: 0.0087 - acc: 0.989049/75 [==================&gt;...........] - ETA: 1s - loss: 0.0087 - acc: 0.989150/75 [===================&gt;..........] - ETA: 1s - loss: 0.0086 - acc: 0.989251/75 [===================&gt;..........] - ETA: 1s - loss: 0.0086 - acc: 0.989252/75 [===================&gt;..........] - ETA: 1s - loss: 0.0085 - acc: 0.989353/75 [====================&gt;.........] - ETA: 1s - loss: 0.0085 - acc: 0.989254/75 [====================&gt;.........] - ETA: 1s - loss: 0.0085 - acc: 0.989255/75 [=====================&gt;........] - ETA: 1s - loss: 0.0085 - acc: 0.989056/75 [=====================&gt;........] - ETA: 1s - loss: 0.0086 - acc: 0.989057/75 [=====================&gt;........] - ETA: 0s - loss: 0.0086 - acc: 0.988958/75 [======================&gt;.......] - ETA: 0s - loss: 0.0086 - acc: 0.988959/75 [======================&gt;.......] - ETA: 0s - loss: 0.0086 - acc: 0.989060/75 [=======================&gt;......] - ETA: 0s - loss: 0.0086 - acc: 0.989061/75 [=======================&gt;......] - ETA: 0s - loss: 0.0086 - acc: 0.988962/75 [=======================&gt;......] - ETA: 0s - loss: 0.0085 - acc: 0.989064/75 [========================&gt;.....] - ETA: 0s - loss: 0.0085 - acc: 0.989065/75 [=========================&gt;....] - ETA: 0s - loss: 0.0084 - acc: 0.989166/75 [=========================&gt;....] - ETA: 0s - loss: 0.0084 - acc: 0.989067/75 [=========================&gt;....] - ETA: 0s - loss: 0.0084 - acc: 0.989068/75 [==========================&gt;...] - ETA: 0s - loss: 0.0084 - acc: 0.988969/75 [==========================&gt;...] - ETA: 0s - loss: 0.0084 - acc: 0.988970/75 [===========================&gt;..] - ETA: 0s - loss: 0.0084 - acc: 0.989071/75 [===========================&gt;..] - ETA: 0s - loss: 0.0083 - acc: 0.989172/75 [===========================&gt;..] - ETA: 0s - loss: 0.0083 - acc: 0.989073/75 [============================&gt;.] - ETA: 0s - loss: 0.0083 - acc: 0.989074/75 [============================&gt;.] - ETA: 0s - loss: 0.0084 - acc: 0.989075/75 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.989075/75 [==============================] - 4s 55ms/step - loss: 0.0083 - acc: 0.9890 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 7/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 4s - loss: 0.0076 - acc: 0.9890 2/75 [..............................] - ETA: 3s - loss: 0.0087 - acc: 0.9872 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0077 - acc: 0.9892 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0080 - acc: 0.9896 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0075 - acc: 0.9905 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0073 - acc: 0.9910 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0071 - acc: 0.9913 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0076 - acc: 0.990210/75 [===&gt;..........................] - ETA: 3s - loss: 0.0074 - acc: 0.990312/75 [===&gt;..........................] - ETA: 3s - loss: 0.0071 - acc: 0.990513/75 [====&gt;.........................] - ETA: 3s - loss: 0.0069 - acc: 0.990714/75 [====&gt;.........................] - ETA: 3s - loss: 0.0070 - acc: 0.990315/75 [=====&gt;........................] - ETA: 3s - loss: 0.0071 - acc: 0.990216/75 [=====&gt;........................] - ETA: 3s - loss: 0.0070 - acc: 0.990217/75 [=====&gt;........................] - ETA: 3s - loss: 0.0070 - acc: 0.990418/75 [======&gt;.......................] - ETA: 3s - loss: 0.0070 - acc: 0.990319/75 [======&gt;.......................] - ETA: 3s - loss: 0.0071 - acc: 0.990120/75 [=======&gt;......................] - ETA: 2s - loss: 0.0071 - acc: 0.989921/75 [=======&gt;......................] - ETA: 2s - loss: 0.0072 - acc: 0.989722/75 [=======&gt;......................] - ETA: 2s - loss: 0.0072 - acc: 0.989823/75 [========&gt;.....................] - ETA: 2s - loss: 0.0071 - acc: 0.989824/75 [========&gt;.....................] - ETA: 2s - loss: 0.0072 - acc: 0.989725/75 [=========&gt;....................] - ETA: 2s - loss: 0.0072 - acc: 0.989826/75 [=========&gt;....................] - ETA: 2s - loss: 0.0072 - acc: 0.989727/75 [=========&gt;....................] - ETA: 2s - loss: 0.0073 - acc: 0.989428/75 [==========&gt;...................] - ETA: 2s - loss: 0.0073 - acc: 0.989329/75 [==========&gt;...................] - ETA: 2s - loss: 0.0072 - acc: 0.989330/75 [===========&gt;..................] - ETA: 2s - loss: 0.0073 - acc: 0.989231/75 [===========&gt;..................] - ETA: 2s - loss: 0.0073 - acc: 0.989332/75 [===========&gt;..................] - ETA: 2s - loss: 0.0074 - acc: 0.989233/75 [============&gt;.................] - ETA: 2s - loss: 0.0074 - acc: 0.989234/75 [============&gt;.................] - ETA: 2s - loss: 0.0076 - acc: 0.989135/75 [=============&gt;................] - ETA: 2s - loss: 0.0075 - acc: 0.989236/75 [=============&gt;................] - ETA: 2s - loss: 0.0076 - acc: 0.989137/75 [=============&gt;................] - ETA: 2s - loss: 0.0077 - acc: 0.988838/75 [==============&gt;...............] - ETA: 1s - loss: 0.0077 - acc: 0.988739/75 [==============&gt;...............] - ETA: 1s - loss: 0.0078 - acc: 0.988740/75 [===============&gt;..............] - ETA: 1s - loss: 0.0078 - acc: 0.988841/75 [===============&gt;..............] - ETA: 1s - loss: 0.0079 - acc: 0.988542/75 [===============&gt;..............] - ETA: 1s - loss: 0.0079 - acc: 0.988643/75 [================&gt;.............] - ETA: 1s - loss: 0.0079 - acc: 0.988644/75 [================&gt;.............] - ETA: 1s - loss: 0.0080 - acc: 0.988645/75 [=================&gt;............] - ETA: 1s - loss: 0.0080 - acc: 0.988547/75 [=================&gt;............] - ETA: 1s - loss: 0.0080 - acc: 0.988548/75 [==================&gt;...........] - ETA: 1s - loss: 0.0082 - acc: 0.988549/75 [==================&gt;...........] - ETA: 1s - loss: 0.0081 - acc: 0.988550/75 [===================&gt;..........] - ETA: 1s - loss: 0.0082 - acc: 0.988651/75 [===================&gt;..........] - ETA: 1s - loss: 0.0081 - acc: 0.988652/75 [===================&gt;..........] - ETA: 1s - loss: 0.0081 - acc: 0.988753/75 [====================&gt;.........] - ETA: 1s - loss: 0.0081 - acc: 0.988754/75 [====================&gt;.........] - ETA: 1s - loss: 0.0081 - acc: 0.988755/75 [=====================&gt;........] - ETA: 1s - loss: 0.0082 - acc: 0.988656/75 [=====================&gt;........] - ETA: 1s - loss: 0.0081 - acc: 0.988657/75 [=====================&gt;........] - ETA: 1s - loss: 0.0081 - acc: 0.988758/75 [======================&gt;.......] - ETA: 0s - loss: 0.0081 - acc: 0.988759/75 [======================&gt;.......] - ETA: 0s - loss: 0.0080 - acc: 0.988860/75 [=======================&gt;......] - ETA: 0s - loss: 0.0081 - acc: 0.988761/75 [=======================&gt;......] - ETA: 0s - loss: 0.0081 - acc: 0.988762/75 [=======================&gt;......] - ETA: 0s - loss: 0.0081 - acc: 0.988863/75 [========================&gt;.....] - ETA: 0s - loss: 0.0080 - acc: 0.988964/75 [========================&gt;.....] - ETA: 0s - loss: 0.0080 - acc: 0.988965/75 [=========================&gt;....] - ETA: 0s - loss: 0.0079 - acc: 0.989066/75 [=========================&gt;....] - ETA: 0s - loss: 0.0079 - acc: 0.989068/75 [==========================&gt;...] - ETA: 0s - loss: 0.0079 - acc: 0.989169/75 [==========================&gt;...] - ETA: 0s - loss: 0.0079 - acc: 0.989170/75 [===========================&gt;..] - ETA: 0s - loss: 0.0078 - acc: 0.989171/75 [===========================&gt;..] - ETA: 0s - loss: 0.0079 - acc: 0.989272/75 [===========================&gt;..] - ETA: 0s - loss: 0.0078 - acc: 0.989273/75 [============================&gt;.] - ETA: 0s - loss: 0.0079 - acc: 0.989074/75 [============================&gt;.] - ETA: 0s - loss: 0.0078 - acc: 0.989175/75 [==============================] - ETA: 0s - loss: 0.0078 - acc: 0.989175/75 [==============================] - 4s 55ms/step - loss: 0.0078 - acc: 0.9891 - lr: 0.0050</span></span>
<span><span class="co">## Epoch 8/8</span></span>
<span><span class="co">##  1/75 [..............................] - ETA: 4s - loss: 0.0094 - acc: 0.9886 2/75 [..............................] - ETA: 3s - loss: 0.0104 - acc: 0.9870 3/75 [&gt;.............................] - ETA: 3s - loss: 0.0084 - acc: 0.9892 4/75 [&gt;.............................] - ETA: 3s - loss: 0.0071 - acc: 0.9903 5/75 [=&gt;............................] - ETA: 3s - loss: 0.0070 - acc: 0.9905 6/75 [=&gt;............................] - ETA: 3s - loss: 0.0069 - acc: 0.9906 7/75 [=&gt;............................] - ETA: 3s - loss: 0.0069 - acc: 0.9904 8/75 [==&gt;...........................] - ETA: 3s - loss: 0.0066 - acc: 0.9907 9/75 [==&gt;...........................] - ETA: 3s - loss: 0.0066 - acc: 0.990710/75 [===&gt;..........................] - ETA: 3s - loss: 0.0066 - acc: 0.990511/75 [===&gt;..........................] - ETA: 3s - loss: 0.0065 - acc: 0.990412/75 [===&gt;..........................] - ETA: 3s - loss: 0.0064 - acc: 0.990513/75 [====&gt;.........................] - ETA: 3s - loss: 0.0068 - acc: 0.989614/75 [====&gt;.........................] - ETA: 3s - loss: 0.0068 - acc: 0.989415/75 [=====&gt;........................] - ETA: 3s - loss: 0.0069 - acc: 0.989516/75 [=====&gt;........................] - ETA: 3s - loss: 0.0068 - acc: 0.989517/75 [=====&gt;........................] - ETA: 3s - loss: 0.0067 - acc: 0.989618/75 [======&gt;.......................] - ETA: 3s - loss: 0.0066 - acc: 0.989719/75 [======&gt;.......................] - ETA: 2s - loss: 0.0066 - acc: 0.989920/75 [=======&gt;......................] - ETA: 2s - loss: 0.0066 - acc: 0.990021/75 [=======&gt;......................] - ETA: 2s - loss: 0.0065 - acc: 0.990222/75 [=======&gt;......................] - ETA: 2s - loss: 0.0066 - acc: 0.990023/75 [========&gt;.....................] - ETA: 2s - loss: 0.0066 - acc: 0.990124/75 [========&gt;.....................] - ETA: 2s - loss: 0.0067 - acc: 0.990325/75 [=========&gt;....................] - ETA: 2s - loss: 0.0068 - acc: 0.990226/75 [=========&gt;....................] - ETA: 2s - loss: 0.0067 - acc: 0.990327/75 [=========&gt;....................] - ETA: 2s - loss: 0.0067 - acc: 0.990428/75 [==========&gt;...................] - ETA: 2s - loss: 0.0066 - acc: 0.990529/75 [==========&gt;...................] - ETA: 2s - loss: 0.0067 - acc: 0.990430/75 [===========&gt;..................] - ETA: 2s - loss: 0.0067 - acc: 0.990531/75 [===========&gt;..................] - ETA: 2s - loss: 0.0067 - acc: 0.990632/75 [===========&gt;..................] - ETA: 2s - loss: 0.0066 - acc: 0.990633/75 [============&gt;.................] - ETA: 2s - loss: 0.0066 - acc: 0.990434/75 [============&gt;.................] - ETA: 2s - loss: 0.0066 - acc: 0.990436/75 [=============&gt;................] - ETA: 2s - loss: 0.0067 - acc: 0.990237/75 [=============&gt;................] - ETA: 2s - loss: 0.0067 - acc: 0.990138/75 [==============&gt;...............] - ETA: 1s - loss: 0.0068 - acc: 0.990139/75 [==============&gt;...............] - ETA: 1s - loss: 0.0069 - acc: 0.990040/75 [===============&gt;..............] - ETA: 1s - loss: 0.0069 - acc: 0.989842/75 [===============&gt;..............] - ETA: 1s - loss: 0.0069 - acc: 0.990043/75 [================&gt;.............] - ETA: 1s - loss: 0.0069 - acc: 0.989944/75 [================&gt;.............] - ETA: 1s - loss: 0.0069 - acc: 0.989945/75 [=================&gt;............] - ETA: 1s - loss: 0.0068 - acc: 0.990046/75 [=================&gt;............] - ETA: 1s - loss: 0.0068 - acc: 0.990047/75 [=================&gt;............] - ETA: 1s - loss: 0.0068 - acc: 0.990048/75 [==================&gt;...........] - ETA: 1s - loss: 0.0068 - acc: 0.989949/75 [==================&gt;...........] - ETA: 1s - loss: 0.0068 - acc: 0.990050/75 [===================&gt;..........] - ETA: 1s - loss: 0.0068 - acc: 0.990151/75 [===================&gt;..........] - ETA: 1s - loss: 0.0067 - acc: 0.990252/75 [===================&gt;..........] - ETA: 1s - loss: 0.0068 - acc: 0.990253/75 [====================&gt;.........] - ETA: 1s - loss: 0.0068 - acc: 0.990354/75 [====================&gt;.........] - ETA: 1s - loss: 0.0067 - acc: 0.990455/75 [=====================&gt;........] - ETA: 1s - loss: 0.0068 - acc: 0.990356/75 [=====================&gt;........] - ETA: 1s - loss: 0.0068 - acc: 0.990257/75 [=====================&gt;........] - ETA: 0s - loss: 0.0068 - acc: 0.990358/75 [======================&gt;.......] - ETA: 0s - loss: 0.0068 - acc: 0.990359/75 [======================&gt;.......] - ETA: 0s - loss: 0.0069 - acc: 0.990360/75 [=======================&gt;......] - ETA: 0s - loss: 0.0069 - acc: 0.990361/75 [=======================&gt;......] - ETA: 0s - loss: 0.0068 - acc: 0.990362/75 [=======================&gt;......] - ETA: 0s - loss: 0.0068 - acc: 0.990363/75 [========================&gt;.....] - ETA: 0s - loss: 0.0068 - acc: 0.990364/75 [========================&gt;.....] - ETA: 0s - loss: 0.0068 - acc: 0.990465/75 [=========================&gt;....] - ETA: 0s - loss: 0.0068 - acc: 0.990466/75 [=========================&gt;....] - ETA: 0s - loss: 0.0068 - acc: 0.990467/75 [=========================&gt;....] - ETA: 0s - loss: 0.0068 - acc: 0.990468/75 [==========================&gt;...] - ETA: 0s - loss: 0.0067 - acc: 0.990469/75 [==========================&gt;...] - ETA: 0s - loss: 0.0067 - acc: 0.990570/75 [===========================&gt;..] - ETA: 0s - loss: 0.0067 - acc: 0.990571/75 [===========================&gt;..] - ETA: 0s - loss: 0.0067 - acc: 0.990572/75 [===========================&gt;..] - ETA: 0s - loss: 0.0067 - acc: 0.990573/75 [============================&gt;.] - ETA: 0s - loss: 0.0067 - acc: 0.990574/75 [============================&gt;.] - ETA: 0s - loss: 0.0067 - acc: 0.990575/75 [==============================] - ETA: 0s - loss: 0.0067 - acc: 0.990575/75 [==============================] - 4s 54ms/step - loss: 0.0067 - acc: 0.9905 - lr: 0.0050</span></span></code></pre>
<pre><code><span><span class="co">## Training done.</span></span></code></pre>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
<p>Evaluate the trained model.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">gen</span> <span class="op">&lt;-</span>  <span class="fu"><a href="../reference/get_generator.html">get_generator</a></span><span class="op">(</span>path <span class="op">=</span> <span class="va">fasta_path</span>,</span>
<span>                      train_type <span class="op">=</span> <span class="st">"masked_lm"</span>,</span>
<span>                      masked_lm <span class="op">=</span> <span class="va">masked_lm</span>,</span>
<span>                      batch_size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      n_gram_stride <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                      return_int <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                      maxlen <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span>, <span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">z</span> <span class="op">&lt;-</span> <span class="fu">gen</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">sw</span> <span class="op">&lt;-</span> <span class="va">z</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">model</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> </span></code></pre></div>
<pre><code><span><span class="co">## 1/1 [==============================] - ETA: 0s1/1 [==============================] - 0s 103ms/step</span></span></code></pre>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">pred</span><span class="op">[</span><span class="fl">1</span>,,<span class="op">]</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span> </span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, sw <span class="op">=</span> <span class="va">sw</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, pred <span class="op">=</span> <span class="va">pred</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   x sw y pred</span></span>
<span><span class="co">## 1 5  1 1    1</span></span>
<span><span class="co">## 2 1  0 1    1</span></span>
<span><span class="co">## 3 1  0 1    1</span></span>
<span><span class="co">## 4 1  0 1    1</span></span>
<span><span class="co">## 5 1  0 1    1</span></span>
<span><span class="co">## 6 1  0 1    1</span></span></code></pre>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    x sw y pred</span></span>
<span><span class="co">## 1  5  1 1    1</span></span>
<span><span class="co">## 7  5  1 1    1</span></span>
<span><span class="co">## 14 5  1 1    1</span></span>
<span><span class="co">## 21 1  1 1    1</span></span>
<span><span class="co">## 34 5  1 2    2</span></span>
<span><span class="co">## 43 2  1 2    2</span></span>
<span><span class="co">## 51 4  1 3    3</span></span>
<span><span class="co">## 54 5  1 3    3</span></span>
<span><span class="co">## 59 3  1 3    3</span></span>
<span><span class="co">## 73 5  1 3    3</span></span>
<span><span class="co">## 74 5  1 3    3</span></span>
<span><span class="co">## 79 5  1 4    4</span></span>
<span><span class="co">## 82 5  1 4    4</span></span>
<span><span class="co">## 85 5  1 4    4</span></span>
<span><span class="co">## 87 2  1 4    4</span></span></code></pre>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df2</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">df</span><span class="op">$</span><span class="va">sw</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="va">df2</span><span class="op">$</span><span class="va">pred</span>, <span class="va">df2</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    </span></span>
<span><span class="co">##     1 2 3 4</span></span>
<span><span class="co">##   1 4 0 0 0</span></span>
<span><span class="co">##   2 0 2 0 0</span></span>
<span><span class="co">##   3 0 0 5 0</span></span>
<span><span class="co">##   4 0 0 0 4</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="label-classification">Label classification<a class="anchor" aria-label="anchor" href="#label-classification"></a>
</h2>
<p>With label classification, we describe the task of mapping a label to
a sequence. For example: given the input <tt>ACGACCG</tt>, does the
sequence belong to a viral or bacterial genome?</p>
<p>deepG offers three options to map a label to a sequence</p>
<ol style="list-style-type: decimal">
<li><p>the label gets read from the fasta header</p></li>
<li><p>files from every class are in separate folders</p></li>
<li><p>get label from csv file</p></li>
</ol>
<div class="section level3">
<h3 id="create-dummy-data-1">Create dummy data<a class="anchor" aria-label="anchor" href="#create-dummy-data-1"></a>
</h3>
<p>To test label classification, we create a simple dummy data set. One
class consists of random sequences using just <tt>A</tt> and <tt>C</tt>
and second class uses just <tt>G</tt> and <tt>T</tt>.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create training fasta files</span></span>
<span><span class="va">train_dir_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">train_dir_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir_1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">train_dir_2</span><span class="op">)</span></span>
<span><span class="va">train_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="va">train_dir_2</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_1"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_1_train_file"</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_2"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_2_train_file"</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/create_dummy_data.html">create_dummy_data</a></span><span class="op">(</span>file_path <span class="op">=</span> <span class="va">train_dir</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                    num_files <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                    seq_length <span class="op">=</span> <span class="fl">20</span>, </span>
<span>                    num_seq <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    header <span class="op">=</span> <span class="va">header</span>,</span>
<span>                    fasta_name_start <span class="op">=</span> <span class="va">fasta_name_start</span>,</span>
<span>                    vocabulary <span class="op">=</span> <span class="va">vocabulary</span><span class="op">)</span></span>
<span><span class="op">}</span>  </span>
<span></span>
<span><span class="co"># create validation fasta files</span></span>
<span><span class="va">val_dir_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">val_dir_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir_1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">val_dir_2</span><span class="op">)</span></span>
<span><span class="va">val_dir</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">val_dir_1</span>, <span class="va">val_dir_2</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">i</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"C"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_1"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_1_val_file"</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">vocabulary</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"G"</span>, <span class="st">"T"</span><span class="op">)</span></span>
<span>    <span class="va">header</span> <span class="op">&lt;-</span> <span class="st">"label_2"</span></span>
<span>    <span class="va">fasta_name_start</span> <span class="op">&lt;-</span> <span class="st">"label_2_val_file"</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/create_dummy_data.html">create_dummy_data</a></span><span class="op">(</span>file_path <span class="op">=</span> <span class="va">val_dir</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>,</span>
<span>                    num_files <span class="op">=</span> <span class="fl">3</span>,</span>
<span>                    seq_length <span class="op">=</span> <span class="fl">20</span>, </span>
<span>                    num_seq <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    header <span class="op">=</span> <span class="va">header</span>,</span>
<span>                    fasta_name_start <span class="op">=</span> <span class="va">fasta_name_start</span>,</span>
<span>                    vocabulary <span class="op">=</span> <span class="va">vocabulary</span><span class="op">)</span></span>
<span><span class="op">}</span>  </span></code></pre></div>
</div>
<div class="section level3">
<h3 id="label-by-folder">Label by folder<a class="anchor" aria-label="anchor" href="#label-by-folder"></a>
</h3>
<p>In this approach, we put all data from one class into a separate
folder. Say we want to classify if a sequence belongs to a viral or
bacterial genome. We may put all virus and bacteria files into their own
folder. In this case the <code>path</code> and <code>path_val</code>
arguments should be vectors, where each entry is the path to one
class.</p>
<p>First we have to create a model. We may use a model with 1 LSTM and 1
dense layer for predictions. An input sequence has length 5.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>, <span class="co"># binary classification</span></span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span> <span class="co"># text consists of A,C,G,T</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_3"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_5 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm_3 (LSTM)               (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense_5 (Dense)             (None, 2)                 18        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 434 (1.70 KB)</span></span>
<span><span class="co">## Trainable params: 434 (1.70 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_folder"</span>, <span class="co"># reading label from folder  </span></span>
<span>            model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            path <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="co"># note that path has two entries </span></span>
<span>                     <span class="va">train_dir_2</span><span class="op">)</span>,</span>
<span>            path_val <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">val_dir_1</span>,</span>
<span>                         <span class="va">val_dir_2</span><span class="op">)</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, <span class="co"># use 5 batches per epoch</span></span>
<span>            train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span>            batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">2</span>,</span>
<span>            vocabulary_label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label_1"</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="co"># names of classes</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 3s - loss: 0.7907 - acc: 0.0000e+005/5 [==============================] - 1s 67ms/step - loss: 0.4321 - acc: 0.7500 - val_loss: 0.0375 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0406 - acc: 1.00005/5 [==============================] - 0s 19ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Final epoch (plot to see history):</span></span>
<span><span class="co">##     loss: 0.015</span></span>
<span><span class="co">##      acc: 1</span></span>
<span><span class="co">## val_loss: 0.001184</span></span>
<span><span class="co">##  val_acc: 1</span></span>
<span><span class="co">##       lr: 0.1</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="label-by-fasta-header">Label by fasta header<a class="anchor" aria-label="anchor" href="#label-by-fasta-header"></a>
</h3>
<p>The fasta headers in our dummy data have the names “label_1” or
“label_2”</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="va">train_dir_1</span>, full.names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">fasta_file</span> <span class="op">&lt;-</span> <span class="fu">microseq</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/microseq/man/readFasta.html" class="external-link">readFasta</a></span><span class="op">(</span><span class="va">files</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">fasta_file</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 5 × 2</span></span></span>
<span><span class="co">##   Header  Sequence            </span></span>
<span><span class="co">##   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>               </span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> label_1 CCCACCCCCAACACCAACCC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">2</span> label_1 AACCCCCCACCCCAAACCAA</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">3</span> label_1 CCCAAACACACAACCAAACC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">4</span> label_1 ACCCAAAACAAAAACCCCAC</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">5</span> label_1 CCCAACAACCAAACACACCC</span></span></code></pre>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_header"</span>, <span class="co"># reading label from fasta header  </span></span>
<span>            model <span class="op">=</span> <span class="va">model</span>,</span>
<span>            path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>            path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>            steps_per_epoch <span class="op">=</span> <span class="fl">5</span>, </span>
<span>            train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span>            batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>            epochs <span class="op">=</span> <span class="fl">2</span>,</span>
<span>            vocabulary_label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label_1"</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="co"># names of labels</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0018 - acc: 1.00005/5 [==============================] - 0s 21ms/step - loss: 7.1555e-04 - acc: 1.0000 - val_loss: 2.1807e-04 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 2.2103e-04 - acc: 1.00005/5 [==============================] - 0s 20ms/step - loss: 1.0457e-04 - acc: 1.0000 - val_loss: 2.0042e-05 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Final epoch (plot to see history):</span></span>
<span><span class="co">##     loss: 0.0001046</span></span>
<span><span class="co">##      acc: 1</span></span>
<span><span class="co">## val_loss: 0.00002004</span></span>
<span><span class="co">##  val_acc: 1</span></span>
<span><span class="co">##       lr: 0.1</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="label-from-csv-file">Label from csv file<a class="anchor" aria-label="anchor" href="#label-from-csv-file"></a>
</h3>
<p>In this approach we extract the sequence label by mapping the current
file name to a csv table.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">files_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_1</span>, <span class="va">val_dir_1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">files_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">train_dir_2</span>, <span class="va">val_dir_2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">files_1</span>, <span class="va">files_2</span><span class="op">)</span></span>
<span><span class="va">label_1</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_detect.html" class="external-link">str_detect</a></span><span class="op">(</span><span class="va">file</span>, <span class="st">"label_1"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">label_2</span> <span class="op">&lt;-</span> <span class="fu">stringr</span><span class="fu">::</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_detect.html" class="external-link">str_detect</a></span><span class="op">(</span><span class="va">file</span>, <span class="st">"label_2"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">file</span>, <span class="va">label_1</span>, <span class="va">label_2</span><span class="op">)</span></span>
<span><span class="va">df</span></span></code></pre></div>
<pre><code><span><span class="co">##                          file label_1 label_2</span></span>
<span><span class="co">## 1  label_1_train_file_1.fasta       1       0</span></span>
<span><span class="co">## 2  label_1_train_file_2.fasta       1       0</span></span>
<span><span class="co">## 3  label_1_train_file_3.fasta       1       0</span></span>
<span><span class="co">## 4    label_1_val_file_1.fasta       1       0</span></span>
<span><span class="co">## 5    label_1_val_file_2.fasta       1       0</span></span>
<span><span class="co">## 6    label_1_val_file_3.fasta       1       0</span></span>
<span><span class="co">## 7  label_2_train_file_1.fasta       0       1</span></span>
<span><span class="co">## 8  label_2_train_file_2.fasta       0       1</span></span>
<span><span class="co">## 9  label_2_train_file_3.fasta       0       1</span></span>
<span><span class="co">## 10   label_2_val_file_1.fasta       0       1</span></span>
<span><span class="co">## 11   label_2_val_file_2.fasta       0       1</span></span>
<span><span class="co">## 12   label_2_val_file_3.fasta       0       1</span></span></code></pre>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">csv_path</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span>fileext <span class="op">=</span> <span class="st">".csv"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/write.table.html" class="external-link">write.csv</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">csv_path</span>, row.names <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_csv"</span>,</span>
<span>                    target_from_csv <span class="op">=</span> <span class="va">csv_path</span>,</span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">train_dir</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">val_dir</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    train_val_ratio <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span>                    batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 6.2479e-05 - acc: 1.00005/5 [==============================] - 0s 22ms/step - loss: 3.3899e-05 - acc: 1.0000 - val_loss: 3.0979e-05 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 3.0934e-05 - acc: 1.00005/5 [==============================] - 0s 21ms/step - loss: 1.7735e-05 - acc: 1.0000 - val_loss: 5.5730e-06 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-20-1.png" width="700"></p>
</div>
<div class="section level3">
<h3 id="training-with-rds-files">Training with rds files<a class="anchor" aria-label="anchor" href="#training-with-rds-files"></a>
</h3>
<p>We can also use rds files files as input, where the data must already
be preprocessed. We may use the <code>dataset_from_gen</code> function
to create rds files from fasta files.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rds_folder_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">rds_folder_val</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/tempfile.html" class="external-link">tempfile</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">rds_folder_train</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/files2.html" class="external-link">dir.create</a></span><span class="op">(</span><span class="va">rds_folder_val</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">data_type</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"train"</span>, <span class="st">"val"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  </span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">data_type</span> <span class="op">==</span> <span class="st">"train"</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">output_path</span> <span class="op">&lt;-</span> <span class="va">rds_folder_train</span></span>
<span>    <span class="va">path_corpus</span> <span class="op">&lt;-</span> <span class="va">train_dir</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">output_path</span> <span class="op">&lt;-</span> <span class="va">rds_folder_val</span></span>
<span>    <span class="va">path_corpus</span> <span class="op">&lt;-</span> <span class="va">val_dir</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="fu"><a href="../reference/dataset_from_gen.html">dataset_from_gen</a></span><span class="op">(</span>output_path <span class="op">=</span> <span class="va">output_path</span>,</span>
<span>                   iterations <span class="op">=</span> <span class="fl">25</span>, <span class="co"># create 25 rds files </span></span>
<span>                   train_type <span class="op">=</span> <span class="st">"label_folder"</span>,</span>
<span>                   path_corpus <span class="op">=</span> <span class="va">path_corpus</span>, </span>
<span>                   batch_size <span class="op">=</span> <span class="fl">128</span>,</span>
<span>                   maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                   step <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                   vocabulary <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"c"</span>, <span class="st">"g"</span>, <span class="st">"t"</span><span class="op">)</span>,</span>
<span>                   file_name_start <span class="op">=</span> <span class="st">"batch_"</span><span class="op">)</span></span>
<span>  </span>
<span><span class="op">}</span></span></code></pre></div>
<p>We created 25 files for training and validation with preprocessed
data.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">train_files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">list.files</a></span><span class="op">(</span><span class="va">rds_folder_train</span>, full.names <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/basename.html" class="external-link">basename</a></span><span class="op">(</span><span class="va">train_files</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  [1] "batch_1.rds"  "batch_10.rds" "batch_11.rds" "batch_12.rds" "batch_13.rds"</span></span>
<span><span class="co">##  [6] "batch_14.rds" "batch_15.rds" "batch_16.rds" "batch_17.rds" "batch_18.rds"</span></span>
<span><span class="co">## [11] "batch_19.rds" "batch_2.rds"  "batch_20.rds" "batch_21.rds" "batch_22.rds"</span></span>
<span><span class="co">## [16] "batch_23.rds" "batch_24.rds" "batch_25.rds" "batch_3.rds"  "batch_4.rds" </span></span>
<span><span class="co">## [21] "batch_5.rds"  "batch_6.rds"  "batch_7.rds"  "batch_8.rds"  "batch_9.rds"</span></span></code></pre>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/readRDS.html" class="external-link">readRDS</a></span><span class="op">(</span><span class="va">train_files</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">example_batch</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">example_batch</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 128   5   4</span></span></code></pre>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 128   2</span></span></code></pre>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span><span class="op">[</span><span class="fl">1</span>,,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##      [,1] [,2] [,3] [,4]</span></span>
<span><span class="co">## [1,]    0    1    0    0</span></span>
<span><span class="co">## [2,]    0    1    0    0</span></span>
<span><span class="co">## [3,]    0    1    0    0</span></span>
<span><span class="co">## [4,]    1    0    0    0</span></span>
<span><span class="co">## [5,]    0    1    0    0</span></span></code></pre>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span><span class="op">[</span><span class="fl">1</span>,<span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1 0</span></span></code></pre>
<p>We can now use these files for training.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Model: "model_4"</span></span>
<span><span class="co">## _________________________________________________________________</span></span>
<span><span class="co">##  Layer (type)                Output Shape              Param #   </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">##  input_6 (InputLayer)        [(None, 5, 4)]            0         </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  lstm_4 (LSTM)               (None, 8)                 416       </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">##  dense_6 (Dense)             (None, 2)                 18        </span></span>
<span><span class="co">##                                                                  </span></span>
<span><span class="co">## =================================================================</span></span>
<span><span class="co">## Total params: 434 (1.70 KB)</span></span>
<span><span class="co">## Trainable params: 434 (1.70 KB)</span></span>
<span><span class="co">## Non-trainable params: 0 (0.00 Byte)</span></span>
<span><span class="co">## _________________________________________________________________</span></span></code></pre>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/train_model.html">train_model</a></span><span class="op">(</span>train_type <span class="op">=</span> <span class="st">"label_rds"</span>,</span>
<span>                    model <span class="op">=</span> <span class="va">model</span>,</span>
<span>                    path <span class="op">=</span> <span class="va">rds_folder_train</span>,</span>
<span>                    path_val <span class="op">=</span> <span class="va">rds_folder_val</span>,</span>
<span>                    steps_per_epoch <span class="op">=</span> <span class="fl">5</span>,</span>
<span>                    format <span class="op">=</span> <span class="st">"rds"</span>,</span>
<span>                    batch_size <span class="op">=</span> <span class="fl">8</span>,</span>
<span>                    epochs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 3s - loss: 0.7408 - acc: 0.12505/5 [==============================] - 1s 63ms/step - loss: 0.2828 - acc: 0.8250 - val_loss: 0.0084 - val_acc: 1.0000 - lr: 0.1000</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/5 [=====&gt;........................] - ETA: 0s - loss: 0.0064 - acc: 1.00005/5 [==============================] - 0s 14ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.2997e-04 - val_acc: 1.0000 - lr: 0.1000</span></span></code></pre>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">hist</span><span class="op">)</span></span></code></pre></div>
<p><img src="training_types_files/figure-html/unnamed-chunk-23-1.png" width="700"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>

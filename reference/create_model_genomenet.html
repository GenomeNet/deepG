<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Create GenomeNet Model with Given Architecture Parameters — create_model_genomenet • deepG</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Create GenomeNet Model with Given Architecture Parameters — create_model_genomenet"><meta name="description" content="Create GenomeNet Model with Given Architecture Parameters"><meta property="og:description" content="Create GenomeNet Model with Given Architecture Parameters"><meta property="og:image" content="https://genomenet.github.io/deepG/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">deepG</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.3.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-alt"></span> Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-notebooks" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Notebooks</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-notebooks"><li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing">deepG tutorial</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing">Read-length level: Human contamination</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing">Locus level: CRISPR detection</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing">Gene level: 16S rRNA detection</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing">Genome level: Bacterial morphology (Sporulation)</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing">Full metagenome level: Colorectal cancer prediction</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing">BERT with deepG</a></li>
  </ul></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials"><li><a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/training_types.html">Training types</a></li>
    <li><a class="dropdown-item" href="../articles/data_generator.html">Data generator</a></li>
    <li><a class="dropdown-item" href="../articles/using_tb.html">Using tensorboard</a></li>
    <li><a class="dropdown-item" href="../articles/integrated_gradient.html">Integrated Gradient</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://github.com/GenomeNet/deepG/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Create GenomeNet Model with Given Architecture Parameters</h1>
      <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/master/R/create_model_genomenet.R" class="external-link"><code>R/create_model_genomenet.R</code></a></small>
      <div class="d-none name"><code>create_model_genomenet.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Create GenomeNet Model with Given Architecture Parameters</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">create_model_genomenet</span><span class="op">(</span></span>
<span>  maxlen <span class="op">=</span> <span class="fl">300</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  number_of_cnn_layers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  conv_block_count <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  kernel_size_0 <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  kernel_size_end <span class="op">=</span> <span class="fl">16</span>,</span>
<span>  filters_0 <span class="op">=</span> <span class="fl">256</span>,</span>
<span>  filters_end <span class="op">=</span> <span class="fl">512</span>,</span>
<span>  dilation_end <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  max_pool_end <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  dense_layer_num <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  dense_layer_units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  dropout_lstm <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  dropout <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  batch_norm_momentum <span class="op">=</span> <span class="fl">0.8</span>,</span>
<span>  leaky_relu_alpha <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  dense_activation <span class="op">=</span> <span class="st">"relu"</span>,</span>
<span>  skip_block_fraction <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  residual_block <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  reverse_encoding <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  model_type <span class="op">=</span> <span class="st">"gap"</span>,</span>
<span>  recurrent_type <span class="op">=</span> <span class="st">"lstm"</span>,</span>
<span>  recurrent_layers <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  recurrent_bidirectional <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  recurrent_units <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  vocabulary_size <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  last_layer_activation <span class="op">=</span> <span class="st">"softmax"</span>,</span>
<span>  loss_fn <span class="op">=</span> <span class="st">"categorical_crossentropy"</span>,</span>
<span>  auc_metric <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  num_targets <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  model_seed <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  bal_acc <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  f1_metric <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mixed_precision <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mirrored_strategy <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-maxlen">maxlen<a class="anchor" aria-label="anchor" href="#arg-maxlen"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Input sequence length.</p></dd>


<dt id="arg-learning-rate">learning_rate<a class="anchor" aria-label="anchor" href="#arg-learning-rate"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Used by the <code>keras</code> optimizer that is specified by <code>optimizer</code>.</p></dd>


<dt id="arg-number-of-cnn-layers">number_of_cnn_layers<a class="anchor" aria-label="anchor" href="#arg-number-of-cnn-layers"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Target number of CNN-layers to use in total. If <code>number_of_cnn_layers</code> is
greater than <code>conv_block_count</code>, then the effective number of CNN layers
is set to the closest integer that is divisible by <code>conv_block_count</code>.</p></dd>


<dt id="arg-conv-block-count">conv_block_count<a class="anchor" aria-label="anchor" href="#arg-conv-block-count"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of convolutional blocks, into which the CNN layers are divided.
If this is greater than <code>number_of_cnn_layers</code>, then it is set to
<code>number_of_cnn_layers</code> (the convolutional block size will then be 1).<br>
Convolutional blocks are used when <code>model_type</code> is <code>"gap"</code> (the output of
the last <code>conv_block_count * (1 - skip_block_fraction)</code> blocks is
fed to global average pooling and then concatenated), and also when
<code>residual_block</code> is <code>TRUE</code> (the number of filters is held constant within
blocks). If neither of these is the case, <code>conv_block_count</code> has little
effect besides the fact that <code>number_of_cnn_layers</code> is set to the closest
integer divisible by <code>conv_block_count</code>.</p></dd>


<dt id="arg-kernel-size-">kernel_size_0<a class="anchor" aria-label="anchor" href="#arg-kernel-size-"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target CNN kernel size of the first CNN-layer. Although CNN kernel size is
always an integer, this value can be non-integer, potentially affecting
the kernel-sizes of intermediate layers (which are geometrically
interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).</p></dd>


<dt id="arg-kernel-size-end">kernel_size_end<a class="anchor" aria-label="anchor" href="#arg-kernel-size-end"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target CNN kernel size of the last CNN-layer; ignored if only one
CNN-layer is used (i.e. if <code>number_of_cnn_layers</code> is 1). Although CNN
kernel size is always an integer, this value can be non-integer,
potentially affecting the kernel-sizes of intermediate layers (which are
geometrically interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).</p></dd>


<dt id="arg-filters-">filters_0<a class="anchor" aria-label="anchor" href="#arg-filters-"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target filter number of the first CNN-layer. Although CNN filter number is
always an integer, this value can be non-integer, potentially affecting
the filter-numbers of intermediate layers (which are geometrically
interpolated between <code>filters_0</code> and <code>filters_end</code>).<br>
Note that filters are constant within convolutional blocks when
<code>residual_block</code> is <code>TRUE</code>.</p></dd>


<dt id="arg-filters-end">filters_end<a class="anchor" aria-label="anchor" href="#arg-filters-end"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target filter number of the last CNN-layer; ignored if only one CNN-layer
is used (i.e. if <code>number_of_cnn_layers</code> is 1). Although CNN filter number
is always an integer, this value can be non-integer, potentially affecting
the filter-numbers of intermediate dilation_rates layers (which are geometrically
interpolated between <code>kernel_size_0</code> and <code>kernel_size_end</code>).<br>
Note that filters are constant within convolutional blocks when
<code>residual_block</code> is <code>TRUE</code>.</p></dd>


<dt id="arg-dilation-end">dilation_end<a class="anchor" aria-label="anchor" href="#arg-dilation-end"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Dilation of the last CNN-layer <em>within each block</em>. Dilation rates within
each convolutional block grows exponentially from 1 (no dilation) for the
first CNN-layer to each block, to this value. Set to 1 (default) to
disable dilation.</p></dd>


<dt id="arg-max-pool-end">max_pool_end<a class="anchor" aria-label="anchor" href="#arg-max-pool-end"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Target total effective pooling of CNN part of the network. "Effective
pooling" here is the product of the pooling rates of all previous
CNN-layers. A network with three CNN-layers, all of which are followed
by pooling layers of size 2, therefore has effective pooling of 8, with
the effective pooling at intermediate positions being 1 (beginning), 2,
and 4. Effective pooling after each layer is set to the power of 2 that is,
on a logarithmic scale, closest to
<code>max_pool_end ^ (&lt;CNN layer number&gt; / &lt;total number of CNN layers&gt;)</code>.
Therefore, even though the total effective pooling size of the whole
CNN part of the network will always be a power of 2, having different,
possibly non-integer values of <code>max_pool_end</code>, will still lead to
different networks.</p></dd>


<dt id="arg-dense-layer-num">dense_layer_num<a class="anchor" aria-label="anchor" href="#arg-dense-layer-num"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
number of dense layers at the end of the network, not counting the output
layer.</p></dd>


<dt id="arg-dense-layer-units">dense_layer_units<a class="anchor" aria-label="anchor" href="#arg-dense-layer-units"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of units in each dense layer, except for the output layer.</p></dd>


<dt id="arg-dropout-lstm">dropout_lstm<a class="anchor" aria-label="anchor" href="#arg-dropout-lstm"></a></dt>
<dd><p>Fraction of the units to drop for inputs.</p></dd>


<dt id="arg-dropout">dropout<a class="anchor" aria-label="anchor" href="#arg-dropout"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
Dropout rate of dense layers, except for the output layer.</p></dd>


<dt id="arg-batch-norm-momentum">batch_norm_momentum<a class="anchor" aria-label="anchor" href="#arg-batch-norm-momentum"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br><code>momentum</code>-parameter of <code>layer_batch_normalization</code> layers used in the
convolutional part of the network.</p></dd>


<dt id="arg-leaky-relu-alpha">leaky_relu_alpha<a class="anchor" aria-label="anchor" href="#arg-leaky-relu-alpha"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br><code>alpha</code>-parameter of the <code>layer_activation_leaky_relu</code> activation layers
used in the convolutional part of the network.</p></dd>


<dt id="arg-dense-activation">dense_activation<a class="anchor" aria-label="anchor" href="#arg-dense-activation"></a></dt>
<dd><p>(<code>character(1)</code>)<br>
Which activation function to use for dense layers. Should be one of
<code>"relu"</code>, <code>"sigmoid"</code>, or <code>"tanh"</code>.</p></dd>


<dt id="arg-skip-block-fraction">skip_block_fraction<a class="anchor" aria-label="anchor" href="#arg-skip-block-fraction"></a></dt>
<dd><p>(<code>numeric(1)</code>)<br>
What fraction of the first convolutional blocks to skip.
Only used when <code>model_type</code> is <code>"gap"</code>.</p></dd>


<dt id="arg-residual-block">residual_block<a class="anchor" aria-label="anchor" href="#arg-residual-block"></a></dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether to use residual layers in the convolutional part of the network.</p></dd>


<dt id="arg-reverse-encoding">reverse_encoding<a class="anchor" aria-label="anchor" href="#arg-reverse-encoding"></a></dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether the network should have a second input for reverse-complement
sequences.</p></dd>


<dt id="arg-optimizer">optimizer<a class="anchor" aria-label="anchor" href="#arg-optimizer"></a></dt>
<dd><p>(<code>character(1)</code>)<br>
Which optimizer to use. One of <code>"adam"</code>, <code>"adagrad"</code>, <code>"rmsprop"</code>, or <code>"sgd"</code>.</p></dd>


<dt id="arg-model-type">model_type<a class="anchor" aria-label="anchor" href="#arg-model-type"></a></dt>
<dd><p>(<code>character(1)</code>)<br>
Whether to use the global average pooling (<code>"gap"</code>) or recurrent
(<code>"recurrent"</code>) model type.</p></dd>


<dt id="arg-recurrent-type">recurrent_type<a class="anchor" aria-label="anchor" href="#arg-recurrent-type"></a></dt>
<dd><p>(<code>character(1)</code>)<br>
Which recurrent network type to use. One of <code>"lstm"</code> or <code>"gru"</code>.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt id="arg-recurrent-layers">recurrent_layers<a class="anchor" aria-label="anchor" href="#arg-recurrent-layers"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of recurrent layers.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt id="arg-recurrent-bidirectional">recurrent_bidirectional<a class="anchor" aria-label="anchor" href="#arg-recurrent-bidirectional"></a></dt>
<dd><p>(<code>logical(1)</code>)<br>
Whether to use bidirectional recurrent layers.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt id="arg-recurrent-units">recurrent_units<a class="anchor" aria-label="anchor" href="#arg-recurrent-units"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of units in each recurrent layer.
Only used when <code>model_type</code> is <code>"recurrent"</code>.</p></dd>


<dt id="arg-vocabulary-size">vocabulary_size<a class="anchor" aria-label="anchor" href="#arg-vocabulary-size"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Vocabulary size of (one-hot encoded) input strings. This determines the
input tensor shape, together with <code>maxlen</code>.</p></dd>


<dt id="arg-last-layer-activation">last_layer_activation<a class="anchor" aria-label="anchor" href="#arg-last-layer-activation"></a></dt>
<dd><p>Either <code>"sigmoid"</code> or <code>"softmax"</code>.</p></dd>


<dt id="arg-loss-fn">loss_fn<a class="anchor" aria-label="anchor" href="#arg-loss-fn"></a></dt>
<dd><p>Either <code>"categorical_crossentropy"</code> or <code>"binary_crossentropy"</code>. If <code>label_noise_matrix</code> given, will use custom <code>"noisy_loss"</code>.</p></dd>


<dt id="arg-auc-metric">auc_metric<a class="anchor" aria-label="anchor" href="#arg-auc-metric"></a></dt>
<dd><p>Whether to add AUC metric.</p></dd>


<dt id="arg-num-targets">num_targets<a class="anchor" aria-label="anchor" href="#arg-num-targets"></a></dt>
<dd><p>(integer <code>numeric(1)</code>)<br>
Number of output units to create.</p></dd>


<dt id="arg-model-seed">model_seed<a class="anchor" aria-label="anchor" href="#arg-model-seed"></a></dt>
<dd><p>Set seed for model parameters in tensorflow if not <code>NULL</code>.</p></dd>


<dt id="arg-bal-acc">bal_acc<a class="anchor" aria-label="anchor" href="#arg-bal-acc"></a></dt>
<dd><p>Whether to add balanced accuracy.</p></dd>


<dt id="arg-f-metric">f1_metric<a class="anchor" aria-label="anchor" href="#arg-f-metric"></a></dt>
<dd><p>Whether to add F1 metric.</p></dd>


<dt id="arg-mixed-precision">mixed_precision<a class="anchor" aria-label="anchor" href="#arg-mixed-precision"></a></dt>
<dd><p>Whether to use mixed precision (https://www.tensorflow.org/guide/mixed_precision).</p></dd>


<dt id="arg-mirrored-strategy">mirrored_strategy<a class="anchor" aria-label="anchor" href="#arg-mirrored-strategy"></a></dt>
<dd><p>Whether to use distributed mirrored strategy. If NULL, will use distributed mirrored strategy only if &gt;1 GPU available.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A keras model.</p>
<p>A keras model implementing genomenet architecture.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># reticulate::py_module_available("tensorflow")</span></span></span>
<span class="r-in"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">create_model_genomenet</span><span class="op">(</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">model</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>


<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Remove layers from model and add dense layers — remove_add_layers • deepG</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Remove layers from model and add dense layers — remove_add_layers"><meta name="description" content="Function takes a model as input and removes all layers after a certain layer, specified in layer_name argument.
Optional to add dense layers on top of pruned model. Model can have multiple output layers with separate loss/activation functions.
You can freeze all the weights of the pruned model by setting freeze_base_model = TRUE."><meta property="og:description" content="Function takes a model as input and removes all layers after a certain layer, specified in layer_name argument.
Optional to add dense layers on top of pruned model. Model can have multiple output layers with separate loss/activation functions.
You can freeze all the weights of the pruned model by setting freeze_base_model = TRUE."><meta property="og:image" content="https://genomenet.github.io/deepG/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">deepG</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.2.1-9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-alt"></span> Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-notebooks" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Notebooks</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-notebooks"><li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/175jIdXcDcgPUvaBo2rH2Lupbpjnp5O7G?usp=sharing">deepG tutorial</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1Eolc0koMNM1zkuO4XyVM58ImeF1BpRiH?usp=sharing">Read-length level: Human contamination</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1yiXSwFafXpMLHaov9iBTQLIDZ6bK1zYX?usp=sharing">Locus level: CRISPR detection</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1G7bOFEX87cZNrM2tdRtTdkrZn5fM__g0?usp=sharing">Gene level: 16S rRNA detection</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1BCggL-tfQF136YeJ8cKKi-zoBEDMgkNh?usp=sharing">Genome level: Bacterial morphology (Sporulation)</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/10xpRzGd3JeBAbqQYSCxzQUMctt01sx9D?usp=sharing">Full metagenome level: Colorectal cancer prediction</a></li>
    <li><a class="external-link dropdown-item" href="https://colab.research.google.com/drive/1kyYK7IU7GSfdpDzO_a8U3_qD4i3zTu6w?usp=sharing">BERT with deepG</a></li>
  </ul></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials"><li><a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/training_types.html">Training types</a></li>
    <li><a class="dropdown-item" href="../articles/data_generator.html">Data generator</a></li>
    <li><a class="dropdown-item" href="../articles/using_tb.html">Using tensorboard</a></li>
    <li><a class="dropdown-item" href="../articles/integrated_gradient.html">Integrated Gradient</a></li>
  </ul></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://github.com/GenomeNet/deepG/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Remove layers from model and add dense layers</h1>
      <small class="dont-index">Source: <a href="https://github.com/GenomeNet/deepG/blob/master/R/create_model_utils.R" class="external-link"><code>R/create_model_utils.R</code></a></small>
      <div class="d-none name"><code>remove_add_layers.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Function takes a model as input and removes all layers after a certain layer, specified in <code>layer_name</code> argument.
Optional to add dense layers on top of pruned model. Model can have multiple output layers with separate loss/activation functions.
You can freeze all the weights of the pruned model by setting <code>freeze_base_model = TRUE</code>.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">remove_add_layers</span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  layer_name <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dense_layers <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  shared_dense_layers <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  last_activation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"softmax"</span><span class="op">)</span>,</span>
<span>  output_names <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  losses <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  dropout <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  dropout_shared <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  freeze_base_model <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  compile <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.001</span>,</span>
<span>  solver <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  flatten <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  global_pooling <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  model_seed <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  mixed_precision <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  mirrored_strategy <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>A keras model.</p></dd>


<dt id="arg-layer-name">layer_name<a class="anchor" aria-label="anchor" href="#arg-layer-name"></a></dt>
<dd><p>Name of last layer to use from old model.</p></dd>


<dt id="arg-dense-layers">dense_layers<a class="anchor" aria-label="anchor" href="#arg-dense-layers"></a></dt>
<dd><p>List of vectors specifying number of units for each dense layer. If this is a list of length &gt; 1, model
has multiple output layers.</p></dd>


<dt id="arg-shared-dense-layers">shared_dense_layers<a class="anchor" aria-label="anchor" href="#arg-shared-dense-layers"></a></dt>
<dd><p>Vector with number of units for dense layer. These layers will be connected on top of layer in
argument <code>layer_name</code>. Can be used to have shared dense layers, before model has multiple output layers. Don't use if model has just one output layer
(use only <code>dense_layers</code>).</p></dd>


<dt id="arg-last-activation">last_activation<a class="anchor" aria-label="anchor" href="#arg-last-activation"></a></dt>
<dd><p>List of activations for last entry for each list entry from <code>dense_layers</code>. Either <code>"softmax"</code>, <code>"sigmoid"</code> or <code>"linear"</code>.</p></dd>


<dt id="arg-output-names">output_names<a class="anchor" aria-label="anchor" href="#arg-output-names"></a></dt>
<dd><p>List of names for each output layer.</p></dd>


<dt id="arg-losses">losses<a class="anchor" aria-label="anchor" href="#arg-losses"></a></dt>
<dd><p>List of loss function for each output.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>Boolean.</p></dd>


<dt id="arg-dropout">dropout<a class="anchor" aria-label="anchor" href="#arg-dropout"></a></dt>
<dd><p>List of vectors with dropout rates for each new dense layer.</p></dd>


<dt id="arg-dropout-shared">dropout_shared<a class="anchor" aria-label="anchor" href="#arg-dropout-shared"></a></dt>
<dd><p>Vectors of dropout rates for dense layer from <code>shared_dense_layers</code>.</p></dd>


<dt id="arg-freeze-base-model">freeze_base_model<a class="anchor" aria-label="anchor" href="#arg-freeze-base-model"></a></dt>
<dd><p>Whether to freeze all weights before new dense layers.</p></dd>


<dt id="arg-compile">compile<a class="anchor" aria-label="anchor" href="#arg-compile"></a></dt>
<dd><p>Boolean, whether to compile the new model.</p></dd>


<dt id="arg-learning-rate">learning_rate<a class="anchor" aria-label="anchor" href="#arg-learning-rate"></a></dt>
<dd><p>Learning rate if <code>compile = TRUE</code>, default learning rate of the old model.</p></dd>


<dt id="arg-solver">solver<a class="anchor" aria-label="anchor" href="#arg-solver"></a></dt>
<dd><p>Optimization method, options are <code>"adam", "adagrad", "rmsprop"</code> or <code>"sgd"</code>.</p></dd>


<dt id="arg-flatten">flatten<a class="anchor" aria-label="anchor" href="#arg-flatten"></a></dt>
<dd><p>Whether to add flatten layer before new dense layers.</p></dd>


<dt id="arg-global-pooling">global_pooling<a class="anchor" aria-label="anchor" href="#arg-global-pooling"></a></dt>
<dd><p>"max_ch_first" for global max pooling with channel first
(<a href="https://keras.io/api/layers/pooling_layers/global_average_pooling1d/" class="external-link">keras docs</a>),
"max_ch_last" for global max pooling with channel last, "average_ch_first" for global average pooling with channel first,
"average_ch_last" for global average pooling with channel last or <code>NULL</code> for no global pooling.
"both_ch_first" or "both_ch_last" to combine average and max pooling. "all" for all 4 options at once.</p></dd>


<dt id="arg-model-seed">model_seed<a class="anchor" aria-label="anchor" href="#arg-model-seed"></a></dt>
<dd><p>Set seed for model parameters in tensorflow if not <code>NULL</code>.</p></dd>


<dt id="arg-mixed-precision">mixed_precision<a class="anchor" aria-label="anchor" href="#arg-mixed-precision"></a></dt>
<dd><p>Whether to use mixed precision (https://www.tensorflow.org/guide/mixed_precision).</p></dd>


<dt id="arg-mirrored-strategy">mirrored_strategy<a class="anchor" aria-label="anchor" href="#arg-mirrored-strategy"></a></dt>
<dd><p>Whether to use distributed mirrored strategy. If NULL, will use distributed mirrored strategy only if &gt;1 GPU available.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A keras model; added and/or removed layers from some base model.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># reticulate::py_module_available("tensorflow")</span></span></span>
<span class="r-in"><span><span class="va">model_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="create_model_lstm_cnn.html">create_model_lstm_cnn</a></span><span class="op">(</span>layer_lstm <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">64</span>, <span class="fl">64</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                                 maxlen <span class="op">=</span> <span class="fl">50</span>,</span></span>
<span class="r-in"><span>                                 layer_dense <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">4</span><span class="op">)</span>, </span></span>
<span class="r-in"><span>                                 verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># get name of second to last layer </span></span></span>
<span class="r-in"><span><span class="va">num_layers</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">model_1</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">layers</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">layer_name</span> <span class="op">&lt;-</span> <span class="va">model_1</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">layers</span><span class="op">[[</span><span class="va">num_layers</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">name</span></span></span>
<span class="r-in"><span><span class="co"># add dense layer with multi outputs and separate loss/activation functions</span></span></span>
<span class="r-in"><span><span class="va">model_2</span> <span class="op">&lt;-</span> <span class="fu">remove_add_layers</span><span class="op">(</span>model <span class="op">=</span> <span class="va">model_1</span>,</span></span>
<span class="r-in"><span>                             layer_name <span class="op">=</span> <span class="va">layer_name</span>,</span></span>
<span class="r-in"><span>                             dense_layers <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">16</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">8</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">12</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             losses <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"binary_crossentropy"</span>, <span class="st">"mae"</span>,</span></span>
<span class="r-in"><span>                                           <span class="st">"categorical_crossentropy"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             last_activation <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"sigmoid"</span>, <span class="st">"linear"</span>, <span class="st">"softmax"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>                             freeze_base_model <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>                             output_names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"out_1_binary_classsification"</span>, </span></span>
<span class="r-in"><span>                                                 <span class="st">"out_2_regression"</span>, </span></span>
<span class="r-in"><span>                                                 <span class="st">"out_3_classification"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span> </span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Philipp Münch, René Mreches, Martin Binder, Hüseyin Anil Gündüz, Xiao-Yin To, Alice McHardy.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer></div>





  </body></html>


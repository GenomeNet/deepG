% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict.R
\name{predict_model_one_pred_per_entry}
\alias{predict_model_one_pred_per_entry}
\title{Get states for label classification model.}
\usage{
predict_model_one_pred_per_entry(
  model = NULL,
  layer_name = NULL,
  path_input,
  round_digits = 2,
  format = "fasta",
  ambiguous_nuc = "zero",
  filename = "states.h5",
  padding = padding,
  vocabulary = c("a", "c", "g", "t"),
  batch_size = 256,
  verbose = TRUE,
  return_states = FALSE,
  path_model = NULL,
  reverse_complement_encoding = FALSE,
  include_seq = FALSE,
  use_quality = FALSE,
  ...
)
}
\arguments{
\item{model}{A keras model. If model and path_model are not NULL, model will be used for inference.}

\item{layer_name}{Name of layer to get output from. If \code{NULL}, will use the last layer.}

\item{path_input}{Path to fasta file.}

\item{round_digits}{Number of decimal places.}

\item{format}{Either \code{"fasta"} or \code{"fastq"}.}

\item{ambiguous_nuc}{\code{"zero"} or \code{"equal"}.}

\item{filename}{Filename to store states in. No file output if argument is \code{NULL}.}

\item{padding}{Whether to pad sequences too short for one sample with zeros.}

\item{vocabulary}{Vector of allowed characters, character outside vocabulary get encoded as 0-vector.}

\item{batch_size}{Number of samples to evaluate at once. Does not change output, only relevant for speed and memory.}

\item{verbose}{Whether to print model before and after removing layers.}

\item{return_states}{Logical scalar, return states matrix.}

\item{path_model}{Path to a pretrained model.}

\item{include_seq}{Whether to include input sequence in h5 file.}

\item{...}{Further arguments for sequence encoding with \code{\link{seq_encoding_label}}.}
}
\description{
Computes output at specified model layer. Forces every fasta entry to have length maxlen by either padding sequences shorter than maxlen or taking random subsequence for
longer sequences.
}
\keyword{internal}

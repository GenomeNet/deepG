% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict.R
\name{predict_model}
\alias{predict_model}
\title{Make prediction for nucleotide sequence or entries in fasta/fastq file}
\usage{
predict_model(
  output_format = "one_seq",
  model = NULL,
  layer_name = NULL,
  sequence = NULL,
  path_input = NULL,
  round_digits = NULL,
  filename = "states.h5",
  step = 1,
  vocabulary = c("a", "c", "g", "t"),
  batch_size = 256,
  verbose = TRUE,
  return_states = FALSE,
  output_type = "h5",
  padding = "none",
  use_quality = FALSE,
  quality_string = NULL,
  path_model = NULL,
  mode = "label",
  lm_format = "target_right",
  output_dir = NULL,
  format = "fasta",
  include_seq = FALSE,
  reverse_complement_encoding = FALSE,
  ambiguous_nuc = "zero",
  ...
)
}
\arguments{
\item{output_format}{Either \code{"one_seq"}, \code{"by_entry"}, \code{"by_entry_one_file"}, \code{"one_pred_per_entry"}.}

\item{model}{A keras model. If model and path_model are not NULL, model will be used for inference.}

\item{layer_name}{Name of layer to get output from. If \code{NULL}, will use the last layer.}

\item{sequence}{Character string, ignores path_input if argument given.}

\item{path_input}{Path to fasta file.}

\item{round_digits}{Number of decimal places.}

\item{filename}{Filename to store states in. No file output if argument is \code{NULL}.}

\item{step}{Frequency of sampling steps.}

\item{vocabulary}{Vector of allowed characters, character outside vocabulary get encoded as 0-vector.}

\item{batch_size}{Number of samples to evaluate at once. Does not change output, only relevant for speed and memory.}

\item{verbose}{Boolean.}

\item{return_states}{Return predictions as data frame. Only supported for output_format \code{"one_seq"}.}

\item{output_type}{\code{"h5"} or \code{"csv"}. If \verb{output_format`` is }"by_entries_one_file", "one_pred_per_entry"\verb{can only be}"h5"`.}

\item{padding}{Either \code{"none"}, \code{"maxlen"}, \code{"standard"} or \code{"self"}.
\itemize{
\item If \code{"none"}, apply no padding and skip sequences that are too short.
\item If \code{"maxlen"}, pad with maxlen number of zeros vectors.
\item If \code{"standard"}, pad with zero vectors only if sequence is shorter than maxlen. Pads to minimum size required for one prediction.
\item If \code{"self"}, concatenate sequence with itself until sequence is long enough for one prediction.
Example: if sequence is "ACGT" and maxlen is 10, make prediction for "ACGTACGTAC".
Only applied if sequence is shorter than maxlen.
}}

\item{path_model}{Path to a pretrained model.}

\item{mode}{Either \code{"lm"} for language model or \code{"label"} for label classification.}

\item{output_dir}{Directory for file output.}

\item{format}{Either \code{"fasta"} or \code{"fastq"}.}

\item{include_seq}{Whether to include input sequence in h5 file.}

\item{reverse_complement_encoding}{Whether to use both original sequence and reverse complement as two input sequences.}

\item{ambiguous_nuc}{\code{"zero"} or \code{"equal"}.}

\item{...}{Further arguments for sequence encoding with \code{\link{seq_encoding_label}}.}
}
\description{
Removes layers (optional) from pretrained model and calculates states of fasta/fastq file or nucleotide sequence.
Writes states to h5 or csv file (access content of h5 output with \code{\link{load_prediction}} function).
There are several options on how to process an input file:
\itemize{
\item If \code{"one_seq"}, computes prediction for sequence argument or fasta/fastq file.
Combines fasta entries in file to one sequence. This means predictor sequences can contain elements from more than one fasta entry.
\item If \code{"by_entry"}, will output a separate file for each fasta/fastq entry.
Names of output files are: \code{output_dir} + "Nr" + i + \code{filename} + \code{output_type}, where i is the number of the fasta entry.
\item If \code{"by_entry_one_file"}, will store prediction for all fasta entries in one h5 file.
\item If \code{"one_pred_per_entry"}, will make one prediction for each entry by either picking random sample for long sequences
or pad sequence for short sequences.
}
}
\examples{
# make prediction for single sequence and write to h5 file
model <- create_model_lstm_cnn(maxlen = 20, layer_lstm = 8, layer_dense = 2, verbose = FALSE)
vocabulary <- c("a", "c", "g", "t")
sequence <- paste(sample(vocabulary, 200, replace = TRUE), collapse = "")
output_file <- tempfile(fileext = ".h5")
predict_model(output_format = "one_seq", model = model, step = 10,
             sequence = sequence, filename = output_file, mode = "label")

# make prediction for fasta file with multiple entries, write output to separate h5 files
fasta_path <- tempfile(fileext = ".fasta")
create_dummy_data(file_path = fasta_path, num_files = 1,
                 num_seq = 5, seq_length = 100,
                 write_to_file_path = TRUE)
model <- create_model_lstm_cnn(maxlen = 20, layer_lstm = 8, layer_dense = 2, verbose = FALSE)
output_dir <- tempfile()
dir.create(output_dir)
predict_model(output_format = "by_entry", model = model, step = 10, verbose = FALSE,
               output_dir = output_dir, mode = "label", path_input = fasta_path)
list.files(output_dir)
}

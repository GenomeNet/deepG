% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/create_model.R
\name{create_model_lstm_cnn_target_middle}
\alias{create_model_lstm_cnn_target_middle}
\title{Creates LSTM/CNN network}
\usage{
create_model_lstm_cnn_target_middle(
  maxlen = 50,
  dropout_lstm = 0,
  recurrent_dropout_lstm = 0,
  layer_lstm = 128,
  solver = "adam",
  learning_rate = 0.001,
  use_multiple_gpus = FALSE,
  merge_on_cpu = TRUE,
  gpu_num = 2,
  vocabulary_size = 4,
  bidirectional = FALSE,
  stateful = FALSE,
  batch_size = NULL,
  padding = "same",
  compile = TRUE,
  layer_dense = NULL,
  kernel_size = NULL,
  filters = NULL,
  pool_size = NULL,
  strides = NULL,
  label_input = NULL,
  zero_mask = FALSE,
  label_smoothing = 0,
  label_noise_matrix = NULL,
  last_layer_activation = "softmax",
  loss_fn = "categorical_crossentropy",
  num_output_layers = 1,
  f1_metric = FALSE,
  verbose = TRUE,
  batch_norm_momentum = 0.99
)
}
\arguments{
\item{maxlen}{Length of predictor sequence.}

\item{dropout_lstm}{Fraction of the units to drop for inputs.}

\item{recurrent_dropout_lstm}{Fraction of the units to drop for recurrent state.}

\item{layer_lstm}{Number of cells per network layer. Can be a scalar or vector.}

\item{solver}{Optimization method, options are "adam", "adagrad", "rmsprop" or "sgd".}

\item{learning_rate}{Learning rate for optimizer.}

\item{use_multiple_gpus}{If true, multi_gpu_model() will be used based on gpu_num.}

\item{merge_on_cpu}{True on default, false recommend if the server supports NVlink, only relevant if use.multiple.gpu is true.}

\item{gpu_num}{Number of GPUs to be used, only relevant if multiple_gpu is true.}

\item{vocabulary_size}{Number of unique character in vocabulary.}

\item{bidirectional}{Use bidirectional wrapper for lstm layers.}

\item{stateful}{Boolean. Whether to use stateful LSTM layer.}

\item{batch_size}{Number of samples that are used for one network update. Only used if \code{stateful = TRUE}.}

\item{padding}{Padding of CNN layers, e.g. "same", "valid" or "causal".}

\item{compile}{Whether to compile the model.}

\item{layer_dense}{Dense layers of size layer_dense after last LSTM (or last CNN if \code{layers.lstm = 0}) layer.}

\item{kernel_size}{Size of 1d convolutional layer.}

\item{filters}{Number of filters.}

\item{pool_size}{Integer, size of the max pooling windows.}

\item{strides}{Stide length of convolution.}

\item{label_input}{Integer or NULL. If not NULL, adds additional input layer of \code{label_input} size.}
}
\description{
Creates a network consisting of an arbitrary number of CNN, LSTM and dense layers.
Last layer is a dense layer with softmax activation.
Network tries to predict target in the middle of a sequence. If input is AACCTAAGG, input tensors should correspond to x1 = AACC, x2 = GGAA and y = T
(set \code{target_middle = TRUE} in \code{train_model} function).
Function creates two sub networks consisting each of an (optional) CNN layer followed by an arbitrary number of LSTM layers. Afterwards the last LSTM layers
get concatenated and followed by a dense layers.
}
